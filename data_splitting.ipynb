{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Functions'\n",
    "\n",
    "def preprocess_nifti_data(data_folder):\n",
    "    \"\"\"\n",
    "    Processes all .nii.gz files in a folder by extracting, loading, rotating, \n",
    "    and concatenating them into a single volume.\n",
    "    \n",
    "    Parameters:\n",
    "        data_folder (str): Path to the folder containing .nii.gz files.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The final 4D array of shape (Nx, Ny, Nz * num_files, t).\n",
    "    \"\"\"\n",
    "\n",
    "    volumes = []\n",
    "\n",
    "    # List all .nii.gz files in the folder\n",
    "    nii_gz_files = [f for f in os.listdir(data_folder) if f.endswith('.nii.gz')]\n",
    "\n",
    "    for file in nii_gz_files:\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        extracted_path = file_path[:-3]  # Remove \".gz\" to get \".nii\" path\n",
    "\n",
    "        # Extract the .nii file from .nii.gz\n",
    "        with gzip.open(file_path, 'rb') as f_in, open(extracted_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "        # Load the extracted .nii file\n",
    "        nii = nib.load(extracted_path)\n",
    "        data = nii.get_fdata()\n",
    "\n",
    "        # Rotate 90 degrees counterclockwise in the xy-plane\n",
    "        rotated_data = np.rot90(data, k=1, axes=(0, 1))\n",
    "\n",
    "        # Append to list\n",
    "        volumes.append(rotated_data)\n",
    "\n",
    "        # Delete the extracted .nii file after loading\n",
    "        os.remove(extracted_path)\n",
    "\n",
    "    # Concatenate along the z-axis\n",
    "    final_data = np.concatenate(volumes, axis=2)\n",
    "\n",
    "    print(f\"Final shape of ground truth: {final_data.shape}; dimensions: (Nx, Ny, Nz*Nvol, t)\")\n",
    "    return final_data\n",
    "\n",
    "\n",
    "def add_gaussian_noise(data, noise_level):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to each slice and timeframe in the dataset with a different noise level per slice and timeframe.\n",
    "\n",
    "    Parameters:\n",
    "        data (numpy.ndarray): The full dataset of shape (Nx, Ny, Nz*Nvol, t).\n",
    "        noise_level (float): Maximum fraction of image intensity to use as noise (between 0 and 1).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The noisy dataset with the same shape as the input.\n",
    "    \"\"\"\n",
    "    noisy_data = np.zeros_like(data)\n",
    "\n",
    "    # Iterate over time dimension\n",
    "    for t in range(data.shape[-1]):\n",
    "        for z in range(data.shape[2]):  # Iterate over slices in the 3rd dimension\n",
    "            # Compute slice-specific noise level as a fraction of its max intensity\n",
    "            max_intensity = np.max(data[:, :, z, t])\n",
    "            noise_std = np.random.uniform(0, noise_level) * max_intensity  # Scale noise\n",
    "\n",
    "            # Add Gaussian noise to this slice\n",
    "            noise = np.random.normal(0, noise_std, data[:, :, z, t].shape)\n",
    "            noisy_data[:, :, z, t] = data[:, :, z, t] + noise\n",
    "\n",
    "    print(f\"Final shape of noisy dataset: {noisy_data.shape}; dimensions: (Nx, Ny, Nz*Nvol, t)\")\n",
    "\n",
    "    return noisy_data\n",
    "\n",
    "\n",
    "def get_run_and_slice(slice_index, slices_per_run=39):\n",
    "    \"\"\"\n",
    "    Input slice index from total data volume and return specific run and corresponding slice within run.\n",
    "\n",
    "    Paramters:\n",
    "        slice_index: Slice index from total volume.\n",
    "\n",
    "    Returns:\n",
    "        run: specific run from which given slice_index originates.\n",
    "        \n",
    "        slice_within_run: corresponding slice in run.\n",
    "    \"\"\"\n",
    "    run = slice_index // slices_per_run + 1  # Runs are 1-based\n",
    "    slice_within_run = slice_index % slices_per_run\n",
    "    return run, slice_within_run\n",
    "\n",
    "\n",
    "def organize_data(source_folder, target_folder, train_subs, test_subs):\n",
    "    \"\"\"\n",
    "    Organizes .nii.gz files from a flat source folder into train and test folders based on subject prefixes.\n",
    "    \n",
    "    Parameters:\n",
    "        source_folder (str): Path to the folder containing all .nii.gz files\n",
    "        target_folder (str): Path to the target folder where files will be copied\n",
    "        train_subs (list): List of subject prefixes to use for training (e.g., ['sub-01', 'sub-02'])\n",
    "        test_subs (list): List of subject prefixes to use for testing (e.g., ['sub-03'])\n",
    "    \"\"\"\n",
    "    # Create train and test directories\n",
    "    train_dir = os.path.join(target_folder, 'train')\n",
    "    test_dir = os.path.join(target_folder, 'test')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all .nii.gz files from source folder\n",
    "    all_files = [f for f in os.listdir(source_folder) if f.endswith('.nii.gz')]\n",
    "    \n",
    "    # Process files\n",
    "    for file in all_files:\n",
    "        # Check if file starts with any of the train subject prefixes\n",
    "        is_train = any(file.startswith(sub) for sub in train_subs)\n",
    "        # Check if file starts with any of the test subject prefixes\n",
    "        is_test = any(file.startswith(sub) for sub in test_subs)\n",
    "        \n",
    "        if is_train:\n",
    "            src_file = os.path.join(source_folder, file)\n",
    "            dst_file = os.path.join(train_dir, file)\n",
    "            shutil.copy2(src_file, dst_file)\n",
    "            print(f\"Copied {file} to train set\")\n",
    "        elif is_test:\n",
    "            src_file = os.path.join(source_folder, file)\n",
    "            dst_file = os.path.join(test_dir, file)\n",
    "            shutil.copy2(src_file, dst_file)\n",
    "            print(f\"Copied {file} to test set\")\n",
    "        else:\n",
    "            print(f\"Skipped {file} - not in train or test subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate ground truth dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split functional data (without considering anatomical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied sub-01_ses-1_task-motor_run-10_bold (2).nii.gz to train set\n",
      "Copied sub-01_ses-1_task-motor_run-1_bold (1).nii.gz to train set\n",
      "Copied sub-01_ses-1_task-motor_run-2_bold (1).nii.gz to train set\n",
      "Copied sub-01_ses-1_task-motor_run-3_bold.nii.gz to train set\n",
      "Copied sub-01_ses-1_task-motor_run-4_bold.nii.gz to train set\n",
      "Copied sub-01_ses-1_task-motor_run-5_bold.nii.gz to train set\n",
      "Copied sub-01_ses-1_task-motor_run-6_bold.nii.gz to train set\n",
      "Copied sub-01_ses-1_task-motor_run-7_bold.nii.gz to train set\n",
      "Copied sub-01_ses-1_task-motor_run-8_bold.nii.gz to train set\n",
      "Copied sub-01_ses-1_task-motor_run-9_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-10_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-1_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-2_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-3_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-4_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-5_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-6_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-7_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-8_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-agency_run-9_bold.nii.gz to train set\n",
      "Copied sub-01_ses-2_task-rest_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-1_task-motor_run-10_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-1_task-motor_run-1_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-1_task-motor_run-2_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-1_task-motor_run-3_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-1_task-motor_run-4_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-1_task-motor_run-5_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-1_task-motor_run-6_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-1_task-motor_run-7_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-1_task-motor_run-9_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-10_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-1_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-2_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-3_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-4_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-5_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-6_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-7_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-8_bold.nii.gz to train set\n",
      "Copied sub-dd_ses-2_task-agency_run-9_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-10_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-1_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-2_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-3_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-4_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-5_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-6_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-7_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-8_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-1_task-motor_run-9_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-10_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-1_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-2_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-3_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-4_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-5_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-6_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-7_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-8_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-agency_run-9_bold.nii.gz to train set\n",
      "Copied sub-gg_ses-2_task-rest_bold.nii.gz to train set\n",
      "Copied sub-uu_ses-1_task-motor_run-10_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-1_task-motor_run-1_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-1_task-motor_run-2_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-1_task-motor_run-3_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-1_task-motor_run-4_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-1_task-motor_run-5_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-1_task-motor_run-6_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-1_task-motor_run-7_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-1_task-motor_run-8_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-1_task-motor_run-9_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-10_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-1_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-2_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-3_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-4_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-5_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-6_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-7_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-8_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-agency_run-9_bold.nii.gz to test set\n",
      "Copied sub-uu_ses-2_task-rest_bold.nii.gz to test set\n"
     ]
    }
   ],
   "source": [
    "# Creating train/test split (without considering) anatomical data\n",
    "source_folder = r'../all_data/func'\n",
    "target_folder = r'../split_data/func'\n",
    "train_subs = ['sub-01', 'sub-dd', 'sub-gg']\n",
    "test_subs = ['sub-uu']\n",
    "organize_data(source_folder, target_folder, train_subs, test_subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split with anatomical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied sub-01_ses-1_T1w.nii.gz to train set\n",
      "Copied sub-dd_ses-1_T1w.nii.gz to train set\n",
      "Copied sub-gg_ses-1_T1w.nii.gz to train set\n",
      "Copied sub-uu_ses-1_T1w.nii.gz to test set\n"
     ]
    }
   ],
   "source": [
    "# Creating train/test split including anatomical data\n",
    "source_folder = r'../all_data/anat'\n",
    "target_folder = r'../split_data/anat'\n",
    "train_subs = ['sub-01', 'sub-dd', 'sub-gg']\n",
    "test_subs = ['sub-uu']\n",
    "organize_data(source_folder, target_folder, train_subs, test_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
