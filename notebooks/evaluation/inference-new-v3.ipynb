{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11815303,"sourceType":"datasetVersion","datasetId":7421178},{"sourceId":392500,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":323167,"modelId":343895}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"!pip install tensorboardX","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:46.705929Z","iopub.execute_input":"2025-05-14T22:49:46.706219Z","iopub.status.idle":"2025-05-14T22:49:49.782518Z","shell.execute_reply.started":"2025-05-14T22:49:46.706199Z","shell.execute_reply":"2025-05-14T22:49:49.781548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport argparse\nimport logging\nfrom tensorboardX import SummaryWriter\nimport os\nimport numpy as np\n\nfrom io import BytesIO\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport random\nfrom re import split\nimport torch.utils.data\n\n# import torch.nn as nn\nfrom collections import OrderedDict\n\nimport functools\nfrom torch.nn import init\nfrom torch.nn import modules\n\n# u-net\nimport math\nimport torch.nn.functional as F\nfrom inspect import isfunction\n\n# diffusion\nfrom torch import nn\nfrom functools import partial\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:49.784173Z","iopub.execute_input":"2025-05-14T22:49:49.784513Z","iopub.status.idle":"2025-05-14T22:49:49.790382Z","shell.execute_reply.started":"2025-05-14T22:49:49.784480Z","shell.execute_reply":"2025-05-14T22:49:49.789657Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Config","metadata":{}},{"cell_type":"code","source":"opt = {\n    \"name\": \"denoising\",\n    \"phase\": \"test\",\n    \"gpu_ids\": [0, 1], \n    \"debug\": False,  \n    \"enable_wandb\": False,  \n    \"log_wandb_ckpt\": False,  \n    \"log_eval\": False,  \n    \"path\": {\n        \"log\": \"/kaggle/working/logs\",\n        \"tb_logger\": \"/kaggle/working/tb_logger\",\n        \"results\": \"/kaggle/working/results\",\n        \"checkpoint\": \"/kaggle/working/checkpoint\",\n        \"resume_state\": \"/kaggle/input/sr3_v3/pytorch/default/1/checkpoint/Final_I4500_E5\"\n    },\n    \"datasets\": {\n        \"train\": {\n            \"noisy_data_paths\": ['/kaggle/input/fmri-train-1-sampled/data/noisy_func_train_1.npy',\n                '/kaggle/input/fmri-train-2-sampled/data/noisy_func_train_2.npy',\n                '/kaggle/input/fmri-train-3-sampled/data/noisy_func_train_3.npy'],\n            \"gt_data_paths\": ['/kaggle/input/fmri-train-1-sampled/data/gt_func_train_1.npy',\n                '/kaggle/input/fmri-train-2-sampled/data/gt_func_train_2.npy',\n                '/kaggle/input/fmri-train-3-sampled/data/gt_func_train_3.npy'],\n            \"batch_size\": 1,\n            \"num_workers\": 1,\n            \"use_shuffle\": True\n        },\n        \"test\": {\n            \"noisy_data_paths\": ['/kaggle/input/fmri-test-norm-v3/data/noisy_func_test.npy'],\n            \"gt_data_paths\": ['/kaggle/input/fmri-test-norm-v3/data/gt_func_test.npy']\n        }\n    },\n    \"model\": {\n        \"which_model_G\": \"sr3\",\n        \"finetune_norm\": False,\n        \"unet\": {\n            \"in_channel\": 2,\n            \"out_channel\": 1,\n            \"inner_channel\": 64,\n            \"norm_groups\": 16,\n            \"channel_multiplier\": [1, 2, 4, 8],\n            \"attn_res\": [],\n            \"res_blocks\": 1,\n            \"dropout\": 0\n        },\n        \"beta_schedule\": {\n            \"train\": {\n                \"schedule\": \"linear\",\n                \"n_timestep\": 2000,\n                \"linear_start\": 1e-6,\n                \"linear_end\": 1e-2\n            },\n            \"test\": {\n                \"schedule\": \"linear\",\n                \"n_timestep\": 2000,\n                \"linear_start\": 1e-6,\n                \"linear_end\": 1e-2\n            }\n        },\n        \"diffusion\": {\n            \"image_size\": 64,\n            \"channels\": 1,\n            \"conditional\": True\n        }\n    },\n    \"train\": {\n        \"n_iter\": 150,\n        \"val_freq\": 1e4,\n        \"save_checkpoint_freq\": 100,\n        \"print_freq\": 50,\n        \"optimizer\": {\n            \"type\": \"adam\",\n            \"lr\": 3e-6\n        },\n        \"ema_scheduler\": {\n            \"step_start_ema\": 5000,\n            \"update_ema_every\": 1,\n            \"ema_decay\": 0.9999\n        }\n    },\n    \"wandb\": {\n        \"project\": \"distributed_high_sr_ffhq\"\n    },\n    \"config_file\": \"config/sr_sr3_16_128.json\"  # from CLI\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:49.791048Z","iopub.execute_input":"2025-05-14T22:49:49.791242Z","iopub.status.idle":"2025-05-14T22:49:49.808072Z","shell.execute_reply.started":"2025-05-14T22:49:49.791228Z","shell.execute_reply":"2025-05-14T22:49:49.807234Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(opt['path']['log'], exist_ok=True)\nos.makedirs(opt['path']['tb_logger'], exist_ok=True)\nos.makedirs(opt['path']['results'], exist_ok=True)\nos.makedirs(opt['path']['checkpoint'], exist_ok=True)\n#os.makedirs(opt['path']['resume_state'], exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:49.808813Z","iopub.execute_input":"2025-05-14T22:49:49.809127Z","iopub.status.idle":"2025-05-14T22:49:49.825216Z","shell.execute_reply.started":"2025-05-14T22:49:49.809109Z","shell.execute_reply":"2025-05-14T22:49:49.824529Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Logger","metadata":{}},{"cell_type":"code","source":"# logging\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\ndef dict2str(opt, indent_l=1):\n    '''dict to string for logger'''\n    msg = ''\n    for k, v in opt.items():\n        if isinstance(v, dict):\n            msg += ' ' * (indent_l * 2) + k + ':[\\n'\n            msg += dict2str(v, indent_l + 1)\n            msg += ' ' * (indent_l * 2) + ']\\n'\n        else:\n            msg += ' ' * (indent_l * 2) + k + ': ' + str(v) + '\\n'\n    return msg\n\ndef setup_logger(logger_name, root, phase, level=logging.INFO, screen=False):\n    '''set up logger'''\n    l = logging.getLogger(logger_name)\n    formatter = logging.Formatter(\n        '%(asctime)s.%(msecs)03d - %(levelname)s: %(message)s', datefmt='%y-%m-%d %H:%M:%S')\n    log_file = os.path.join(root, '{}.log'.format(phase))\n    fh = logging.FileHandler(log_file, mode='w')\n    fh.setFormatter(formatter)\n    l.setLevel(level)\n    l.addHandler(fh)\n    if screen:\n        sh = logging.StreamHandler()\n        sh.setFormatter(formatter)\n        l.addHandler(sh)\n\n\nsetup_logger(None, opt['path']['log'],\n                    'train', level=logging.INFO, screen=True)\nsetup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\nlogger = logging.getLogger('base')\n#logger.info(dict2str(opt))\ntb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])\n\n# # Initialize WandbLogger\n# if opt['enable_wandb']:\n#     import wandb\n#     wandb_logger = WandbLogger(opt)\n#     wandb.define_metric('validation/val_step')\n#     wandb.define_metric('epoch')\n#     wandb.define_metric(\"validation/*\", step_metric=\"val_step\")\n#     val_step = 0\n# else:\n#     wandb_logger = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:49.826983Z","iopub.execute_input":"2025-05-14T22:49:49.827192Z","iopub.status.idle":"2025-05-14T22:49:49.845272Z","shell.execute_reply.started":"2025-05-14T22:49:49.827177Z","shell.execute_reply":"2025-05-14T22:49:49.844532Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dataset creation","metadata":{}},{"cell_type":"code","source":"class PairwiseDataset(Dataset):\n    def __init__(self, noisy_images_paths: list, gt_images_paths: list):\n        \"\"\"Initialize fMRI dataset for denoising with memory-efficient loading.\n        \n        Args:\n            noisy_images_paths (list): List of paths to noisy fMRI volumes (.npy files)\n            gt_images_paths (list): List of paths to ground truth fMRI volumes (.npy files)\n        \"\"\"\n        self.noisy_paths = noisy_images_paths\n        self.gt_paths = gt_images_paths\n        \n        # Get the data shape and total slices without loading all data\n        # Just load file info and calculate indices\n        self.file_slice_mapping = []\n        self.z_t_dimension_sizes = []\n        total_slices = 0\n        dataset_length = 0 # in terms of indeces that can be iteratet over at the end (less than slice number due to batch loading within get_item)\n        \n        for i, path in enumerate(noisy_images_paths):\n            # Load metadata about the file shape without loading full content\n            data_shape = np.load(path, mmap_mode='r').shape\n            num_slices = data_shape[2] * data_shape[3]  # z * t\n            self.z_t_dimension_sizes.append((data_shape[2], data_shape[3]))\n            \n            # Store mapping information: which file and which t index (has been done due to more efficient data loading, no information aggregation based thinking behind that)\n            for batch_idx in range(0, data_shape[3]):\n                self.file_slice_mapping.append((i, batch_idx))\n                dataset_length += 1\n            \n            total_slices += num_slices \n            \n        self.data_len = dataset_length\n\n    def __len__(self):\n        return self.data_len\n\n    def __getitem__(self, index):\n        # Use the mapping to determine which file and slice to load\n        file_idx, t_idx = self.file_slice_mapping[index]\n        \n        # Load data from the specific file\n        noisy_file_path = self.noisy_paths[file_idx]\n        gt_file_path = self.gt_paths[file_idx]\n        \n        # Load the full 4D array with mmap_mode to avoid loading everything\n        noisy_volume = np.load(noisy_file_path, mmap_mode='r')\n        gt_volume = np.load(gt_file_path, mmap_mode='r')\n        \n        # Extract only the slice we need\n        noisy_slice = noisy_volume[:, :, :, t_idx].copy()  # Force copy from mmap\n        gt_slice = gt_volume[:, :, :, t_idx].copy()\n        \n        return {\n            'GT': torch.tensor(gt_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n            'Noisy': torch.tensor(noisy_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n            'Index': index\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:49.846409Z","iopub.execute_input":"2025-05-14T22:49:49.846626Z","iopub.status.idle":"2025-05-14T22:49:49.858001Z","shell.execute_reply.started":"2025-05-14T22:49:49.846609Z","shell.execute_reply":"2025-05-14T22:49:49.857271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PairwiseTestDataset(Dataset):\n    def __init__(self, noisy_images_paths: list, gt_images_paths: list):\n        \"\"\"Initialize fMRI dataset for denoising with memory-efficient loading.\n        \n        Args:\n            noisy_images_paths (list): List of paths to noisy fMRI volumes (.npy files)\n            gt_images_paths (list): List of paths to ground truth fMRI volumes (.npy files)\n        \"\"\"\n        self.noisy_paths = noisy_images_paths\n        self.gt_paths = gt_images_paths\n        \n        # Get the data shape and total slices without loading all data\n        # Just load file info and calculate indices\n        self.file_slice_mapping = []\n        total_slices = 0\n        \n        for i, path in enumerate(noisy_images_paths):\n            # Load metadata about the file shape without loading full content\n            data_shape = np.load(path, mmap_mode='r').shape\n            num_slices = data_shape[2] * data_shape[3]  # z * t\n            \n            # Store mapping information: which file and which slice\n            for slice_idx in range(num_slices):\n                self.file_slice_mapping.append((i, slice_idx))\n            \n            total_slices += num_slices\n            \n        self.data_len = total_slices\n\n    def __len__(self):\n        return self.data_len\n\n    def __getitem__(self, index):\n        # Use the mapping to determine which file and slice to load\n        file_idx, slice_idx = self.file_slice_mapping[index]\n        \n        # Load data from the specific file\n        noisy_file_path = self.noisy_paths[file_idx]\n        gt_file_path = self.gt_paths[file_idx]\n        \n        # Load the full 4D array with mmap_mode to avoid loading everything\n        noisy_volume = np.load(noisy_file_path, mmap_mode='r')\n        gt_volume = np.load(gt_file_path, mmap_mode='r')\n        \n        # Calculate the z and t indices from linear slice_idx\n        z = slice_idx % noisy_volume.shape[2]\n        t = slice_idx // noisy_volume.shape[2]\n        \n        # Extract only the slice we need\n        noisy_slice = noisy_volume[:, :, z, t].copy()  # Force copy from mmap\n        gt_slice = gt_volume[:, :, z, t].copy()\n        \n        return {\n            'GT': torch.tensor(gt_slice).float().unsqueeze(0),\n            'Noisy': torch.tensor(noisy_slice).float().unsqueeze(0),\n            'Index': index\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:49.858798Z","iopub.execute_input":"2025-05-14T22:49:49.859094Z","iopub.status.idle":"2025-05-14T22:49:49.879081Z","shell.execute_reply.started":"2025-05-14T22:49:49.859077Z","shell.execute_reply":"2025-05-14T22:49:49.878281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collate_merge_batches(batch):\n    merged = {\n        'Noisy': torch.cat([item['Noisy'] for item in batch], dim=0),\n        'GT': torch.cat([item['GT'] for item in batch], dim=0),\n        'Index': [item['Index'] for item in batch]\n    }\n    return merged\n\ndef create_dataloader(dataset, dataset_opt, phase):\n    '''create dataloader '''\n    if phase == 'train':\n        return torch.utils.data.DataLoader(\n            dataset,\n            batch_size=dataset_opt['batch_size'],\n            shuffle=dataset_opt['use_shuffle'],\n            num_workers=dataset_opt['num_workers'],\n            pin_memory=True,\n            collate_fn = collate_merge_batches)\n    elif phase == 'test':\n        return torch.utils.data.DataLoader(\n            dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n    else:\n        raise NotImplementedError(\n            'Dataloader [{:s}] is not found.'.format(phase))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:49.880087Z","iopub.execute_input":"2025-05-14T22:49:49.880438Z","iopub.status.idle":"2025-05-14T22:49:49.897549Z","shell.execute_reply.started":"2025-05-14T22:49:49.880418Z","shell.execute_reply":"2025-05-14T22:49:49.896824Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# dataset\nfor phase, dataset_opt in opt['datasets'].items():\n    if phase == 'train' and opt['phase'] != 'test':\n        train_set = PairwiseDataset(dataset_opt['noisy_data_paths'], dataset_opt['gt_data_paths'])\n        train_loader = create_dataloader(\n            train_set, dataset_opt, phase)\n    elif phase == 'test':\n        test_set = PairwiseTestDataset(dataset_opt['noisy_data_paths'], dataset_opt['gt_data_paths'])\n        test_loader = create_dataloader(\n            test_set, dataset_opt, phase)\n# logger.info('Initial Dataset Finished')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:49.898561Z","iopub.execute_input":"2025-05-14T22:49:49.899209Z","iopub.status.idle":"2025-05-14T22:49:49.930812Z","shell.execute_reply.started":"2025-05-14T22:49:49.899172Z","shell.execute_reply":"2025-05-14T22:49:49.930235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"noisy_slice = test_set[400][\"Noisy\"]\ngt_slice = test_set[400][\"GT\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:49.931522Z","iopub.execute_input":"2025-05-14T22:49:49.931781Z","iopub.status.idle":"2025-05-14T22:49:50.061686Z","shell.execute_reply.started":"2025-05-14T22:49:49.931760Z","shell.execute_reply":"2025-05-14T22:49:50.061052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# for _, data in train_loader:\n#     print(data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:50.062466Z","iopub.execute_input":"2025-05-14T22:49:50.062677Z","iopub.status.idle":"2025-05-14T22:49:50.065969Z","shell.execute_reply.started":"2025-05-14T22:49:50.062661Z","shell.execute_reply":"2025-05-14T22:49:50.065451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\n\n# Plot ground truth image\naxes[0].imshow(noisy_slice.squeeze(0), cmap='gray')\naxes[1].imshow(gt_slice.squeeze(0), cmap='gray')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:50.066680Z","iopub.execute_input":"2025-05-14T22:49:50.066868Z","iopub.status.idle":"2025-05-14T22:49:50.369826Z","shell.execute_reply.started":"2025-05-14T22:49:50.066853Z","shell.execute_reply":"2025-05-14T22:49:50.369140Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model loading","metadata":{}},{"cell_type":"markdown","source":"Modules","metadata":{}},{"cell_type":"code","source":"# generic functions\ndef exists(x):\n    return x is not None\n\n\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if isfunction(d) else d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:50.370626Z","iopub.execute_input":"2025-05-14T22:49:50.370904Z","iopub.status.idle":"2025-05-14T22:49:50.375152Z","shell.execute_reply.started":"2025-05-14T22:49:50.370880Z","shell.execute_reply":"2025-05-14T22:49:50.374477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### U-Net ###\n\n# PositionalEncoding Source： https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\nclass PositionalEncoding(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, noise_level):\n        count = self.dim // 2\n        step = torch.arange(count, dtype=noise_level.dtype,\n                            device=noise_level.device) / count\n        encoding = noise_level.unsqueeze(\n            1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n        encoding = torch.cat(\n            [torch.sin(encoding), torch.cos(encoding)], dim=-1)\n        return encoding\n\n\nclass FeatureWiseAffine(nn.Module):\n    def __init__(self, in_channels, out_channels, use_affine_level=False):\n        super(FeatureWiseAffine, self).__init__()\n        self.use_affine_level = use_affine_level\n        self.noise_func = nn.Sequential(\n            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n        )\n\n    def forward(self, x, noise_embed):\n        batch = x.shape[0]\n        if self.use_affine_level:\n            gamma, beta = self.noise_func(noise_embed).view(\n                batch, -1, 1, 1).chunk(2, dim=1)\n            x = (1 + gamma) * x + beta\n        else:\n            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n        return x\n\n\nclass Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\n\nclass Upsample(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n\n    def forward(self, x):\n        return self.conv(self.up(x))\n\n\nclass Downsample(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n\n    def forward(self, x):\n        return self.conv(x)\n\n\n# building block modules\n\n\nclass Block(nn.Module):\n    def __init__(self, dim, dim_out, groups=32, dropout=0):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.GroupNorm(groups, dim),\n            Swish(),\n            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n            nn.Conv2d(dim, dim_out, 3, padding=1)\n        )\n\n    def forward(self, x):\n        return self.block(x)\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32):\n        super().__init__()\n        self.noise_func = FeatureWiseAffine(\n            noise_level_emb_dim, dim_out, use_affine_level)\n\n        self.block1 = Block(dim, dim_out, groups=norm_groups)\n        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout)\n        self.res_conv = nn.Conv2d(\n            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n\n    def forward(self, x, time_emb):\n        b, c, h, w = x.shape\n        h = self.block1(x)\n        h = self.noise_func(h, time_emb)\n        h = self.block2(h)\n        return h + self.res_conv(x)\n\n\nclass SelfAttention(nn.Module):\n    def __init__(self, in_channel, n_head=1, norm_groups=32):\n        super().__init__()\n\n        self.n_head = n_head\n\n        self.norm = nn.GroupNorm(norm_groups, in_channel)\n        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n        self.out = nn.Conv2d(in_channel, in_channel, 1)\n\n    def forward(self, input):\n        batch, channel, height, width = input.shape\n        n_head = self.n_head\n        head_dim = channel // n_head\n\n        norm = self.norm(input)\n        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n\n        attn = torch.einsum(\n            \"bnchw, bncyx -> bnhwyx\", query, key\n        ).contiguous() / math.sqrt(channel)\n        attn = attn.view(batch, n_head, height, width, -1)\n        attn = torch.softmax(attn, -1)\n        attn = attn.view(batch, n_head, height, width, height, width)\n\n        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n        out = self.out(out.view(batch, channel, height, width))\n\n        return out + input\n\n\nclass ResnetBlocWithAttn(nn.Module):\n    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False):\n        super().__init__()\n        self.with_attn = with_attn\n        self.res_block = ResnetBlock(\n            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout)\n        if with_attn:\n            self.attn = SelfAttention(dim_out, norm_groups=norm_groups)\n\n    def forward(self, x, time_emb):\n        x = self.res_block(x, time_emb)\n        if(self.with_attn):\n            x = self.attn(x)\n        return x\n\n\nclass UNet(nn.Module):\n    def __init__(\n        self,\n        in_channel=6,\n        out_channel=3,\n        inner_channel=32,\n        norm_groups=32,\n        channel_mults=(1, 2, 4, 8, 8),\n        attn_res=(8),\n        res_blocks=3,\n        dropout=0,\n        with_noise_level_emb=True,\n        image_size=128\n    ):\n        super().__init__()\n\n        if with_noise_level_emb:\n            noise_level_channel = inner_channel\n            self.noise_level_mlp = nn.Sequential(\n                PositionalEncoding(inner_channel),\n                nn.Linear(inner_channel, inner_channel * 4),\n                Swish(),\n                nn.Linear(inner_channel * 4, inner_channel)\n            )\n        else:\n            noise_level_channel = None\n            self.noise_level_mlp = None\n\n        num_mults = len(channel_mults)\n        pre_channel = inner_channel\n        feat_channels = [pre_channel]\n        now_res = image_size\n        downs = [nn.Conv2d(in_channel, inner_channel,\n                           kernel_size=3, padding=1)]\n        for ind in range(num_mults):\n            is_last = (ind == num_mults - 1)\n            use_attn = (now_res in attn_res)\n            channel_mult = inner_channel * channel_mults[ind]\n            for _ in range(0, res_blocks):\n                downs.append(ResnetBlocWithAttn(\n                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn))\n                feat_channels.append(channel_mult)\n                pre_channel = channel_mult\n            if not is_last:\n                downs.append(Downsample(pre_channel))\n                feat_channels.append(pre_channel)\n                now_res = now_res//2\n        self.downs = nn.ModuleList(downs)\n\n        self.mid = nn.ModuleList([\n            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n                               dropout=dropout, with_attn=True),\n            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n                               dropout=dropout, with_attn=False)\n        ])\n\n        ups = []\n        for ind in reversed(range(num_mults)):\n            is_last = (ind < 1)\n            use_attn = (now_res in attn_res)\n            channel_mult = inner_channel * channel_mults[ind]\n            for _ in range(0, res_blocks+1):\n                ups.append(ResnetBlocWithAttn(\n                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n                        dropout=dropout, with_attn=use_attn))\n                pre_channel = channel_mult\n            if not is_last:\n                ups.append(Upsample(pre_channel))\n                now_res = now_res*2\n\n        self.ups = nn.ModuleList(ups)\n\n        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups)\n\n    def forward(self, x, time):\n        t = self.noise_level_mlp(time) if exists(\n            self.noise_level_mlp) else None\n\n        feats = []\n        for layer in self.downs:\n            if isinstance(layer, ResnetBlocWithAttn):\n                x = layer(x, t)\n            else:\n                x = layer(x)\n            feats.append(x)\n\n        for layer in self.mid:\n            if isinstance(layer, ResnetBlocWithAttn):\n                x = layer(x, t)\n            else:\n                x = layer(x)\n\n        for layer in self.ups:\n            if isinstance(layer, ResnetBlocWithAttn):\n                x = layer(torch.cat((x, feats.pop()), dim=1), t)\n            else:\n                x = layer(x)\n\n        return self.final_conv(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:50.378008Z","iopub.execute_input":"2025-05-14T22:49:50.378204Z","iopub.status.idle":"2025-05-14T22:49:50.405245Z","shell.execute_reply.started":"2025-05-14T22:49:50.378189Z","shell.execute_reply":"2025-05-14T22:49:50.404627Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Diffusion ###\ndef _warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n    betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n    warmup_time = int(n_timestep * warmup_frac)\n    betas[:warmup_time] = np.linspace(\n        linear_start, linear_end, warmup_time, dtype=np.float64)\n    return betas\n\n\ndef make_beta_schedule(schedule, n_timestep, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n    if schedule == 'quad':\n        betas = np.linspace(linear_start ** 0.5, linear_end ** 0.5,\n                            n_timestep, dtype=np.float64) ** 2\n    elif schedule == 'linear':\n        betas = np.linspace(linear_start, linear_end,\n                            n_timestep, dtype=np.float64)\n    elif schedule == 'warmup10':\n        betas = _warmup_beta(linear_start, linear_end,\n                             n_timestep, 0.1)\n    elif schedule == 'warmup50':\n        betas = _warmup_beta(linear_start, linear_end,\n                             n_timestep, 0.5)\n    elif schedule == 'const':\n        betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n    elif schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n        betas = 1. / np.linspace(n_timestep,\n                                 1, n_timestep, dtype=np.float64)\n    elif schedule == \"cosine\":\n        timesteps = (\n            torch.arange(n_timestep + 1, dtype=torch.float64) /\n            n_timestep + cosine_s\n        )\n        alphas = timesteps / (1 + cosine_s) * math.pi / 2\n        alphas = torch.cos(alphas).pow(2)\n        alphas = alphas / alphas[0]\n        betas = 1 - alphas[1:] / alphas[:-1]\n        betas = betas.clamp(max=0.999)\n    else:\n        raise NotImplementedError(schedule)\n    return betas\n\n\n# gaussian diffusion trainer class\nclass GaussianDiffusion(nn.Module):\n    def __init__(\n        self,\n        denoise_fn,\n        image_size,\n        channels=3,\n        loss_type='l1',\n        conditional=True,\n        schedule_opt=None\n    ):\n        super().__init__()\n        self.channels = channels\n        self.image_size = image_size\n        self.denoise_fn = denoise_fn\n        self.loss_type = loss_type\n        self.conditional = conditional\n        if schedule_opt is not None:\n            pass\n            # self.set_new_noise_schedule(schedule_opt)\n\n    def set_loss(self, device):\n        if self.loss_type == 'l1':\n            self.loss_func = nn.L1Loss(reduction='sum').to(device)\n        elif self.loss_type == 'l2':\n            self.loss_func = nn.MSELoss(reduction='sum').to(device)\n        else:\n            raise NotImplementedError()\n\n    def set_new_noise_schedule(self, schedule_opt, device):\n        to_torch = partial(torch.tensor, dtype=torch.float32, device=device)\n\n        betas = make_beta_schedule(\n            schedule=schedule_opt['schedule'],\n            n_timestep=schedule_opt['n_timestep'],\n            linear_start=schedule_opt['linear_start'],\n            linear_end=schedule_opt['linear_end'])\n        betas = betas.detach().cpu().numpy() if isinstance(\n            betas, torch.Tensor) else betas\n        alphas = 1. - betas\n        alphas_cumprod = np.cumprod(alphas, axis=0)\n        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n        self.sqrt_alphas_cumprod_prev = np.sqrt(\n            np.append(1., alphas_cumprod))\n\n        timesteps, = betas.shape\n        self.num_timesteps = int(timesteps)\n        self.register_buffer('betas', to_torch(betas))\n        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n        self.register_buffer('alphas_cumprod_prev',\n                             to_torch(alphas_cumprod_prev))\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer('sqrt_alphas_cumprod',\n                             to_torch(np.sqrt(alphas_cumprod)))\n        self.register_buffer('sqrt_one_minus_alphas_cumprod',\n                             to_torch(np.sqrt(1. - alphas_cumprod)))\n        self.register_buffer('log_one_minus_alphas_cumprod',\n                             to_torch(np.log(1. - alphas_cumprod)))\n        self.register_buffer('sqrt_recip_alphas_cumprod',\n                             to_torch(np.sqrt(1. / alphas_cumprod)))\n        self.register_buffer('sqrt_recipm1_alphas_cumprod',\n                             to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n\n        # calculations for posterior q(x_{t-1} | x_t, x_0)\n        posterior_variance = betas * \\\n            (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n        self.register_buffer('posterior_variance',\n                             to_torch(posterior_variance))\n        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n        self.register_buffer('posterior_log_variance_clipped', to_torch(\n            np.log(np.maximum(posterior_variance, 1e-20))))\n        self.register_buffer('posterior_mean_coef1', to_torch(\n            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n        self.register_buffer('posterior_mean_coef2', to_torch(\n            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n\n    def predict_start_from_noise(self, x_t, t, noise):\n        return self.sqrt_recip_alphas_cumprod[t] * x_t - \\\n            self.sqrt_recipm1_alphas_cumprod[t] * noise\n\n    def q_posterior(self, x_start, x_t, t):\n        posterior_mean = self.posterior_mean_coef1[t] * \\\n            x_start + self.posterior_mean_coef2[t] * x_t\n        posterior_log_variance_clipped = self.posterior_log_variance_clipped[t]\n        return posterior_mean, posterior_log_variance_clipped\n\n    def p_mean_variance(self, x, t, clip_denoised: bool, condition_x=None):\n        batch_size = x.shape[0]\n        noise_level = torch.FloatTensor(\n            [self.sqrt_alphas_cumprod_prev[t+1]]).repeat(batch_size, 1).to(x.device)\n        if condition_x is not None:\n            #print(f\"condition:{condition_x.shape}\")\n            #print(f\"x:{x.shape}\")\n            x_recon = self.predict_start_from_noise(\n                x, t=t, noise=self.denoise_fn(torch.cat([condition_x, x], dim=1), noise_level)) # previously dim=1\n            #print(f\"x_recon:{x_recon.shape}\")\n        else:\n            x_recon = self.predict_start_from_noise(\n                x, t=t, noise=self.denoise_fn(x, noise_level))\n\n        if clip_denoised:\n            x_recon.clamp_(-1., 1.)\n\n        model_mean, posterior_log_variance = self.q_posterior(\n            x_start=x_recon, x_t=x, t=t)\n        return model_mean, posterior_log_variance\n\n    @torch.no_grad()\n    def p_sample(self, x, t, clip_denoised=True, condition_x=None):\n        model_mean, model_log_variance = self.p_mean_variance(\n            x=x, t=t, clip_denoised=clip_denoised, condition_x=condition_x)\n        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n        return model_mean + noise * (0.5 * model_log_variance).exp()\n\n    @torch.no_grad()\n    def p_sample_loop(self, x_in, continous=False):\n        device = self.betas.device\n        sample_inter = (1 | (self.num_timesteps//10))\n        if not self.conditional:\n            shape = x_in\n            img = torch.randn(shape, device=device)\n            ret_img = img\n            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n                img = self.p_sample(img, i)\n                if i % sample_inter == 0:\n                    ret_img = torch.cat([ret_img, img], dim=0)\n        else:\n            x = x_in\n            shape = x.shape\n            #print(shape)\n            img = torch.randn(shape, device=device)\n            ret_img = x\n            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n                img = self.p_sample(img, i, condition_x=x)\n                if i % sample_inter == 0:\n                    ret_img = torch.cat([ret_img, img], dim=0)\n                    #print(ret_img.shape)\n        if continous:\n            return ret_img\n        else:\n            return ret_img[-1]\n\n    @torch.no_grad()\n    def sample(self, batch_size=1, continous=False):\n        image_size = self.image_size\n        channels = self.channels\n        return self.p_sample_loop((batch_size, channels, image_size, image_size), continous)\n\n    @torch.no_grad()\n    def super_resolution(self, x_in, continous=False):\n        return self.p_sample_loop(x_in, continous)\n\n    def q_sample(self, x_start, continuous_sqrt_alpha_cumprod, noise=None):\n        noise = default(noise, lambda: torch.randn_like(x_start))\n\n        # random gama\n        return (\n            continuous_sqrt_alpha_cumprod * x_start +\n            (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * noise\n        )\n\n    def p_losses(self, x_in, noise=None):\n        x_start = x_in['GT']\n        [b, c, h, w] = x_start.shape\n        t = np.random.randint(1, self.num_timesteps + 1)\n        continuous_sqrt_alpha_cumprod = torch.FloatTensor(\n            np.random.uniform(\n                self.sqrt_alphas_cumprod_prev[t-1],\n                self.sqrt_alphas_cumprod_prev[t],\n                size=b\n            )\n        ).to(x_start.device)\n        continuous_sqrt_alpha_cumprod = continuous_sqrt_alpha_cumprod.view(\n            b, -1)\n\n        noise = default(noise, lambda: torch.randn_like(x_start))\n        x_noisy = self.q_sample(\n            x_start=x_start, continuous_sqrt_alpha_cumprod=continuous_sqrt_alpha_cumprod.view(-1, 1, 1, 1), noise=noise)\n\n        if not self.conditional:\n            x_recon = self.denoise_fn(x_noisy, continuous_sqrt_alpha_cumprod)\n        else:\n            x_recon = self.denoise_fn(\n                torch.cat([x_in['Noisy'], x_noisy], dim=1), continuous_sqrt_alpha_cumprod)\n                # Everything has to be 4D! Otherwise concatenation on this axis is not possible!!!\n                # The concatenated representation is automatically 4D anyways at the end!!!\n        loss = self.loss_func(noise, x_recon)\n        return loss\n\n    def forward(self, x, *args, **kwargs):\n        return self.p_losses(x, *args, **kwargs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:50.406235Z","iopub.execute_input":"2025-05-14T22:49:50.406634Z","iopub.status.idle":"2025-05-14T22:49:50.433342Z","shell.execute_reply.started":"2025-05-14T22:49:50.406612Z","shell.execute_reply":"2025-05-14T22:49:50.432671Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Helper functions","metadata":{}},{"cell_type":"code","source":"def weights_init_normal(m, std=0.02):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.normal_(m.weight.data, 0.0, std)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('Linear') != -1:\n        init.normal_(m.weight.data, 0.0, std)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal_(m.weight.data, 1.0, std)  # BN also uses norm\n        init.constant_(m.bias.data, 0.0)\n\n\ndef weights_init_kaiming(m, scale=1):\n    classname = m.__class__.__name__\n    if classname.find('Conv2d') != -1:\n        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n        m.weight.data *= scale\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('Linear') != -1:\n        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n        m.weight.data *= scale\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('BatchNorm2d') != -1:\n        init.constant_(m.weight.data, 1.0)\n        init.constant_(m.bias.data, 0.0)\n\n\ndef weights_init_orthogonal(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.orthogonal_(m.weight.data, gain=1)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('Linear') != -1:\n        init.orthogonal_(m.weight.data, gain=1)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('BatchNorm2d') != -1:\n        init.constant_(m.weight.data, 1.0)\n        init.constant_(m.bias.data, 0.0)\n\n\ndef init_weights(net, init_type='kaiming', scale=1, std=0.02):\n    # scale for 'kaiming', std for 'normal'.\n    logger.info('Initialization method [{:s}]'.format(init_type))\n    if init_type == 'normal':\n        weights_init_normal_ = functools.partial(weights_init_normal, std=std)\n        net.apply(weights_init_normal_)\n    elif init_type == 'kaiming':\n        weights_init_kaiming_ = functools.partial(\n            weights_init_kaiming, scale=scale)\n        net.apply(weights_init_kaiming_)\n    elif init_type == 'orthogonal':\n        net.apply(weights_init_orthogonal)\n    else:\n        raise NotImplementedError(\n            'initialization method [{:s}] not implemented'.format(init_type))\n\n\n####################\n# define network\n####################\n\n\n# Generator\ndef define_G(opt):\n    model_opt = opt['model']\n    if ('norm_groups' not in model_opt['unet']) or model_opt['unet']['norm_groups'] is None:\n        model_opt['unet']['norm_groups']=32\n    model = UNet(\n        in_channel=model_opt['unet']['in_channel'],\n        out_channel=model_opt['unet']['out_channel'],\n        norm_groups=model_opt['unet']['norm_groups'],\n        inner_channel=model_opt['unet']['inner_channel'],\n        channel_mults=model_opt['unet']['channel_multiplier'],\n        attn_res=model_opt['unet']['attn_res'],\n        res_blocks=model_opt['unet']['res_blocks'],\n        dropout=model_opt['unet']['dropout'],\n        image_size=model_opt['diffusion']['image_size']\n    )\n    netG = GaussianDiffusion(\n        model,\n        image_size=model_opt['diffusion']['image_size'],\n        channels=model_opt['diffusion']['channels'],\n        loss_type='l1',    # L1 or L2\n        conditional=model_opt['diffusion']['conditional'],\n        schedule_opt=model_opt['beta_schedule']['train']\n    )\n    if opt['phase'] == 'train':\n        # init_weights(netG, init_type='kaiming', scale=0.1)\n        init_weights(netG, init_type='orthogonal')\n    if opt['gpu_ids']:\n        assert torch.cuda.is_available()\n    # if opt['gpu_ids'] and opt['distributed']:\n    #     assert torch.cuda.is_available()\n    #     netG = nn.DataParallel(netG)\n    return netG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:50.434169Z","iopub.execute_input":"2025-05-14T22:49:50.434423Z","iopub.status.idle":"2025-05-14T22:49:50.453831Z","shell.execute_reply.started":"2025-05-14T22:49:50.434405Z","shell.execute_reply":"2025-05-14T22:49:50.453068Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model classes","metadata":{}},{"cell_type":"code","source":"class SR3():\n    def __init__(self, opt):\n        self.opt = opt\n        self.device = torch.device(\n            'cuda' if opt['gpu_ids'] is not None else 'cpu')\n        self.begin_step = 0\n        self.begin_epoch = 0\n        # define network and load pretrained models\n        self.netG = self.set_device(define_G(opt))\n        self.schedule_phase = None\n\n        # set loss and load resume state\n        self.set_loss()\n        self.set_new_noise_schedule(\n            opt['model']['beta_schedule']['train'], schedule_phase='train')\n        if self.opt['phase'] == 'train':\n            self.netG.train()\n            # find the parameters to optimize\n            if opt['model']['finetune_norm']:\n                optim_params = []\n                for k, v in self.netG.named_parameters():\n                    v.requires_grad = False\n                    if k.find('transformer') >= 0:\n                        v.requires_grad = True\n                        v.data.zero_()\n                        optim_params.append(v)\n                        logger.info(\n                            'Params [{:s}] initialized to 0 and will optimize.'.format(k))\n            else:\n                optim_params = list(self.netG.parameters())\n\n            self.optG = torch.optim.Adam(\n                optim_params, lr=opt['train'][\"optimizer\"][\"lr\"])\n            self.log_dict = OrderedDict()\n        self.load_network()\n        self.print_network()\n\n    def set_device(self, x):\n        if isinstance(x, dict):\n            for key, item in x.items():\n                if item is not None and type(item)==torch.Tensor:\n                    x[key] = item.to(self.device)\n        elif isinstance(x, list):\n            for item in x:\n                if item is not None:\n                    item = item.to(self.device)\n        else:\n            x = x.to(self.device)\n        return x\n\n    def get_network_description(self, network):\n        '''Get the string and total parameters of the network'''\n        if isinstance(network, nn.DataParallel):\n            network = network.module\n        s = str(network)\n        n = sum(map(lambda x: x.numel(), network.parameters()))\n        return s, n\n\n    def feed_data(self, data):\n        self.data = self.set_device(data)\n\n    def optimize_parameters(self):\n        self.optG.zero_grad()\n        l_pix = self.netG(self.data)\n        # need to average in multi-gpu\n        b, c, h, w = self.data['GT'].shape\n        l_pix = l_pix.sum()/int(b*c*h*w)\n        l_pix.backward()\n        self.optG.step()\n\n        # set log\n        self.log_dict['l_pix'] = l_pix.item()\n\n    def test(self, continous=False):\n        self.netG.eval()\n        with torch.no_grad():\n            if isinstance(self.netG, nn.DataParallel):\n                self.SR = self.netG.module.super_resolution(\n                    self.data['Noisy'], continous)\n            else:\n                self.SR = self.netG.super_resolution(\n                    self.data['Noisy'], continous)\n        self.netG.train()\n\n    def inference(self, img, continous=False):\n        self.netG.eval()\n        return self.netG.super_resolution(\n                    img, continous)\n\n    def sample(self, batch_size=1, continous=False):\n        self.netG.eval()\n        with torch.no_grad():\n            if isinstance(self.netG, nn.DataParallel):\n                self.SR = self.netG.module.sample(batch_size, continous)\n            else:\n                self.SR = self.netG.sample(batch_size, continous)\n        self.netG.train()\n\n    def set_loss(self):\n        if isinstance(self.netG, nn.DataParallel):\n            self.netG.module.set_loss(self.device)\n        else:\n            self.netG.set_loss(self.device)\n\n    def set_new_noise_schedule(self, schedule_opt, schedule_phase='train'):\n        if self.schedule_phase is None or self.schedule_phase != schedule_phase:\n            self.schedule_phase = schedule_phase\n            if isinstance(self.netG, nn.DataParallel):\n                self.netG.module.set_new_noise_schedule(\n                    schedule_opt, self.device)\n            else:\n                self.netG.set_new_noise_schedule(schedule_opt, self.device)\n\n    def get_current_log(self):\n        return self.log_dict\n\n    def get_current_visuals(self, need_LR=True, sample=False):\n        out_dict = OrderedDict()\n        if sample:\n            out_dict['SAM'] = self.SR.detach().float().cpu()\n        else:\n            out_dict['SR'] = self.SR.detach().float().cpu()\n            out_dict['INF'] = self.data['SR'].detach().float().cpu()\n            out_dict['HR'] = self.data['HR'].detach().float().cpu()\n            if need_LR and 'LR' in self.data:\n                out_dict['LR'] = self.data['LR'].detach().float().cpu()\n            else:\n                out_dict['LR'] = out_dict['INF']\n        return out_dict\n\n    def print_network(self):\n        s, n = self.get_network_description(self.netG)\n        if isinstance(self.netG, nn.DataParallel):\n            net_struc_str = '{} - {}'.format(self.netG.__class__.__name__,\n                                             self.netG.module.__class__.__name__)\n        else:\n            net_struc_str = '{}'.format(self.netG.__class__.__name__)\n\n        logger.info(\n            'Network G structure: {}, with parameters: {:,d}'.format(net_struc_str, n))\n        logger.info(s)\n\n    def save_network(self, epoch, iter_step):\n        gen_path = os.path.join(\n            self.opt['path']['checkpoint'], 'I{}_E{}_gen.pth'.format(iter_step, epoch))\n        opt_path = os.path.join(\n            self.opt['path']['checkpoint'], 'I{}_E{}_opt.pth'.format(iter_step, epoch))\n        # gen\n        network = self.netG\n        if isinstance(self.netG, nn.DataParallel):\n            network = network.module\n        state_dict = network.state_dict()\n        for key, param in state_dict.items():\n            state_dict[key] = param.cpu()\n        torch.save(state_dict, gen_path)\n        # opt\n        opt_state = {'epoch': epoch, 'iter': iter_step,\n                     'scheduler': None, 'optimizer': None}\n        opt_state['optimizer'] = self.optG.state_dict()\n        torch.save(opt_state, opt_path)\n\n        logger.info(\n            'Saved model in [{:s}] ...'.format(gen_path))\n\n    def load_network(self):\n        load_path = self.opt['path']['resume_state']\n        if load_path is not None:\n            logger.info(\n                'Loading pretrained model for G [{:s}] ...'.format(load_path))\n            gen_path = '{}_gen.pth'.format(load_path)\n            opt_path = '{}_opt.pth'.format(load_path)\n            # gen\n            network = self.netG\n            if isinstance(self.netG, nn.DataParallel):\n                network = network.module\n            network.load_state_dict(torch.load(\n                gen_path), strict=(not self.opt['model']['finetune_norm']))\n            # network.load_state_dict(torch.load(\n            #     gen_path), strict=False)\n            if self.opt['phase'] == 'train':\n                # optimizer\n                opt = torch.load(opt_path)\n                self.optG.load_state_dict(opt['optimizer'])\n                self.begin_step = opt['iter']\n                self.begin_epoch = opt['epoch']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:50.454705Z","iopub.execute_input":"2025-05-14T22:49:50.454959Z","iopub.status.idle":"2025-05-14T22:49:50.476908Z","shell.execute_reply.started":"2025-05-14T22:49:50.454935Z","shell.execute_reply":"2025-05-14T22:49:50.476124Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Training process","metadata":{}},{"cell_type":"code","source":"# model\ndiffusion = SR3(opt)\n# logger.info('Initial Model Finished')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:50.477649Z","iopub.execute_input":"2025-05-14T22:49:50.477905Z","iopub.status.idle":"2025-05-14T22:49:51.048201Z","shell.execute_reply.started":"2025-05-14T22:49:50.477887Z","shell.execute_reply":"2025-05-14T22:49:51.047679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load weights of trained model","metadata":{}},{"cell_type":"code","source":"diffusion.load_network()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:51.049022Z","iopub.execute_input":"2025-05-14T22:49:51.049287Z","iopub.status.idle":"2025-05-14T22:49:51.204435Z","shell.execute_reply.started":"2025-05-14T22:49:51.049262Z","shell.execute_reply":"2025-05-14T22:49:51.203836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_img = test_set[10]['Noisy'].unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:49:51.205145Z","iopub.execute_input":"2025-05-14T22:49:51.205401Z","iopub.status.idle":"2025-05-14T22:50:18.252070Z","shell.execute_reply.started":"2025-05-14T22:49:51.205384Z","shell.execute_reply":"2025-05-14T22:50:18.251277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gt_img = test_set[10]['GT'].unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:01:47.951884Z","iopub.execute_input":"2025-05-14T23:01:47.952183Z","iopub.status.idle":"2025-05-14T23:01:48.067209Z","shell.execute_reply.started":"2025-05-14T23:01:47.952162Z","shell.execute_reply":"2025-05-14T23:01:48.066374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_img.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:50:18.252932Z","iopub.execute_input":"2025-05-14T22:50:18.253119Z","iopub.status.idle":"2025-05-14T22:50:18.257993Z","shell.execute_reply.started":"2025-05-14T22:50:18.253105Z","shell.execute_reply":"2025-05-14T22:50:18.257359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = diffusion.inference(test_img.to(\"cuda\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:50:18.258672Z","iopub.execute_input":"2025-05-14T22:50:18.258857Z","iopub.status.idle":"2025-05-14T22:50:39.354079Z","shell.execute_reply.started":"2025-05-14T22:50:18.258843Z","shell.execute_reply":"2025-05-14T22:50:39.353253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:50:39.354909Z","iopub.execute_input":"2025-05-14T22:50:39.355586Z","iopub.status.idle":"2025-05-14T22:50:39.587606Z","shell.execute_reply.started":"2025-05-14T22:50:39.355556Z","shell.execute_reply":"2025-05-14T22:50:39.586856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import transforms\n\nto_pil = transforms.ToPILImage()\n\n# Assume `tensor` is in shape [C, H, W] and in [0, 1] or [0, 255] range\npil_image = to_pil(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:50:39.588373Z","iopub.execute_input":"2025-05-14T22:50:39.588636Z","iopub.status.idle":"2025-05-14T22:50:43.201163Z","shell.execute_reply.started":"2025-05-14T22:50:39.588613Z","shell.execute_reply":"2025-05-14T22:50:43.200381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pil_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:50:43.201902Z","iopub.execute_input":"2025-05-14T22:50:43.202476Z","iopub.status.idle":"2025-05-14T22:50:43.210208Z","shell.execute_reply.started":"2025-05-14T22:50:43.202450Z","shell.execute_reply":"2025-05-14T22:50:43.209450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch import Tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T22:55:04.421539Z","iopub.execute_input":"2025-05-14T22:55:04.421808Z","iopub.status.idle":"2025-05-14T22:55:04.425718Z","shell.execute_reply.started":"2025-05-14T22:55:04.421790Z","shell.execute_reply":"2025-05-14T22:55:04.424914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(Tensor.cpu(result)[0], cmap='gray')\nplt.axis('off')\nplt.title(\"64x64 Denoised Prediction\")\nplt.show()\n\nplt.imshow(test_img[0][0], cmap='gray')\nplt.axis('off')\nplt.title(\"64x64 Noisy Input\")\nplt.show()\n\nplt.imshow(gt_img[0][0], cmap='gray')\nplt.axis('off')\nplt.title(\"64x64 Ground Truth\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T23:02:14.346376Z","iopub.execute_input":"2025-05-14T23:02:14.346956Z","iopub.status.idle":"2025-05-14T23:02:14.586299Z","shell.execute_reply.started":"2025-05-14T23:02:14.346933Z","shell.execute_reply":"2025-05-14T23:02:14.585479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}