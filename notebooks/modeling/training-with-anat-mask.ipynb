{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe4d9bb",
   "metadata": {},
   "source": [
    "### Denoising fMRI Scans with Diffusion Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011156e6",
   "metadata": {},
   "source": [
    "## Training with Anatomy as Condition and Masked Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ad4b11",
   "metadata": {},
   "source": [
    "This Code is based on the implementation of the Super-Resolution Network SR3: https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement.git\n",
    "\n",
    "Changes were made throughout the full code to convert the super-resolution architecture to a denoising-architecture with an additional condition (Structural MRI / anatomy) and masked loss.\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb96fe65",
   "metadata": {
    "papermill": {
     "duration": 0.004501,
     "end_time": "2025-06-22T02:33:59.260973",
     "exception": false,
     "start_time": "2025-06-22T02:33:59.256472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21817c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:33:59.270901Z",
     "iopub.status.busy": "2025-06-22T02:33:59.270438Z",
     "iopub.status.idle": "2025-06-22T02:34:06.624739Z",
     "shell.execute_reply": "2025-06-22T02:34:06.624105Z"
    },
    "papermill": {
     "duration": 7.360709,
     "end_time": "2025-06-22T02:34:06.626131",
     "exception": false,
     "start_time": "2025-06-22T02:33:59.265422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "from torch.utils.data import Dataset\n",
    "from collections import OrderedDict\n",
    "import functools\n",
    "from torch.nn import init\n",
    "\n",
    "# U-Net\n",
    "import math\n",
    "from inspect import isfunction\n",
    "\n",
    "# Diffusion\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "# learning rate scheduler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# mixed precision training for memory\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# read masks\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dc3296",
   "metadata": {
    "papermill": {
     "duration": 0.004524,
     "end_time": "2025-06-22T02:34:06.635612",
     "exception": false,
     "start_time": "2025-06-22T02:34:06.631088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf127d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:06.646069Z",
     "iopub.status.busy": "2025-06-22T02:34:06.645471Z",
     "iopub.status.idle": "2025-06-22T02:34:06.652953Z",
     "shell.execute_reply": "2025-06-22T02:34:06.652432Z"
    },
    "papermill": {
     "duration": 0.01375,
     "end_time": "2025-06-22T02:34:06.653970",
     "exception": false,
     "start_time": "2025-06-22T02:34:06.640220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"denoising\",\n",
    "    \"phase\": \"train\",\n",
    "    \"gpu_ids\": [0, 1], \n",
    "    \"debug\": False,  \n",
    "    \"enable_wandb\": False,  \n",
    "    \"log_wandb_ckpt\": False,  \n",
    "    \"log_eval\": False,  \n",
    "    \"path\": {\n",
    "        \"log\": \"/kaggle/working/logs\",\n",
    "        \"tb_logger\": \"/kaggle/working/tb_logger\",\n",
    "        \"results\": \"/kaggle/working/results\",\n",
    "        \"checkpoint\": \"/kaggle/working/checkpoint\",\n",
    "        \"resume_state\": None\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-train-1-norm-v3/data/noisy_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-norm-v3/data/noisy_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-norm-v3/data/noisy_func_train_3.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-train-1-norm-v3/data/gt_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-norm-v3/data/gt_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-norm-v3/data/gt_func_train_3.npy'],\n",
    "            \"mask_data_paths\": ['/kaggle/input/brain-mask-01/brain_mask_01.nii',\n",
    "                '/kaggle/input/brain-mask-dd/brain_mask_dd.nii',\n",
    "                '/kaggle/input/brain-mask-gg/brain_mask_gg.nii'],\n",
    "            \"anat_data_paths\": ['/kaggle/input/coregistered-anatomy/coregistered_outputs/sub-01_smri_coregistered.nii',\n",
    "                '/kaggle/input/coregistered-anatomy/coregistered_outputs/sub-dd_smri_coregistered.nii',\n",
    "                '/kaggle/input/coregistered-anatomy/coregistered_outputs/sub-gg_smri_coregistered.nii'],\n",
    "            \"batch_size\": 2,\n",
    "            \"num_workers\": 4,\n",
    "            \"use_shuffle\": True\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-test-norm-v3/data/noisy_func_test.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-test-norm-v3/data/gt_func_test.npy'],\n",
    "            \"mask_data_paths\": ['/kaggle/input/brain-mask-uu/brain_mask_uu.nii'],\n",
    "            \"anat_data_paths\": ['/kaggle/input/coregistered-anatomy/coregistered_outputs/sub-uu_smri_coregistered.nii'],\n",
    "            \"batch_size\": 2,\n",
    "            \"num_workers\": 4,\n",
    "        }\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\",\n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 3,\n",
    "            \"out_channel\": 1,\n",
    "            \"inner_channel\": 32,\n",
    "            \"norm_groups\": 16,\n",
    "            \"channel_multiplier\": [1, 2, 4, 8],\n",
    "            \"attn_res\": [8],\n",
    "            \"res_blocks\": 1,\n",
    "            \"dropout\": 0.1\n",
    "        },\n",
    "        \"beta_schedule\": {\n",
    "            \"train\": {\n",
    "                \"schedule\": \"cosine\",\n",
    "                \"n_timestep\": 1000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"schedule\": \"cosine\",\n",
    "                \"n_timestep\": 1000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 64,\n",
    "            \"channels\": 1,\n",
    "            \"conditional\": True\n",
    "        }\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"n_iter\": 27000,\n",
    "        \"val_freq\": 1e4,\n",
    "        \"save_checkpoint_freq\": 1000,\n",
    "        \"print_freq\": 100,\n",
    "        \"accumulation_steps\": 2,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"lr\": 5e-6\n",
    "        },\n",
    "        \"ema_scheduler\": {\n",
    "            \"step_start_ema\": 9000,\n",
    "            \"update_ema_every\": 10,\n",
    "            \"ema_decay\": 0.999\n",
    "        }\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        \"project\": \"distributed_high_sr_ffhq\"\n",
    "    },\n",
    "    \"config_file\": \"config/sr_sr3_16_128.json\"  # from CLI\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918771c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:06.663854Z",
     "iopub.status.busy": "2025-06-22T02:34:06.663672Z",
     "iopub.status.idle": "2025-06-22T02:34:06.667916Z",
     "shell.execute_reply": "2025-06-22T02:34:06.667239Z"
    },
    "papermill": {
     "duration": 0.010534,
     "end_time": "2025-06-22T02:34:06.669076",
     "exception": false,
     "start_time": "2025-06-22T02:34:06.658542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(opt['path']['log'], exist_ok=True)\n",
    "os.makedirs(opt['path']['tb_logger'], exist_ok=True)\n",
    "os.makedirs(opt['path']['results'], exist_ok=True)\n",
    "os.makedirs(opt['path']['checkpoint'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ec064",
   "metadata": {
    "papermill": {
     "duration": 0.004337,
     "end_time": "2025-06-22T02:34:06.677957",
     "exception": false,
     "start_time": "2025-06-22T02:34:06.673620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6923c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:06.688198Z",
     "iopub.status.busy": "2025-06-22T02:34:06.687734Z",
     "iopub.status.idle": "2025-06-22T02:34:06.695587Z",
     "shell.execute_reply": "2025-06-22T02:34:06.695051Z"
    },
    "papermill": {
     "duration": 0.014241,
     "end_time": "2025-06-22T02:34:06.696623",
     "exception": false,
     "start_time": "2025-06-22T02:34:06.682382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logging\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def dict2str(opt, indent_l=1):\n",
    "    '''dict to string for logger'''\n",
    "    msg = ''\n",
    "    for k, v in opt.items():\n",
    "        if isinstance(v, dict):\n",
    "            msg += ' ' * (indent_l * 2) + k + ':[\\n'\n",
    "            msg += dict2str(v, indent_l + 1)\n",
    "            msg += ' ' * (indent_l * 2) + ']\\n'\n",
    "        else:\n",
    "            msg += ' ' * (indent_l * 2) + k + ': ' + str(v) + '\\n'\n",
    "    return msg\n",
    "\n",
    "def setup_logger(logger_name, root, phase, level=logging.INFO, screen=False):\n",
    "    '''set up logger'''\n",
    "    l = logging.getLogger(logger_name)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s.%(msecs)03d - %(levelname)s: %(message)s', datefmt='%y-%m-%d %H:%M:%S')\n",
    "    log_file = os.path.join(root, '{}.log'.format(phase))\n",
    "    fh = logging.FileHandler(log_file, mode='w')\n",
    "    fh.setFormatter(formatter)\n",
    "    l.setLevel(level)\n",
    "    l.addHandler(fh)\n",
    "    if screen:\n",
    "        sh = logging.StreamHandler()\n",
    "        sh.setFormatter(formatter)\n",
    "        l.addHandler(sh)\n",
    "\n",
    "\n",
    "setup_logger(None, opt['path']['log'],\n",
    "                    'train', level=logging.INFO, screen=True)\n",
    "setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "logger = logging.getLogger('base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8c39c",
   "metadata": {
    "papermill": {
     "duration": 0.004336,
     "end_time": "2025-06-22T02:34:06.705738",
     "exception": false,
     "start_time": "2025-06-22T02:34:06.701402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb219e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:06.715620Z",
     "iopub.status.busy": "2025-06-22T02:34:06.715400Z",
     "iopub.status.idle": "2025-06-22T02:34:06.722801Z",
     "shell.execute_reply": "2025-06-22T02:34:06.722117Z"
    },
    "papermill": {
     "duration": 0.013523,
     "end_time": "2025-06-22T02:34:06.723778",
     "exception": false,
     "start_time": "2025-06-22T02:34:06.710255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, noisy_images_paths: list, gt_images_paths: list, mask_images_paths: list, anat_images_paths: list):\n",
    "        \"\"\"Initialize fMRI dataset for denoising with memory-efficient loading.\"\"\"\n",
    "        self.noisy_paths = noisy_images_paths\n",
    "        self.gt_paths = gt_images_paths\n",
    "        self.mask_paths = mask_images_paths\n",
    "        self.anat_paths = anat_images_paths\n",
    "\n",
    "        # Pre-load the anatomy and mask volumes into a list in memory\n",
    "        self.anat_volumes = [nib.load(path).get_fdata() for path in anat_images_paths]\n",
    "        self.mask_volumes = [nib.load(path).get_fdata() for path in mask_images_paths]\n",
    "\n",
    "    \n",
    "        self.file_slice_mapping = []\n",
    "        for i, path in enumerate(noisy_images_paths):\n",
    "            data_shape = np.load(path, mmap_mode='r').shape\n",
    "            for t_idx in range(data_shape[3]):\n",
    "                self.file_slice_mapping.append((i, t_idx))\n",
    "        self.data_len = len(self.file_slice_mapping)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_idx, t_idx = self.file_slice_mapping[index]\n",
    "        \n",
    "        noisy_file_path = self.noisy_paths[file_idx]\n",
    "        gt_file_path = self.gt_paths[file_idx]\n",
    "        \n",
    "        noisy_volume = np.load(noisy_file_path, mmap_mode='r')\n",
    "        gt_volume = np.load(gt_file_path, mmap_mode='r')\n",
    "        mask_volume = self.mask_volumes[file_idx]\n",
    "        anat_volume = self.anat_volumes[file_idx]\n",
    "        \n",
    "        noisy_slice = noisy_volume[:, :, :, t_idx].copy()\n",
    "        gt_slice = gt_volume[:, :, :, t_idx].copy()\n",
    "        mask_slice = mask_volume.copy()\n",
    "        anat_slice = anat_volume.copy()\n",
    "\n",
    "        def to_tensor(data):\n",
    "            return torch.tensor(data).float().unsqueeze(0).permute(-1, 0, 1, 2)\n",
    "\n",
    "        return {\n",
    "            'GT': to_tensor(gt_slice),\n",
    "            'Noisy': to_tensor(noisy_slice),\n",
    "            'Mask': to_tensor(mask_slice),\n",
    "            'Anat': to_tensor(anat_slice),\n",
    "            'Index': index\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103580c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:06.735331Z",
     "iopub.status.busy": "2025-06-22T02:34:06.734988Z",
     "iopub.status.idle": "2025-06-22T02:34:06.740054Z",
     "shell.execute_reply": "2025-06-22T02:34:06.739424Z"
    },
    "papermill": {
     "duration": 0.012946,
     "end_time": "2025-06-22T02:34:06.741231",
     "exception": false,
     "start_time": "2025-06-22T02:34:06.728285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_merge_batches(batch):\n",
    "    \"\"\"Correctly concatenates tensors from a list of dictionaries.\"\"\"\n",
    "    return {\n",
    "        'Noisy': torch.cat([item['Noisy'] for item in batch], dim=0),\n",
    "        'GT': torch.cat([item['GT'] for item in batch], dim=0),\n",
    "        'Mask': torch.cat([item['Mask'] for item in batch], dim=0),\n",
    "        'Anat': torch.cat([item['Anat'] for item in batch], dim=0),\n",
    "        'Index': [item['Index'] for item in batch]\n",
    "    }\n",
    "\n",
    "def create_dataloader(dataset, dataset_opt, phase):\n",
    "    \"\"\"Creates dataloader for training or testing.\"\"\"\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=dataset_opt['batch_size'],\n",
    "        shuffle=dataset_opt.get('use_shuffle', False),\n",
    "        num_workers=dataset_opt.get('num_workers', 1),\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_merge_batches\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ea3b03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:06.751035Z",
     "iopub.status.busy": "2025-06-22T02:34:06.750671Z",
     "iopub.status.idle": "2025-06-22T02:34:07.055928Z",
     "shell.execute_reply": "2025-06-22T02:34:07.055194Z"
    },
    "papermill": {
     "duration": 0.311428,
     "end_time": "2025-06-22T02:34:07.057145",
     "exception": false,
     "start_time": "2025-06-22T02:34:06.745717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 02:34:06.968 - INFO: Training dataset with 900 instances created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 02:34:07.052 - INFO: Test dataset with 300 instances created.\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset and dataloader\n",
    "train_set = PairwiseDataset(\n",
    "    opt['datasets']['train']['noisy_data_paths'], \n",
    "    opt['datasets']['train']['gt_data_paths'],\n",
    "    opt['datasets']['train']['mask_data_paths'],\n",
    "    opt['datasets']['train']['anat_data_paths']\n",
    ")\n",
    "train_loader = create_dataloader(train_set, opt['datasets']['train'], 'train')\n",
    "logger.info(f\"Training dataset with {len(train_set)} instances created.\")\n",
    "\n",
    "test_set = PairwiseDataset(\n",
    "    opt['datasets']['test']['noisy_data_paths'], \n",
    "    opt['datasets']['test']['gt_data_paths'],\n",
    "    opt['datasets']['test']['mask_data_paths'],\n",
    "    opt['datasets']['test']['anat_data_paths']\n",
    ")\n",
    "test_loader = create_dataloader(test_set, opt['datasets']['test'], 'test')\n",
    "logger.info(f\"Test dataset with {len(test_set)} instances created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b61839c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:07.083363Z",
     "iopub.status.busy": "2025-06-22T02:34:07.083115Z",
     "iopub.status.idle": "2025-06-22T02:34:40.831193Z",
     "shell.execute_reply": "2025-06-22T02:34:40.830560Z"
    },
    "papermill": {
     "duration": 33.754966,
     "end_time": "2025-06-22T02:34:40.832588",
     "exception": false,
     "start_time": "2025-06-22T02:34:07.077622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noisy_slice = train_set[400][\"Noisy\"]\n",
    "gt_slice = train_set[400][\"GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489217f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:40.868896Z",
     "iopub.status.busy": "2025-06-22T02:34:40.868613Z",
     "iopub.status.idle": "2025-06-22T02:34:41.340702Z",
     "shell.execute_reply": "2025-06-22T02:34:41.340056Z"
    },
    "papermill": {
     "duration": 0.481591,
     "end_time": "2025-06-22T02:34:41.341857",
     "exception": false,
     "start_time": "2025-06-22T02:34:40.860266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7e0d907fcb10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization of example slice\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot ground truth image\n",
    "axes[0].imshow(noisy_slice[0,0,:,:], cmap='gray')\n",
    "axes[1].imshow(gt_slice[0,0,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42b93e",
   "metadata": {
    "papermill": {
     "duration": 0.005122,
     "end_time": "2025-06-22T02:34:41.352769",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.347647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50c3fe",
   "metadata": {
    "papermill": {
     "duration": 0.00518,
     "end_time": "2025-06-22T02:34:41.363498",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.358318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ba4b52c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:41.374856Z",
     "iopub.status.busy": "2025-06-22T02:34:41.374654Z",
     "iopub.status.idle": "2025-06-22T02:34:41.378160Z",
     "shell.execute_reply": "2025-06-22T02:34:41.377650Z"
    },
    "papermill": {
     "duration": 0.010435,
     "end_time": "2025-06-22T02:34:41.379125",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.368690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generic functions\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80dc02c",
   "metadata": {},
   "source": [
    "U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9f12b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:41.390904Z",
     "iopub.status.busy": "2025-06-22T02:34:41.390717Z",
     "iopub.status.idle": "2025-06-22T02:34:41.414503Z",
     "shell.execute_reply": "2025-06-22T02:34:41.413966Z"
    },
    "papermill": {
     "duration": 0.030967,
     "end_time": "2025-06-22T02:34:41.415552",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.384585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PositionalEncoding Source https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        count = self.dim // 2\n",
    "        step = torch.arange(count, dtype=noise_level.dtype,\n",
    "                            device=noise_level.device) / count\n",
    "        encoding = noise_level.unsqueeze(\n",
    "            1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n",
    "        encoding = torch.cat(\n",
    "            [torch.sin(encoding), torch.cos(encoding)], dim=-1)\n",
    "        return encoding\n",
    "\n",
    "\n",
    "class FeatureWiseAffine(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_affine_level=False):\n",
    "        super(FeatureWiseAffine, self).__init__()\n",
    "        self.use_affine_level = use_affine_level\n",
    "        self.noise_func = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, noise_embed):\n",
    "        batch = x.shape[0]\n",
    "        if self.use_affine_level:\n",
    "            gamma, beta = self.noise_func(noise_embed).view(\n",
    "                batch, -1, 1, 1).chunk(2, dim=1)\n",
    "            x = (1 + gamma) * x + beta\n",
    "        else:\n",
    "            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.up(x))\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# building block modules\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=32, dropout=0):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, dim),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32):\n",
    "        super().__init__()\n",
    "        self.noise_func = FeatureWiseAffine(\n",
    "            noise_level_emb_dim, dim_out, use_affine_level)\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=norm_groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout)\n",
    "        self.res_conv = nn.Conv2d(\n",
    "            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        b, c, h, w = x.shape\n",
    "        h = self.block1(x)\n",
    "        h = self.noise_func(h, time_emb)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channel, n_head=1, norm_groups=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.norm = nn.GroupNorm(norm_groups, in_channel)\n",
    "        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch, channel, height, width = input.shape\n",
    "        n_head = self.n_head\n",
    "        head_dim = channel // n_head\n",
    "\n",
    "        norm = self.norm(input)\n",
    "        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n",
    "        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n",
    "\n",
    "        attn = torch.einsum(\n",
    "            \"bnchw, bncyx -> bnhwyx\", query, key\n",
    "        ).contiguous() / math.sqrt(channel)\n",
    "        attn = attn.view(batch, n_head, height, width, -1)\n",
    "        attn = torch.softmax(attn, -1)\n",
    "        attn = attn.view(batch, n_head, height, width, height, width)\n",
    "\n",
    "        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n",
    "        out = self.out(out.view(batch, channel, height, width))\n",
    "\n",
    "        return out + input\n",
    "\n",
    "\n",
    "class ResnetBlocWithAttn(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False):\n",
    "        super().__init__()\n",
    "        self.with_attn = with_attn\n",
    "        self.res_block = ResnetBlock(\n",
    "            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout)\n",
    "        if with_attn:\n",
    "            self.attn = SelfAttention(dim_out, norm_groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        x = self.res_block(x, time_emb)\n",
    "        if(self.with_attn):\n",
    "            x = self.attn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=6,\n",
    "        out_channel=3,\n",
    "        inner_channel=32,\n",
    "        norm_groups=32,\n",
    "        channel_mults=(1, 2, 4, 8, 8),\n",
    "        attn_res=(8),\n",
    "        res_blocks=3,\n",
    "        dropout=0,\n",
    "        with_noise_level_emb=True,\n",
    "        image_size=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if with_noise_level_emb:\n",
    "            noise_level_channel = inner_channel\n",
    "            self.noise_level_mlp = nn.Sequential(\n",
    "                PositionalEncoding(inner_channel),\n",
    "                nn.Linear(inner_channel, inner_channel * 4),\n",
    "                Swish(),\n",
    "                nn.Linear(inner_channel * 4, inner_channel)\n",
    "            )\n",
    "        else:\n",
    "            noise_level_channel = None\n",
    "            self.noise_level_mlp = None\n",
    "\n",
    "        num_mults = len(channel_mults)\n",
    "        pre_channel = inner_channel\n",
    "        feat_channels = [pre_channel]\n",
    "        now_res = image_size\n",
    "        downs = [nn.Conv2d(in_channel, inner_channel,\n",
    "                           kernel_size=3, padding=1)]\n",
    "        for ind in range(num_mults):\n",
    "            is_last = (ind == num_mults - 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks):\n",
    "                downs.append(ResnetBlocWithAttn(\n",
    "                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn))\n",
    "                feat_channels.append(channel_mult)\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                downs.append(Downsample(pre_channel))\n",
    "                feat_channels.append(pre_channel)\n",
    "                now_res = now_res//2\n",
    "        self.downs = nn.ModuleList(downs)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=True),\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=False)\n",
    "        ])\n",
    "\n",
    "        ups = []\n",
    "        for ind in reversed(range(num_mults)):\n",
    "            is_last = (ind < 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks+1):\n",
    "                ups.append(ResnetBlocWithAttn(\n",
    "                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                        dropout=dropout, with_attn=use_attn))\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                ups.append(Upsample(pre_channel))\n",
    "                now_res = now_res*2\n",
    "\n",
    "        self.ups = nn.ModuleList(ups)\n",
    "\n",
    "        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        t = self.noise_level_mlp(time) if exists(\n",
    "            self.noise_level_mlp) else None\n",
    "\n",
    "        feats = []\n",
    "    \n",
    "        \n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        for layer in self.ups:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(torch.cat((x, feats.pop()), dim=1), t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a05568",
   "metadata": {},
   "source": [
    "Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a813e2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:41.427634Z",
     "iopub.status.busy": "2025-06-22T02:34:41.427449Z",
     "iopub.status.idle": "2025-06-22T02:34:41.449504Z",
     "shell.execute_reply": "2025-06-22T02:34:41.448904Z"
    },
    "papermill": {
     "duration": 0.029491,
     "end_time": "2025-06-22T02:34:41.450556",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.421065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Diffusion ###\n",
    "def _warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n",
    "    betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    warmup_time = int(n_timestep * warmup_frac)\n",
    "    betas[:warmup_time] = np.linspace(\n",
    "        linear_start, linear_end, warmup_time, dtype=np.float64)\n",
    "    return betas\n",
    "\n",
    "\n",
    "def make_beta_schedule(schedule, n_timestep, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n",
    "    if schedule == 'quad':\n",
    "        betas = np.linspace(linear_start ** 0.5, linear_end ** 0.5,\n",
    "                            n_timestep, dtype=np.float64) ** 2\n",
    "    elif schedule == 'linear':\n",
    "        betas = np.linspace(linear_start, linear_end,\n",
    "                            n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'warmup10':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.1)\n",
    "    elif schedule == 'warmup50':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.5)\n",
    "    elif schedule == 'const':\n",
    "        betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        betas = 1. / np.linspace(n_timestep,\n",
    "                                 1, n_timestep, dtype=np.float64)\n",
    "    elif schedule == \"cosine\":\n",
    "        timesteps = (\n",
    "            torch.arange(n_timestep + 1, dtype=torch.float64) /\n",
    "            n_timestep + cosine_s\n",
    "        )\n",
    "        alphas = timesteps / (1 + cosine_s) * math.pi / 2\n",
    "        alphas = torch.cos(alphas).pow(2)\n",
    "        alphas = alphas / alphas[0]\n",
    "        betas = 1 - alphas[1:] / alphas[:-1]\n",
    "        betas = betas.clamp(max=0.999)\n",
    "    else:\n",
    "        raise NotImplementedError(schedule)\n",
    "    return betas\n",
    "\n",
    "\n",
    "# gaussian diffusion trainer class\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        denoise_fn,\n",
    "        image_size,\n",
    "        channels=3,\n",
    "        loss_type='l1',\n",
    "        conditional=True,\n",
    "        schedule_opt=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.denoise_fn = denoise_fn\n",
    "        self.loss_type = loss_type\n",
    "        self.conditional = conditional\n",
    "        if schedule_opt is not None:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def set_loss(self, device):\n",
    "        if self.loss_type == 'l1':\n",
    "            self.loss_func = nn.L1Loss(reduction='sum').to(device)\n",
    "        elif self.loss_type == 'l2':\n",
    "            self.loss_func = nn.MSELoss(reduction='sum').to(device)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, device):\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32, device=device)\n",
    "\n",
    "        betas = make_beta_schedule(\n",
    "            schedule=schedule_opt['schedule'],\n",
    "            n_timestep=schedule_opt['n_timestep'],\n",
    "            linear_start=schedule_opt['linear_start'],\n",
    "            linear_end=schedule_opt['linear_end'])\n",
    "        betas = betas.detach().cpu().numpy() if isinstance(\n",
    "            betas, torch.Tensor) else betas\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n",
    "\n",
    "        \n",
    "        sqrt_alphas_cumprod_prev_np = np.sqrt(np.append(1., alphas_cumprod))\n",
    "        self.register_buffer('sqrt_alphas_cumprod_prev', to_torch(sqrt_alphas_cumprod_prev_np))\n",
    "\n",
    "        timesteps, = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.register_buffer('betas', to_torch(betas))\n",
    "        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n",
    "        self.register_buffer('alphas_cumprod_prev',\n",
    "                             to_torch(alphas_cumprod_prev))\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer('sqrt_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. - alphas_cumprod)))\n",
    "        self.register_buffer('log_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.log(1. - alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recip_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recipm1_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = betas * \\\n",
    "            (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "        self.register_buffer('posterior_variance',\n",
    "                             to_torch(posterior_variance))\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "        self.register_buffer('posterior_log_variance_clipped', to_torch(\n",
    "            np.log(np.maximum(posterior_variance, 1e-20))))\n",
    "        self.register_buffer('posterior_mean_coef1', to_torch(\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n",
    "        self.register_buffer('posterior_mean_coef2', to_torch(\n",
    "            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return self.sqrt_recip_alphas_cumprod[t] * x_t - \\\n",
    "            self.sqrt_recipm1_alphas_cumprod[t] * noise\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = self.posterior_mean_coef1[t] * \\\n",
    "            x_start + self.posterior_mean_coef2[t] * x_t\n",
    "        posterior_log_variance_clipped = self.posterior_log_variance_clipped[t]\n",
    "        return posterior_mean, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, x, t, clip_denoised: bool, condition_x=None):\n",
    "        batch_size = x.shape[0]\n",
    "        noise_level = torch.FloatTensor(\n",
    "            [self.sqrt_alphas_cumprod_prev[t+1]]).repeat(batch_size, 1).to(x.device)\n",
    "        if condition_x is not None:\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(torch.cat([condition_x, x], dim=1), noise_level))\n",
    "        else:\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(x, noise_level))\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1., 1.)\n",
    "\n",
    "        model_mean, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t)\n",
    "        return model_mean, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, clip_denoised=True, condition_x=None):\n",
    "        model_mean, model_log_variance = self.p_mean_variance(\n",
    "            x=x, t=t, clip_denoised=clip_denoised, condition_x=condition_x)\n",
    "        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "        return model_mean + noise * (0.5 * model_log_variance).exp()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, x_in, continous=False):\n",
    "        device = self.betas.device\n",
    "        sample_inter = (1 | (self.num_timesteps//10))\n",
    "        if not self.conditional:\n",
    "            shape = x_in\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = img\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        else:\n",
    "            x = x_in\n",
    "            shape = x.shape\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = x\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i, condition_x=x)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        if continous:\n",
    "            return ret_img\n",
    "        else:\n",
    "            return ret_img[-1]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        image_size = self.image_size\n",
    "        channels = self.channels\n",
    "        return self.p_sample_loop((batch_size, channels, image_size, image_size), continous)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def super_resolution(self, x_in, continous=False):\n",
    "        return self.p_sample_loop(x_in, continous)\n",
    "\n",
    "    \n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        return (self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1) * x_start +\n",
    "                self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1) * noise)\n",
    "\n",
    "# In the GaussianDiffusion class\n",
    "    def p_losses(self, x_in, noise=None):\n",
    "        x_start, mask = x_in['GT'], x_in['Mask']\n",
    "        b, c, h, w = x_start.shape\n",
    "        t = torch.randint(0, self.num_timesteps, (b,), device=x_start.device).long()\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        x_noisy = self.q_sample(x_start=x_start, t=t, noise=noise)\n",
    "        \n",
    "        if self.conditional:\n",
    "            anat = x_in['Anat']\n",
    "            # Ensure anatomy tensor is repeated to match the batch size\n",
    "            if anat.shape[0] != b:\n",
    "                anat = anat.repeat(b // anat.shape[0], 1, 1, 1)\n",
    "                \n",
    "            model_input = torch.cat([x_in['Noisy'], anat, x_noisy], dim=1)\n",
    "            x_recon = self.denoise_fn(model_input, t)\n",
    "        else:\n",
    "            x_recon = self.denoise_fn(x_noisy, t)\n",
    "        \n",
    "        if mask.shape[0] != b:\n",
    "            mask = mask.repeat(b // mask.shape[0], 1, 1, 1)\n",
    "        \n",
    "        loss = self.loss_func(noise * mask, x_recon * mask)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.p_losses(x, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11202ea",
   "metadata": {
    "papermill": {
     "duration": 0.005767,
     "end_time": "2025-06-22T02:34:41.461728",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.455961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3899f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:41.473826Z",
     "iopub.status.busy": "2025-06-22T02:34:41.473648Z",
     "iopub.status.idle": "2025-06-22T02:34:41.484508Z",
     "shell.execute_reply": "2025-06-22T02:34:41.483994Z"
    },
    "papermill": {
     "duration": 0.018047,
     "end_time": "2025-06-22T02:34:41.485471",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.467424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m, std=0.02):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, std)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m, scale=1):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_orthogonal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='kaiming', scale=1, std=0.02):\n",
    "    logger.info('Initialization method [{:s}]'.format(init_type))\n",
    "    if init_type == 'normal':\n",
    "        weights_init_normal_ = functools.partial(weights_init_normal, std=std)\n",
    "        net.apply(weights_init_normal_)\n",
    "    elif init_type == 'kaiming':\n",
    "        weights_init_kaiming_ = functools.partial(\n",
    "            weights_init_kaiming, scale=scale)\n",
    "        net.apply(weights_init_kaiming_)\n",
    "    elif init_type == 'orthogonal':\n",
    "        net.apply(weights_init_orthogonal)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'initialization method [{:s}] not implemented'.format(init_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583fb41",
   "metadata": {},
   "source": [
    "Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00e5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "def define_G(opt):\n",
    "    model_opt = opt['model']\n",
    "    if ('norm_groups' not in model_opt['unet']) or model_opt['unet']['norm_groups'] is None:\n",
    "        model_opt['unet']['norm_groups']=32\n",
    "    model = UNet(\n",
    "        in_channel=model_opt['unet']['in_channel'],\n",
    "        out_channel=model_opt['unet']['out_channel'],\n",
    "        norm_groups=model_opt['unet']['norm_groups'],\n",
    "        inner_channel=model_opt['unet']['inner_channel'],\n",
    "        channel_mults=model_opt['unet']['channel_multiplier'],\n",
    "        attn_res=model_opt['unet']['attn_res'],\n",
    "        res_blocks=model_opt['unet']['res_blocks'],\n",
    "        dropout=model_opt['unet']['dropout'],\n",
    "        image_size=model_opt['diffusion']['image_size']\n",
    "    )\n",
    "    netG = GaussianDiffusion(\n",
    "        model,\n",
    "        image_size=model_opt['diffusion']['image_size'],\n",
    "        channels=model_opt['diffusion']['channels'],\n",
    "        loss_type='l2',    # L1 or L2\n",
    "        conditional=model_opt['diffusion']['conditional'],\n",
    "        schedule_opt=model_opt['beta_schedule']['train']\n",
    "    )\n",
    "    if opt['phase'] == 'train':\n",
    "        # init_weights(netG, init_type='kaiming', scale=0.1)\n",
    "        init_weights(netG, init_type='orthogonal')\n",
    "    if opt['gpu_ids']:\n",
    "        assert torch.cuda.is_available()\n",
    "    # if opt['gpu_ids'] and opt['distributed']:\n",
    "    #     assert torch.cuda.is_available()\n",
    "    #     netG = nn.DataParallel(netG)\n",
    "    return netG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5542433",
   "metadata": {
    "papermill": {
     "duration": 0.006023,
     "end_time": "2025-06-22T02:34:41.497430",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.491407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81df48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:41.509488Z",
     "iopub.status.busy": "2025-06-22T02:34:41.509311Z",
     "iopub.status.idle": "2025-06-22T02:34:41.538431Z",
     "shell.execute_reply": "2025-06-22T02:34:41.537824Z"
    },
    "papermill": {
     "duration": 0.036618,
     "end_time": "2025-06-22T02:34:41.539648",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.503030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SR3():\n",
    "    def __init__(self, opt):       \n",
    "        self.opt = opt\n",
    "        self.device = torch.device(\n",
    "            'cuda' if opt['gpu_ids'] is not None else 'cpu')\n",
    "\n",
    "        # mixed precision training\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        self.begin_step = 0\n",
    "        self.begin_epoch = 0\n",
    "        \n",
    "        # define network and load pretrained models\n",
    "        self.netG = self.set_device(define_G(opt))\n",
    "        self.schedule_phase = None\n",
    "        \n",
    "        # EMA implementation\n",
    "        self.netG_EMA = copy.deepcopy(self.netG)\n",
    "        self.netG_EMA.eval()\n",
    "        for p in self.netG_EMA.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # EMA parameters from config\n",
    "        self.ema_scheduler = self.opt['train']['ema_scheduler']\n",
    "        self.ema_decay = self.ema_scheduler['ema_decay']\n",
    "        self.step_start_ema = self.ema_scheduler['step_start_ema']\n",
    "        self.update_ema_every = self.ema_scheduler['update_ema_every']\n",
    "        \n",
    "        # set loss and load resume state\n",
    "        self.set_loss()\n",
    "        self.set_new_noise_schedule(\n",
    "            opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "        if self.opt['phase'] == 'train':\n",
    "            self.netG.train()\n",
    "\n",
    "            if opt['model']['finetune_norm']:\n",
    "                optim_params = []\n",
    "                for k, v in self.netG.named_parameters():\n",
    "                    v.requires_grad = False\n",
    "                    if k.find('transformer') >= 0:\n",
    "                        v.requires_grad = True\n",
    "                        v.data.zero_()\n",
    "                        optim_params.append(v)\n",
    "                        logger.info(\n",
    "                            'Params [{:s}] initialized to 0 and will optimize.'.format(k))\n",
    "            else:\n",
    "                optim_params = list(self.netG.parameters())\n",
    "\n",
    "\n",
    "            try:\n",
    "                self.optG = torch.optim.Adam(\n",
    "                    optim_params, lr=opt['train'][\"optimizer\"][\"lr\"], fused=True\n",
    "                )\n",
    "                logger.info(\"Using fused Adam optimizer for potential speedup.\")\n",
    "            except:\n",
    "                self.optG = torch.optim.Adam(\n",
    "                    optim_params, lr=opt['train'][\"optimizer\"][\"lr\"]\n",
    "                )\n",
    "\n",
    "\n",
    "            #learning rate scheduler\n",
    "            self.schedulerG = lr_scheduler.CosineAnnealingLR(\n",
    "                self.optG, T_max=self.opt['train']['n_iter'], eta_min=1e-6)\n",
    "            \n",
    "            self.log_dict = OrderedDict()\n",
    "            \n",
    "        self.load_network()\n",
    "        self.print_network()\n",
    "\n",
    "    def set_device(self, x):\n",
    "        if isinstance(x, dict):\n",
    "            for key, item in x.items():\n",
    "                if item is not None and type(item)==torch.Tensor:\n",
    "                    x[key] = item.to(self.device)\n",
    "        elif isinstance(x, list):\n",
    "            for item in x:\n",
    "                if item is not None:\n",
    "                    item = item.to(self.device)\n",
    "        else:\n",
    "            x = x.to(self.device)\n",
    "        return x\n",
    "\n",
    "    def get_network_description(self, network):\n",
    "        '''Get the string and total parameters of the network'''\n",
    "        if isinstance(network, nn.DataParallel):\n",
    "            network = network.module\n",
    "        s = str(network)\n",
    "        n = sum(map(lambda x: x.numel(), network.parameters()))\n",
    "        return s, n\n",
    "\n",
    "    def feed_data(self, data):\n",
    "        self.data = self.set_device(data)\n",
    "\n",
    "    def optimize_parameters(self, current_step):\n",
    "        self.optG.zero_grad()\n",
    "\n",
    "        # mixed precision\n",
    "        with torch.cuda.amp.autocast():\n",
    "            l_pix = self.netG(self.data)\n",
    "            b, c, h, w = self.data['GT'].shape\n",
    "            l_pix = l_pix.sum()/int(b*c*h*w)\n",
    "\n",
    "        self.scaler.scale(l_pix).backward()\n",
    "\n",
    "        self.scaler.unscale_(self.optG)\n",
    "        torch.nn.utils.clip_grad_norm_(self.netG.parameters(), max_norm=1.0)\n",
    "\n",
    "        self.scaler.step(self.optG)\n",
    "        self.scaler.update()  \n",
    "\n",
    "        self._update_ema(current_step)\n",
    "        \n",
    "        #scheduler step\n",
    "        self.schedulerG.step()\n",
    "\n",
    "        # set log\n",
    "        self.log_dict['l_pix'] = l_pix.item()\n",
    "\n",
    "        return l_pix.item()\n",
    "\n",
    "    def evaluate_loss(self, data):\n",
    "        \"\"\"Calculates the diffusion loss using the EMA model.\"\"\"\n",
    "        self.netG_EMA.eval()\n",
    "        with torch.no_grad():\n",
    "            self.feed_data(data)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                l_pix = self.netG_EMA(self.data) \n",
    "                b, c, h, w = self.data['GT'].shape\n",
    "                l_pix = l_pix.sum() / int(b * c * h * w)\n",
    "        \n",
    "        return l_pix.item()\n",
    "    \n",
    "    def test(self, continous=False):\n",
    "        self.netG_EMA.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.netG_EMA, nn.DataParallel):\n",
    "                self.SR = self.netG_EMA.module.super_resolution(\n",
    "                    self.data['SR'], continous)\n",
    "            else:\n",
    "                self.SR = self.netG_EMA.super_resolution(\n",
    "                    self.data['SR'], continous)\n",
    "\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.SR = self.netG.module.sample(batch_size, continous)\n",
    "            else:\n",
    "                self.SR = self.netG.sample(batch_size, continous)\n",
    "        self.netG.train()\n",
    "\n",
    "    def set_loss(self):\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            self.netG.module.set_loss(self.device)\n",
    "        else:\n",
    "            self.netG.set_loss(self.device)\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, schedule_phase='train'):\n",
    "        if self.schedule_phase is None or self.schedule_phase != schedule_phase:\n",
    "            self.schedule_phase = schedule_phase\n",
    "            \n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.netG.module.set_new_noise_schedule(\n",
    "                    schedule_opt, self.device)\n",
    "            else:\n",
    "                self.netG.set_new_noise_schedule(schedule_opt, self.device)\n",
    "                \n",
    "            if isinstance(self.netG_EMA, nn.DataParallel):\n",
    "                self.netG_EMA.module.set_new_noise_schedule(\n",
    "                    schedule_opt, self.device)\n",
    "            else:\n",
    "                self.netG_EMA.set_new_noise_schedule(schedule_opt, self.device)\n",
    "\n",
    "\n",
    "    def _update_ema(self, current_step):\n",
    "        netG_for_state_dict = self.netG._orig_mod if hasattr(self.netG, '_orig_mod') else self.netG\n",
    "    \n",
    "        if current_step < self.step_start_ema:\n",
    "            self.netG_EMA.load_state_dict(netG_for_state_dict.state_dict())\n",
    "            return\n",
    "    \n",
    "        if current_step % self.update_ema_every == 0:\n",
    "            with torch.no_grad():\n",
    "                ema_params = self.netG_EMA.state_dict()\n",
    "                model_params = netG_for_state_dict.state_dict()\n",
    "                \n",
    "                for key in model_params:\n",
    "                    if key in ema_params:\n",
    "                        ema_params[key].mul_(self.ema_decay).add_(model_params[key], alpha=1 - self.ema_decay)\n",
    "\n",
    "                \n",
    "    def get_current_log(self):\n",
    "        return self.log_dict\n",
    "\n",
    "    def get_current_visuals(self, need_LR=True, sample=False):\n",
    "        out_dict = OrderedDict()\n",
    "        if sample:\n",
    "            out_dict['SAM'] = self.SR.detach().float().cpu()\n",
    "        else:\n",
    "            out_dict['SR'] = self.SR.detach().float().cpu()\n",
    "            out_dict['INF'] = self.data['SR'].detach().float().cpu()\n",
    "            out_dict['HR'] = self.data['HR'].detach().float().cpu()\n",
    "            if need_LR and 'LR' in self.data:\n",
    "                out_dict['LR'] = self.data['LR'].detach().float().cpu()\n",
    "            else:\n",
    "                out_dict['LR'] = out_dict['INF']\n",
    "        return out_dict\n",
    "\n",
    "    def print_network(self):\n",
    "        s, n = self.get_network_description(self.netG)\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            net_struc_str = '{} - {}'.format(self.netG.__class__.__name__,\n",
    "                                             self.netG.module.__class__.__name__)\n",
    "        else:\n",
    "            net_struc_str = '{}'.format(self.netG.__class__.__name__)\n",
    "\n",
    "        logger.info(\n",
    "            'Network G structure: {}, with parameters: {:,d}'.format(net_struc_str, n))\n",
    "        logger.info(s)\n",
    "\n",
    "\n",
    "    def save_network(self, epoch, iter_step, is_final=False):\n",
    "        if is_final:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            ema_gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_gen_ema.pth'.format(iter_step, epoch)) # EMA path\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        else:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            ema_gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_gen_ema.pth'.format(iter_step, epoch)) # EMA path\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        \n",
    "\n",
    "        network = self.netG\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            network = network.module\n",
    "        state_dict = network.state_dict()\n",
    "        for key, param in state_dict.items():\n",
    "            state_dict[key] = param.cpu()\n",
    "        torch.save(state_dict, gen_path)\n",
    "\n",
    "        network_ema = self.netG_EMA\n",
    "        if isinstance(self.netG_EMA, nn.DataParallel):\n",
    "            network_ema = network_ema.module\n",
    "        state_dict_ema = network_ema.state_dict()\n",
    "        for key, param in state_dict_ema.items():\n",
    "            state_dict_ema[key] = param.cpu()\n",
    "        torch.save(state_dict_ema, ema_gen_path)\n",
    "\n",
    "        opt_state = {'epoch': epoch, 'iter': iter_step,\n",
    "                     'scheduler': None, 'optimizer': None}\n",
    "        opt_state['optimizer'] = self.optG.state_dict()\n",
    "        torch.save(opt_state, opt_path)\n",
    "\n",
    "        logger.info(\n",
    "            'Saved model in [{:s}] and EMA model in [{:s}] ...'.format(gen_path, ema_gen_path))\n",
    "\n",
    "    def load_network(self):\n",
    "        load_path = self.opt['path']['resume_state']\n",
    "        if load_path is not None:\n",
    "            logger.info(\n",
    "                'Loading pretrained model for G [{:s}] ...'.format(load_path))\n",
    "            gen_path = '{}_gen.pth'.format(load_path)\n",
    "            ema_gen_path = '{}_gen_ema.pth'.format(load_path) # EMA path\n",
    "            opt_path = '{}_opt.pth'.format(load_path)\n",
    "            \n",
    "            network = self.netG\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                network = network.module\n",
    "            network.load_state_dict(torch.load(\n",
    "                gen_path), strict=(not self.opt['model']['finetune_norm']))\n",
    "\n",
    "            if os.path.exists(ema_gen_path):\n",
    "                logger.info('Loading EMA model from [{:s}]...'.format(ema_gen_path))\n",
    "                network_ema = self.netG_EMA\n",
    "                if isinstance(self.netG_EMA, nn.DataParallel):\n",
    "                    network_ema = network_ema.module\n",
    "                network_ema.load_state_dict(torch.load(\n",
    "                    ema_gen_path), strict=(not self.opt['model']['finetune_norm']))\n",
    "            else:\n",
    "                logger.info('No EMA model found. Initializing EMA model with generator weights.')\n",
    "                self.netG_EMA.load_state_dict(network.state_dict())\n",
    "\n",
    "            if self.opt['phase'] == 'train':\n",
    "                opt = torch.load(opt_path)\n",
    "                self.optG.load_state_dict(opt['optimizer'])\n",
    "                self.begin_step = opt['iter']\n",
    "                self.begin_epoch = opt['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a1d7f",
   "metadata": {
    "papermill": {
     "duration": 0.00625,
     "end_time": "2025-06-22T02:34:41.552373",
     "exception": false,
     "start_time": "2025-06-22T02:34:41.546123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491bc4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T02:34:45.415090Z",
     "iopub.status.busy": "2025-06-22T02:34:45.414623Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-06-22T02:34:45.407629",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 02:34:45.421 - INFO: Using gradient accumulation with 2 steps.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2853584465.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2853584465.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 02:48:45.224 - INFO: <epoch:  1, iter:     100> l_pix: 2.7150e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 03:01:21.809 - INFO: <epoch:  1, iter:     200> l_pix: 2.7272e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 03:13:58.406 - INFO: <epoch:  1, iter:     300> l_pix: 2.6875e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 03:26:35.124 - INFO: <epoch:  1, iter:     400> l_pix: 2.6341e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 03:32:53.475 - INFO: Epoch 1 Average Loss: 0.2737178514401118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 03:39:13.504 - INFO: <epoch:  2, iter:     500> l_pix: 2.5939e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 03:51:50.235 - INFO: <epoch:  2, iter:     600> l_pix: 2.6986e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 04:04:26.870 - INFO: <epoch:  2, iter:     700> l_pix: 2.5299e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 04:17:03.517 - INFO: <epoch:  2, iter:     800> l_pix: 2.6511e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 04:29:40.063 - INFO: <epoch:  2, iter:     900> l_pix: 2.5139e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 04:29:40.127 - INFO: Epoch 2 Average Loss: 0.2640072614616818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 04:42:18.148 - INFO: <epoch:  3, iter:   1,000> l_pix: 2.6491e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 04:42:18.150 - INFO: Saving models and training states.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 04:42:18.501 - INFO: Saved model in [/kaggle/working/checkpoint/I1000_E3_gen.pth] and EMA model in [/kaggle/working/checkpoint/I1000_E3_gen_ema.pth] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 04:54:55.178 - INFO: <epoch:  3, iter:   1,100> l_pix: 2.5679e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 05:07:31.777 - INFO: <epoch:  3, iter:   1,200> l_pix: 2.5581e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 05:20:08.436 - INFO: <epoch:  3, iter:   1,300> l_pix: 2.7588e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 05:26:27.148 - INFO: Epoch 3 Average Loss: 0.2633273843924204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 05:32:46.657 - INFO: <epoch:  4, iter:   1,400> l_pix: 2.6508e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 05:45:23.297 - INFO: <epoch:  4, iter:   1,500> l_pix: 2.6919e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 05:58:00.002 - INFO: <epoch:  4, iter:   1,600> l_pix: 2.6447e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 06:10:36.555 - INFO: <epoch:  4, iter:   1,700> l_pix: 2.6456e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 06:23:13.097 - INFO: <epoch:  4, iter:   1,800> l_pix: 2.5606e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 06:23:13.148 - INFO: Epoch 4 Average Loss: 0.263101853662067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 06:35:50.913 - INFO: <epoch:  5, iter:   1,900> l_pix: 2.6765e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 06:48:27.612 - INFO: <epoch:  5, iter:   2,000> l_pix: 2.6845e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 06:48:27.613 - INFO: Saving models and training states.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 06:48:27.961 - INFO: Saved model in [/kaggle/working/checkpoint/I2000_E5_gen.pth] and EMA model in [/kaggle/working/checkpoint/I2000_E5_gen_ema.pth] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 07:01:04.592 - INFO: <epoch:  5, iter:   2,100> l_pix: 2.5601e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 07:13:41.670 - INFO: <epoch:  5, iter:   2,200> l_pix: 2.5681e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 07:20:00.044 - INFO: Epoch 5 Average Loss: 0.26295380413532254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 07:26:20.086 - INFO: <epoch:  6, iter:   2,300> l_pix: 2.6027e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 07:38:56.764 - INFO: <epoch:  6, iter:   2,400> l_pix: 2.7581e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 07:51:33.250 - INFO: <epoch:  6, iter:   2,500> l_pix: 2.6416e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 08:04:10.014 - INFO: <epoch:  6, iter:   2,600> l_pix: 2.5628e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 08:16:46.603 - INFO: <epoch:  6, iter:   2,700> l_pix: 2.6304e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 08:16:46.658 - INFO: Epoch 6 Average Loss: 0.26299861364894445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 08:29:24.414 - INFO: <epoch:  7, iter:   2,800> l_pix: 2.6857e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 08:42:01.117 - INFO: <epoch:  7, iter:   2,900> l_pix: 2.6456e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 08:54:38.075 - INFO: <epoch:  7, iter:   3,000> l_pix: 2.6404e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 08:54:38.075 - INFO: Saving models and training states.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 08:54:38.425 - INFO: Saved model in [/kaggle/working/checkpoint/I3000_E7_gen.pth] and EMA model in [/kaggle/working/checkpoint/I3000_E7_gen_ema.pth] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 09:07:15.140 - INFO: <epoch:  7, iter:   3,100> l_pix: 2.5595e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 09:13:33.484 - INFO: Epoch 7 Average Loss: 0.2629716024796168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 09:19:53.192 - INFO: <epoch:  8, iter:   3,200> l_pix: 2.5604e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 09:32:29.751 - INFO: <epoch:  8, iter:   3,300> l_pix: 2.6797e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 09:45:06.320 - INFO: <epoch:  8, iter:   3,400> l_pix: 2.5270e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 09:57:42.935 - INFO: <epoch:  8, iter:   3,500> l_pix: 2.6341e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 10:10:19.540 - INFO: <epoch:  8, iter:   3,600> l_pix: 2.5540e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 10:10:19.592 - INFO: Epoch 8 Average Loss: 0.2629618999030855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 10:22:57.556 - INFO: <epoch:  9, iter:   3,700> l_pix: 2.6443e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 10:35:33.945 - INFO: <epoch:  9, iter:   3,800> l_pix: 2.5943e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 10:48:10.742 - INFO: <epoch:  9, iter:   3,900> l_pix: 2.6819e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 11:00:47.202 - INFO: <epoch:  9, iter:   4,000> l_pix: 2.6457e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 11:00:47.203 - INFO: Saving models and training states.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 11:00:47.541 - INFO: Saved model in [/kaggle/working/checkpoint/I4000_E9_gen.pth] and EMA model in [/kaggle/working/checkpoint/I4000_E9_gen_ema.pth] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 11:07:05.810 - INFO: Epoch 9 Average Loss: 0.26293015744951037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 11:13:25.364 - INFO: <epoch: 10, iter:   4,100> l_pix: 2.6312e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 11:26:02.016 - INFO: <epoch: 10, iter:   4,200> l_pix: 2.6465e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 11:38:38.437 - INFO: <epoch: 10, iter:   4,300> l_pix: 2.5587e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 11:51:15.070 - INFO: <epoch: 10, iter:   4,400> l_pix: 2.7659e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 12:03:51.468 - INFO: <epoch: 10, iter:   4,500> l_pix: 2.5606e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 12:03:51.526 - INFO: Epoch 10 Average Loss: 0.26293717821439105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 12:16:29.204 - INFO: <epoch: 11, iter:   4,600> l_pix: 2.5587e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 12:29:05.782 - INFO: <epoch: 11, iter:   4,700> l_pix: 2.6434e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 12:41:42.305 - INFO: <epoch: 11, iter:   4,800> l_pix: 2.5578e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 12:54:19.270 - INFO: <epoch: 11, iter:   4,900> l_pix: 2.5585e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 13:00:37.541 - INFO: Epoch 11 Average Loss: 0.2628464452425639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 13:06:57.089 - INFO: <epoch: 12, iter:   5,000> l_pix: 2.5577e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 13:06:57.091 - INFO: Saving models and training states.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 13:06:57.435 - INFO: Saved model in [/kaggle/working/checkpoint/I5000_E12_gen.pth] and EMA model in [/kaggle/working/checkpoint/I5000_E12_gen_ema.pth] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 13:19:33.978 - INFO: <epoch: 12, iter:   5,100> l_pix: 2.6118e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 13:32:10.486 - INFO: <epoch: 12, iter:   5,200> l_pix: 2.6775e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 13:44:47.005 - INFO: <epoch: 12, iter:   5,300> l_pix: 2.6874e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 13:57:23.620 - INFO: <epoch: 12, iter:   5,400> l_pix: 2.6364e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 13:57:23.682 - INFO: Epoch 12 Average Loss: 0.2629329017466969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 14:10:01.735 - INFO: <epoch: 13, iter:   5,500> l_pix: 2.5146e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-22 14:22:38.289 - INFO: <epoch: 13, iter:   5,600> l_pix: 2.5753e-01\n"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "diffusion = SR3(opt)\n",
    "\n",
    "# Training\n",
    "epoch_loss_list = []\n",
    "current_step = diffusion.begin_step\n",
    "current_epoch = diffusion.begin_epoch\n",
    "n_iter = opt['train']['n_iter']\n",
    "\n",
    "accumulation_steps = opt['train']['accumulation_steps']\n",
    "logger.info(f\"Using gradient accumulation with {accumulation_steps} steps.\")\n",
    "optimizer = diffusion.optG\n",
    "scaler = diffusion.scaler\n",
    "scheduler = diffusion.schedulerG\n",
    "\n",
    "if opt['path']['resume_state']:\n",
    "    logger.info(f'Resuming training from epoch: {current_epoch}, iter: {current_step}.')\n",
    "\n",
    "if opt['phase'] == 'train':\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    optimizer.zero_grad()\n",
    "    while current_step < n_iter:\n",
    "        current_epoch += 1\n",
    "        epoch_loss_values = []\n",
    "        \n",
    "        for i, train_data in enumerate(train_loader):\n",
    "\n",
    "            if torch.isnan(train_data['Noisy']).any() or torch.isnan(train_data['GT']).any() or torch.isnan(train_data['Anat']).any():\n",
    "                logger.error(f\"NaN found in input data at step {current_step}. Aborting.\")\n",
    "                break\n",
    "            \n",
    "            current_step += 1\n",
    "            if current_step > n_iter: break\n",
    "            \n",
    "            diffusion.feed_data(train_data)\n",
    "            \n",
    "            with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "                l_pix = diffusion.netG(diffusion.data)\n",
    "                b, c, h, w = diffusion.data['GT'].shape\n",
    "                raw_loss = l_pix.sum() / int(b*c*h*w)\n",
    "                loss = raw_loss / accumulation_steps\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(diffusion.netG.parameters(), max_norm=0.5)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "            \n",
    "            diffusion._update_ema(current_step)\n",
    "            \n",
    "            current_l_pix = raw_loss.item()\n",
    "            epoch_loss_values.append(current_l_pix)\n",
    "                \n",
    "            if current_step % opt['train']['print_freq'] == 0:\n",
    "                logger.info(f'<epoch:{current_epoch:3d}, iter:{current_step:8,d}> l_pix: {current_l_pix:.4e}')\n",
    "                \n",
    "            if current_step % opt['train']['save_checkpoint_freq'] == 0:\n",
    "                logger.info('Saving models and training states.')\n",
    "                diffusion.save_network(current_epoch, current_step)\n",
    "            \n",
    "            if current_step == n_iter:\n",
    "                logger.info(\"Saving final model\")\n",
    "                diffusion.save_network(current_epoch, current_step, is_final=True)\n",
    "\n",
    "        if epoch_loss_values:\n",
    "            epoch_loss = sum(epoch_loss_values)/len(epoch_loss_values)\n",
    "            logger.info(f'Epoch {current_epoch} Average Loss: {epoch_loss}')\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "\n",
    "    logger.info('End of training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ae502",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad059da1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_loss_curve(epoch_loss_list, filename='loss_curve.png'):\n",
    "    epochs = range(1, len(epoch_loss_list) + 1)  # X-axis starts at 1\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, epoch_loss_list, marker='o', label='Training Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(epochs)  # Set integer ticks\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769b9a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_loss_curve(epoch_loss_list, \"/kaggle/working/train_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550d881",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test loop\n",
    "\n",
    "logger.info('Starting model evaluation on the test set using EMA weights...')\n",
    "test_loss_list = []\n",
    "\n",
    "for i, test_data in enumerate(tqdm(test_loader, desc=\"Evaluating on test set\")):\n",
    "    current_test_loss = diffusion.evaluate_loss(test_data, use_ema=True)\n",
    "    test_loss_list.append(current_test_loss)\n",
    "    \n",
    "if test_loss_list:\n",
    "    avg_test_loss = sum(test_loss_list) / len(test_loss_list)\n",
    "    logger.info('=' * 20)\n",
    "    logger.info(f'Average Test Loss (EMA): {avg_test_loss:.4e}')\n",
    "    logger.info('=' * 20)\n",
    "else:\n",
    "    logger.info('Test set was empty or no losses were calculated.')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7419713,
     "sourceId": 11813224,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7419718,
     "sourceId": 11813229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7419725,
     "sourceId": 11813237,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7421178,
     "sourceId": 11815303,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7705878,
     "sourceId": 12230264,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7705886,
     "sourceId": 12230275,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7705889,
     "sourceId": 12230280,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7705891,
     "sourceId": 12230283,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7712535,
     "sourceId": 12240417,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-22T02:33:54.821276",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
