{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e65edd5",
   "metadata": {},
   "source": [
    "### Denoising fMRI Scans with Diffusion Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019e727",
   "metadata": {},
   "source": [
    "## Training with Mask as Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea6b26",
   "metadata": {},
   "source": [
    "This Code is based on the implementation of the Super-Resolution Network SR3: https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement.git\n",
    "\n",
    "Changes were made throughout the full code to convert the super-resolution architecture to a denoising-architecture with an additional masked loss from Structural MRI (anatomy).\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083aebf",
   "metadata": {
    "papermill": {
     "duration": 0.00442,
     "end_time": "2025-06-23T20:37:01.887575",
     "exception": false,
     "start_time": "2025-06-23T20:37:01.883155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee847197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:01.897770Z",
     "iopub.status.busy": "2025-06-23T20:37:01.897499Z",
     "iopub.status.idle": "2025-06-23T20:37:09.361164Z",
     "shell.execute_reply": "2025-06-23T20:37:09.360382Z"
    },
    "papermill": {
     "duration": 7.470416,
     "end_time": "2025-06-23T20:37:09.362522",
     "exception": false,
     "start_time": "2025-06-23T20:37:01.892106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from re import split\n",
    "import torch.utils.data\n",
    "\n",
    "# import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "import functools\n",
    "from torch.nn import init\n",
    "from torch.nn import modules\n",
    "\n",
    "# u-net\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from inspect import isfunction\n",
    "\n",
    "# diffusion\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "# learning rate scheduler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# mixed precision training for memory\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.amp import autocast\n",
    "\n",
    "# activation checkpointing\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "# read masks\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8166b7ad",
   "metadata": {
    "papermill": {
     "duration": 0.004295,
     "end_time": "2025-06-23T20:37:09.371600",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.367305",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad87790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:09.381692Z",
     "iopub.status.busy": "2025-06-23T20:37:09.381148Z",
     "iopub.status.idle": "2025-06-23T20:37:09.388385Z",
     "shell.execute_reply": "2025-06-23T20:37:09.387893Z"
    },
    "papermill": {
     "duration": 0.013375,
     "end_time": "2025-06-23T20:37:09.389365",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.375990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"denoising\",\n",
    "    \"phase\": \"train\",\n",
    "    \"gpu_ids\": [0, 1], \n",
    "    \"debug\": False,  \n",
    "    \"enable_wandb\": False,  \n",
    "    \"log_wandb_ckpt\": False,  \n",
    "    \"log_eval\": False,  \n",
    "    \"path\": {\n",
    "        \"log\": \"/kaggle/working/logs\",\n",
    "        \"tb_logger\": \"/kaggle/working/tb_logger\",\n",
    "        \"results\": \"/kaggle/working/results\",\n",
    "        \"checkpoint\": \"/kaggle/working/checkpoint\",\n",
    "        \"resume_state\": None\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-train-1-norm-v3/data/noisy_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-norm-v3/data/noisy_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-norm-v3/data/noisy_func_train_3.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-train-1-norm-v3/data/gt_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-norm-v3/data/gt_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-norm-v3/data/gt_func_train_3.npy'],\n",
    "            \"mask_data_paths\": ['/kaggle/input/brain-masks/brain_mask_01.nii',\n",
    "                 '/kaggle/input/brain-masks/brain_mask_dd.nii',\n",
    "                 '/kaggle/input/brain-masks/brain_mask_gg.nii'],\n",
    "            \"batch_size\": 2,\n",
    "            \"num_workers\": 4,\n",
    "            \"use_shuffle\": True\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-test-norm-v3/data/noisy_func_test.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-test/data/gt_func_test.npy'],\n",
    "            \"mask_data_paths\": ['/kaggle/input/brain-masks/brain_mask_uu.nii'],\n",
    "        }\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\",\n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 3,\n",
    "            \"out_channel\": 1,\n",
    "            \"inner_channel\": 64,\n",
    "            \"norm_groups\": 16,\n",
    "            \"channel_multiplier\": [1, 2, 4, 8],\n",
    "            \"attn_res\": [8],\n",
    "            \"res_blocks\": 1,\n",
    "            \"dropout\": 0.1\n",
    "        },\n",
    "        \"beta_schedule\": {\n",
    "            \"train\": {\n",
    "                \"schedule\": \"cosine\",\n",
    "                \"n_timestep\": 1000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"schedule\": \"cosine\",\n",
    "                \"n_timestep\": 1000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 64,\n",
    "            \"channels\": 1,\n",
    "            \"conditional\": True\n",
    "        }\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"n_iter\": 18000,\n",
    "        \"val_freq\": 1e4,\n",
    "        \"save_checkpoint_freq\": 1800,\n",
    "        \"print_freq\": 100,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"lr\": 5e-5\n",
    "        },\n",
    "        \"ema_scheduler\": {\n",
    "            \"step_start_ema\": 1000,\n",
    "            \"update_ema_every\": 10,\n",
    "            \"ema_decay\": 0.999\n",
    "        }\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        \"project\": \"distributed_high_sr_ffhq\"\n",
    "    },\n",
    "    \"config_file\": \"config/sr_sr3_16_128.json\"  # from CLI\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4567ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:09.399060Z",
     "iopub.status.busy": "2025-06-23T20:37:09.398873Z",
     "iopub.status.idle": "2025-06-23T20:37:09.402954Z",
     "shell.execute_reply": "2025-06-23T20:37:09.402456Z"
    },
    "papermill": {
     "duration": 0.010144,
     "end_time": "2025-06-23T20:37:09.403941",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.393797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(opt['path']['log'], exist_ok=True)\n",
    "os.makedirs(opt['path']['tb_logger'], exist_ok=True)\n",
    "os.makedirs(opt['path']['results'], exist_ok=True)\n",
    "os.makedirs(opt['path']['checkpoint'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67815e3",
   "metadata": {
    "papermill": {
     "duration": 0.004122,
     "end_time": "2025-06-23T20:37:09.412408",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.408286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97493e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:09.422205Z",
     "iopub.status.busy": "2025-06-23T20:37:09.421710Z",
     "iopub.status.idle": "2025-06-23T20:37:09.428677Z",
     "shell.execute_reply": "2025-06-23T20:37:09.428126Z"
    },
    "papermill": {
     "duration": 0.013001,
     "end_time": "2025-06-23T20:37:09.429751",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.416750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logging\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def dict2str(opt, indent_l=1):\n",
    "    '''dict to string for logger'''\n",
    "    msg = ''\n",
    "    for k, v in opt.items():\n",
    "        if isinstance(v, dict):\n",
    "            msg += ' ' * (indent_l * 2) + k + ':[\\n'\n",
    "            msg += dict2str(v, indent_l + 1)\n",
    "            msg += ' ' * (indent_l * 2) + ']\\n'\n",
    "        else:\n",
    "            msg += ' ' * (indent_l * 2) + k + ': ' + str(v) + '\\n'\n",
    "    return msg\n",
    "\n",
    "def setup_logger(logger_name, root, phase, level=logging.INFO, screen=False):\n",
    "    '''set up logger'''\n",
    "    l = logging.getLogger(logger_name)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s.%(msecs)03d - %(levelname)s: %(message)s', datefmt='%y-%m-%d %H:%M:%S')\n",
    "    log_file = os.path.join(root, '{}.log'.format(phase))\n",
    "    fh = logging.FileHandler(log_file, mode='w')\n",
    "    fh.setFormatter(formatter)\n",
    "    l.setLevel(level)\n",
    "    l.addHandler(fh)\n",
    "    if screen:\n",
    "        sh = logging.StreamHandler()\n",
    "        sh.setFormatter(formatter)\n",
    "        l.addHandler(sh)\n",
    "\n",
    "setup_logger(None, opt['path']['log'],\n",
    "                    'train', level=logging.INFO, screen=True)\n",
    "setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "logger = logging.getLogger('base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09adf4c",
   "metadata": {
    "papermill": {
     "duration": 0.00414,
     "end_time": "2025-06-23T20:37:09.438339",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.434199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477bc96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:09.448652Z",
     "iopub.status.busy": "2025-06-23T20:37:09.448211Z",
     "iopub.status.idle": "2025-06-23T20:37:09.457219Z",
     "shell.execute_reply": "2025-06-23T20:37:09.456642Z"
    },
    "papermill": {
     "duration": 0.015255,
     "end_time": "2025-06-23T20:37:09.458275",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.443020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, noisy_images_paths: list, gt_images_paths: list, mask_images_paths: list):\n",
    "        \"\"\"Initialize fMRI dataset for denoising with memory-efficient loading.\n",
    "        \n",
    "        Args:\n",
    "            noisy_images_paths (list): List of paths to noisy fMRI volumes (.npy files)\n",
    "            gt_images_paths (list): List of paths to ground truth fMRI volumes (.npy files)\n",
    "            mask_images_paths (list): List of paths to brain mask volumes (.nii files)\n",
    "        \"\"\"\n",
    "        self.noisy_paths = noisy_images_paths\n",
    "        self.gt_paths = gt_images_paths\n",
    "        self.mask_paths = mask_images_paths\n",
    "        \n",
    "\n",
    "\n",
    "        self.mask_volumes = [np.rot90(nib.load(path).get_fdata(), k=1, axes=(0, 1)) for path in mask_images_paths]\n",
    "        \n",
    "        self.file_slice_mapping = []\n",
    "        self.z_t_dimension_sizes = []\n",
    "        total_slices = 0\n",
    "        dataset_length = 0 \n",
    "\n",
    "        for i, path in enumerate(noisy_images_paths):\n",
    "            \n",
    "            data_shape = np.load(path, mmap_mode='r').shape\n",
    "            num_slices = data_shape[2] * data_shape[3]  # z * t\n",
    "            self.z_t_dimension_sizes.append((data_shape[2], data_shape[3]))\n",
    "            \n",
    "            for batch_idx in range(0, data_shape[3]):\n",
    "                self.file_slice_mapping.append((i, batch_idx))\n",
    "                dataset_length += 1\n",
    "            \n",
    "            total_slices += num_slices \n",
    "            \n",
    "        self.data_len = dataset_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_idx, t_idx = self.file_slice_mapping[index]\n",
    "        \n",
    "        noisy_file_path = self.noisy_paths[file_idx]\n",
    "        gt_file_path = self.gt_paths[file_idx]\n",
    "        \n",
    "        mask_volume = self.mask_volumes[file_idx]\n",
    "        noisy_volume = np.load(noisy_file_path, mmap_mode='r')\n",
    "        gt_volume = np.load(gt_file_path, mmap_mode='r')\n",
    "        \n",
    "        noisy_slice = noisy_volume[:, :, :, t_idx].copy() \n",
    "        gt_slice = gt_volume[:, :, :, t_idx].copy()\n",
    "        \n",
    "        return {\n",
    "            'GT': torch.tensor(gt_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Noisy': torch.tensor(noisy_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Mask': torch.tensor(mask_volume.copy()).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Index': index\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aef0ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:09.468088Z",
     "iopub.status.busy": "2025-06-23T20:37:09.467901Z",
     "iopub.status.idle": "2025-06-23T20:37:09.473416Z",
     "shell.execute_reply": "2025-06-23T20:37:09.472757Z"
    },
    "papermill": {
     "duration": 0.011507,
     "end_time": "2025-06-23T20:37:09.474448",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.462941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_merge_batches(batch):\n",
    "    merged = {\n",
    "        'Noisy': torch.cat([item['Noisy'] for item in batch], dim=0),\n",
    "        'GT': torch.cat([item['GT'] for item in batch], dim=0),\n",
    "        'Mask': torch.cat([item['Mask'] for item in batch], dim=0),\n",
    "        'Index': [item['Index'] for item in batch]\n",
    "    }\n",
    "    return merged\n",
    "\n",
    "def create_dataloader(dataset, dataset_opt, phase):\n",
    "    '''create dataloader '''\n",
    "    if phase == 'train':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=dataset_opt['batch_size'],\n",
    "            shuffle=dataset_opt['use_shuffle'],\n",
    "            num_workers=dataset_opt['num_workers'],\n",
    "            pin_memory=True,\n",
    "            collate_fn = collate_merge_batches)\n",
    "    elif phase == 'test':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True, collate_fn = lambda x: x[0])\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Dataloader [{:s}] is not found.'.format(phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a35559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:09.483966Z",
     "iopub.status.busy": "2025-06-23T20:37:09.483753Z",
     "iopub.status.idle": "2025-06-23T20:37:09.760349Z",
     "shell.execute_reply": "2025-06-23T20:37:09.759593Z"
    },
    "papermill": {
     "duration": 0.282632,
     "end_time": "2025-06-23T20:37:09.761594",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.478962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 20:37:09.725 - INFO: Training dataset with 900 instances created.\n",
      "25-06-23 20:37:09.757 - INFO: Test dataset with 300 instances created.\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset and dataloader\n",
    "train_set = PairwiseDataset(\n",
    "    opt['datasets']['train']['noisy_data_paths'], \n",
    "    opt['datasets']['train']['gt_data_paths'],\n",
    "    opt['datasets']['train']['mask_data_paths']\n",
    ")\n",
    "train_loader = create_dataloader(\n",
    "    train_set, \n",
    "    opt['datasets']['train'], \n",
    "    'train'\n",
    ")\n",
    "logger.info('Training dataset with {} instances created.'.format(len(train_set)))\n",
    "\n",
    "# Create testing dataset and dataloader\n",
    "test_set = PairwiseDataset(\n",
    "    opt['datasets']['test']['noisy_data_paths'], \n",
    "    opt['datasets']['test']['gt_data_paths'],\n",
    "    opt['datasets']['test']['mask_data_paths']\n",
    ")\n",
    "test_loader = create_dataloader(\n",
    "    test_set, \n",
    "    opt['datasets']['test'], \n",
    "    'test'\n",
    ")\n",
    "logger.info('Test dataset with {} instances created.'.format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053a552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:09.772498Z",
     "iopub.status.busy": "2025-06-23T20:37:09.771825Z",
     "iopub.status.idle": "2025-06-23T20:37:42.907363Z",
     "shell.execute_reply": "2025-06-23T20:37:42.906562Z"
    },
    "papermill": {
     "duration": 33.142312,
     "end_time": "2025-06-23T20:37:42.908846",
     "exception": false,
     "start_time": "2025-06-23T20:37:09.766534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gt_slice = train_set[400][\"GT\"]\n",
    "mask_slice = train_set[400][\"Mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f80a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:42.933301Z",
     "iopub.status.busy": "2025-06-23T20:37:42.933087Z",
     "iopub.status.idle": "2025-06-23T20:37:43.308542Z",
     "shell.execute_reply": "2025-06-23T20:37:43.307878Z"
    },
    "papermill": {
     "duration": 0.381827,
     "end_time": "2025-06-23T20:37:43.309804",
     "exception": false,
     "start_time": "2025-06-23T20:37:42.927977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ceece54db90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example visualization of mask and gt\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot ground truth image\n",
    "axes[0].imshow(gt_slice[0,0,:,:], cmap='gray')\n",
    "axes[1].imshow(mask_slice[0,0,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9c05dd",
   "metadata": {
    "papermill": {
     "duration": 0.004772,
     "end_time": "2025-06-23T20:37:43.320041",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.315269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76004c3e",
   "metadata": {
    "papermill": {
     "duration": 0.004643,
     "end_time": "2025-06-23T20:37:43.329610",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.324967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba3641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:43.340710Z",
     "iopub.status.busy": "2025-06-23T20:37:43.340243Z",
     "iopub.status.idle": "2025-06-23T20:37:43.344030Z",
     "shell.execute_reply": "2025-06-23T20:37:43.343508Z"
    },
    "papermill": {
     "duration": 0.010597,
     "end_time": "2025-06-23T20:37:43.345072",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.334475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9abde8",
   "metadata": {},
   "source": [
    "U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23aab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:43.355987Z",
     "iopub.status.busy": "2025-06-23T20:37:43.355794Z",
     "iopub.status.idle": "2025-06-23T20:37:43.379278Z",
     "shell.execute_reply": "2025-06-23T20:37:43.378581Z"
    },
    "papermill": {
     "duration": 0.030408,
     "end_time": "2025-06-23T20:37:43.380417",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.350009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PositionalEncoding Sourceï¼š https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        count = self.dim // 2\n",
    "        step = torch.arange(count, dtype=noise_level.dtype,\n",
    "                            device=noise_level.device) / count\n",
    "        encoding = noise_level.unsqueeze(\n",
    "            1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n",
    "        encoding = torch.cat(\n",
    "            [torch.sin(encoding), torch.cos(encoding)], dim=-1)\n",
    "        return encoding\n",
    "\n",
    "\n",
    "class FeatureWiseAffine(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_affine_level=False):\n",
    "        super(FeatureWiseAffine, self).__init__()\n",
    "        self.use_affine_level = use_affine_level\n",
    "        self.noise_func = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, noise_embed):\n",
    "        batch = x.shape[0]\n",
    "        if self.use_affine_level:\n",
    "            gamma, beta = self.noise_func(noise_embed).view(\n",
    "                batch, -1, 1, 1).chunk(2, dim=1)\n",
    "            x = (1 + gamma) * x + beta\n",
    "        else:\n",
    "            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.up(x))\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# building block modules\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=32, dropout=0):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, dim),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32):\n",
    "        super().__init__()\n",
    "        self.noise_func = FeatureWiseAffine(\n",
    "            noise_level_emb_dim, dim_out, use_affine_level)\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=norm_groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout)\n",
    "        self.res_conv = nn.Conv2d(\n",
    "            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        b, c, h, w = x.shape\n",
    "        h = self.block1(x)\n",
    "        h = self.noise_func(h, time_emb)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channel, n_head=1, norm_groups=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.norm = nn.GroupNorm(norm_groups, in_channel)\n",
    "        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch, channel, height, width = input.shape\n",
    "        n_head = self.n_head\n",
    "        head_dim = channel // n_head\n",
    "\n",
    "        norm = self.norm(input)\n",
    "        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n",
    "        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n",
    "\n",
    "        attn = torch.einsum(\n",
    "            \"bnchw, bncyx -> bnhwyx\", query, key\n",
    "        ).contiguous() / math.sqrt(channel)\n",
    "        attn = attn.view(batch, n_head, height, width, -1)\n",
    "        attn = torch.softmax(attn, -1)\n",
    "        attn = attn.view(batch, n_head, height, width, height, width)\n",
    "\n",
    "        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n",
    "        out = self.out(out.view(batch, channel, height, width))\n",
    "\n",
    "        return out + input\n",
    "\n",
    "\n",
    "class ResnetBlocWithAttn(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False):\n",
    "        super().__init__()\n",
    "        self.with_attn = with_attn\n",
    "        self.res_block = ResnetBlock(\n",
    "            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout)\n",
    "        if with_attn:\n",
    "            self.attn = SelfAttention(dim_out, norm_groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        x = self.res_block(x, time_emb)\n",
    "        if(self.with_attn):\n",
    "            x = self.attn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=6,\n",
    "        out_channel=3,\n",
    "        inner_channel=32,\n",
    "        norm_groups=32,\n",
    "        channel_mults=(1, 2, 4, 8, 8),\n",
    "        attn_res=(8),\n",
    "        res_blocks=3,\n",
    "        dropout=0,\n",
    "        with_noise_level_emb=True,\n",
    "        image_size=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if with_noise_level_emb:\n",
    "            noise_level_channel = inner_channel\n",
    "            self.noise_level_mlp = nn.Sequential(\n",
    "                PositionalEncoding(inner_channel),\n",
    "                nn.Linear(inner_channel, inner_channel * 4),\n",
    "                Swish(),\n",
    "                nn.Linear(inner_channel * 4, inner_channel)\n",
    "            )\n",
    "        else:\n",
    "            noise_level_channel = None\n",
    "            self.noise_level_mlp = None\n",
    "\n",
    "        num_mults = len(channel_mults)\n",
    "        pre_channel = inner_channel\n",
    "        feat_channels = [pre_channel]\n",
    "        now_res = image_size\n",
    "        downs = [nn.Conv2d(in_channel, inner_channel,\n",
    "                           kernel_size=3, padding=1)]\n",
    "        for ind in range(num_mults):\n",
    "            is_last = (ind == num_mults - 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks):\n",
    "                downs.append(ResnetBlocWithAttn(\n",
    "                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn))\n",
    "                feat_channels.append(channel_mult)\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                downs.append(Downsample(pre_channel))\n",
    "                feat_channels.append(pre_channel)\n",
    "                now_res = now_res//2\n",
    "        self.downs = nn.ModuleList(downs)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=True),\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=False)\n",
    "        ])\n",
    "\n",
    "        ups = []\n",
    "        for ind in reversed(range(num_mults)):\n",
    "            is_last = (ind < 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks+1):\n",
    "                ups.append(ResnetBlocWithAttn(\n",
    "                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                        dropout=dropout, with_attn=use_attn))\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                ups.append(Upsample(pre_channel))\n",
    "                now_res = now_res*2\n",
    "\n",
    "        self.ups = nn.ModuleList(ups)\n",
    "\n",
    "        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        t = self.noise_level_mlp(time) if exists(\n",
    "            self.noise_level_mlp) else None\n",
    "\n",
    "        feats = []\n",
    "        \n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                \n",
    "                x = checkpoint.checkpoint(layer, x, t, use_reentrant=False) # wrap\n",
    "\n",
    "            else:\n",
    "                x = layer(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = checkpoint.checkpoint(layer, x, t, use_reentrant=False) # wrap\n",
    "\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        for layer in self.ups:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = checkpoint.checkpoint(layer, torch.cat((x, feats.pop()), dim=1), t, use_reentrant=False)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ed40a",
   "metadata": {},
   "source": [
    "Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb27d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:43.391831Z",
     "iopub.status.busy": "2025-06-23T20:37:43.391593Z",
     "iopub.status.idle": "2025-06-23T20:37:43.415967Z",
     "shell.execute_reply": "2025-06-23T20:37:43.415370Z"
    },
    "papermill": {
     "duration": 0.031392,
     "end_time": "2025-06-23T20:37:43.417089",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.385697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Diffusion ###\n",
    "def _warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n",
    "    betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    warmup_time = int(n_timestep * warmup_frac)\n",
    "    betas[:warmup_time] = np.linspace(\n",
    "        linear_start, linear_end, warmup_time, dtype=np.float64)\n",
    "    return betas\n",
    "\n",
    "\n",
    "def make_beta_schedule(schedule, n_timestep, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n",
    "    if schedule == 'quad':\n",
    "        betas = np.linspace(linear_start ** 0.5, linear_end ** 0.5,\n",
    "                            n_timestep, dtype=np.float64) ** 2\n",
    "    elif schedule == 'linear':\n",
    "        betas = np.linspace(linear_start, linear_end,\n",
    "                            n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'warmup10':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.1)\n",
    "    elif schedule == 'warmup50':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.5)\n",
    "    elif schedule == 'const':\n",
    "        betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        betas = 1. / np.linspace(n_timestep,\n",
    "                                 1, n_timestep, dtype=np.float64)\n",
    "    elif schedule == \"cosine\":\n",
    "        timesteps = (\n",
    "            torch.arange(n_timestep + 1, dtype=torch.float64) /\n",
    "            n_timestep + cosine_s\n",
    "        )\n",
    "        alphas = timesteps / (1 + cosine_s) * math.pi / 2\n",
    "        alphas = torch.cos(alphas).pow(2)\n",
    "        alphas = alphas / alphas[0]\n",
    "        betas = 1 - alphas[1:] / alphas[:-1]\n",
    "        betas = betas.clamp(max=0.999)\n",
    "    else:\n",
    "        raise NotImplementedError(schedule)\n",
    "    return betas\n",
    "\n",
    "\n",
    "# gaussian diffusion trainer class\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        denoise_fn,\n",
    "        image_size,\n",
    "        channels=3,\n",
    "        loss_type='l1',\n",
    "        conditional=True,\n",
    "        schedule_opt=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.denoise_fn = denoise_fn\n",
    "        self.loss_type = loss_type\n",
    "        self.conditional = conditional\n",
    "        if schedule_opt is not None:\n",
    "            pass\n",
    "\n",
    "\n",
    "    def set_loss(self, device):\n",
    "        if self.loss_type == 'l1':\n",
    "            self.loss_func = nn.L1Loss(reduction='sum').to(device)\n",
    "        elif self.loss_type == 'l2':\n",
    "            self.loss_func = nn.MSELoss(reduction='sum').to(device)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, device):\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32, device=device)\n",
    "\n",
    "        betas = make_beta_schedule(\n",
    "            schedule=schedule_opt['schedule'],\n",
    "            n_timestep=schedule_opt['n_timestep'],\n",
    "            linear_start=schedule_opt['linear_start'],\n",
    "            linear_end=schedule_opt['linear_end'])\n",
    "        betas = betas.detach().cpu().numpy() if isinstance(\n",
    "            betas, torch.Tensor) else betas\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n",
    "        self.sqrt_alphas_cumprod_prev = np.sqrt(\n",
    "            np.append(1., alphas_cumprod))\n",
    "\n",
    "        timesteps, = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.register_buffer('betas', to_torch(betas))\n",
    "        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n",
    "        self.register_buffer('alphas_cumprod_prev',\n",
    "                             to_torch(alphas_cumprod_prev))\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer('sqrt_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. - alphas_cumprod)))\n",
    "        self.register_buffer('log_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.log(1. - alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recip_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recipm1_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = betas * \\\n",
    "            (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "        self.register_buffer('posterior_variance',\n",
    "                             to_torch(posterior_variance))\n",
    "        self.register_buffer('posterior_log_variance_clipped', to_torch(\n",
    "            np.log(np.maximum(posterior_variance, 1e-20))))\n",
    "        self.register_buffer('posterior_mean_coef1', to_torch(\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n",
    "        self.register_buffer('posterior_mean_coef2', to_torch(\n",
    "            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return self.sqrt_recip_alphas_cumprod[t] * x_t - \\\n",
    "            self.sqrt_recipm1_alphas_cumprod[t] * noise\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = self.posterior_mean_coef1[t] * \\\n",
    "            x_start + self.posterior_mean_coef2[t] * x_t\n",
    "        posterior_log_variance_clipped = self.posterior_log_variance_clipped[t]\n",
    "        return posterior_mean, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, x, t, clip_denoised: bool, condition_x=None, mask=None):\n",
    "        batch_size = x.shape[0]\n",
    "        noise_level = torch.tensor(\n",
    "            [self.sqrt_alphas_cumprod_prev[t+1]], dtype=torch.float32).repeat(batch_size, 1).to(x.device)\n",
    "        if condition_x is not None:\n",
    "            if condition_x.shape[0] != mask.shape[0]:\n",
    "                repeats = condition_x.shape[0] // mask.shape[0]\n",
    "                mask = mask.repeat(repeats, 1, 1, 1)\n",
    "\n",
    "            denoise_input = torch.cat([condition_x, mask, x], dim=1)\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(denoise_input, noise_level))\n",
    "        else:\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(x, noise_level))\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1., 1.)\n",
    "\n",
    "        model_mean, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t)\n",
    "        return model_mean, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, clip_denoised=True, condition_x=None, mask=None):\n",
    "        model_mean, model_log_variance = self.p_mean_variance(\n",
    "            x=x, t=t, clip_denoised=clip_denoised, condition_x=condition_x, mask=mask)\n",
    "        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "        return model_mean + noise * (0.5 * model_log_variance).exp()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, x_in, mask, continous=False):\n",
    "        device = self.betas.device\n",
    "        sample_inter = (1 | (self.num_timesteps//10))\n",
    "        if not self.conditional:\n",
    "            shape = x_in\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = img\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        else:\n",
    "            x = x_in\n",
    "            shape = x.shape\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = x\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i, condition_x=x, mask=mask)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        if continous:\n",
    "            return ret_img\n",
    "        else:\n",
    "            return ret_img[-1]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        image_size = self.image_size\n",
    "        channels = self.channels\n",
    "        return self.p_sample_loop((batch_size, channels, image_size, image_size), continous)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def super_resolution(self, x_in, mask, continous=False):\n",
    "        return self.p_sample_loop(x_in, mask, continous)\n",
    "\n",
    "    def q_sample(self, x_start, continuous_sqrt_alpha_cumprod, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        return (\n",
    "            continuous_sqrt_alpha_cumprod * x_start +\n",
    "            (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_in, noise=None):\n",
    "        x_start = x_in['GT']\n",
    "        noisy_input = x_in['Noisy']\n",
    "        mask_input = x_in['Mask']\n",
    "        \n",
    "\n",
    "        if noisy_input.shape[0] != mask_input.shape[0]:\n",
    "            repeats = noisy_input.shape[0] // mask_input.shape[0]\n",
    "            mask_input = mask_input.repeat(repeats, 1, 1, 1)\n",
    "\n",
    "        [b, c, h, w] = x_start.shape\n",
    "        t = np.random.randint(1, self.num_timesteps + 1)\n",
    "        continuous_sqrt_alpha_cumprod = torch.tensor(\n",
    "            np.random.uniform(\n",
    "                self.sqrt_alphas_cumprod_prev[t-1],\n",
    "                self.sqrt_alphas_cumprod_prev[t],\n",
    "                size=b\n",
    "            ),\n",
    "            dtype=torch.float32\n",
    "        ).to(x_start.device)\n",
    "        continuous_sqrt_alpha_cumprod = continuous_sqrt_alpha_cumprod.view(b, -1)\n",
    "\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        x_noisy = self.q_sample(\n",
    "            x_start=x_start, continuous_sqrt_alpha_cumprod=continuous_sqrt_alpha_cumprod.view(-1, 1, 1, 1), noise=noise)\n",
    "\n",
    "        if not self.conditional:\n",
    "            x_recon = self.denoise_fn(x_noisy, continuous_sqrt_alpha_cumprod)\n",
    "        else:\n",
    "            x_recon = self.denoise_fn(\n",
    "                torch.cat([noisy_input, mask_input, x_noisy], dim=1), continuous_sqrt_alpha_cumprod)\n",
    "\n",
    "        loss = self.loss_func(noise, x_recon)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.p_losses(x, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac20e3",
   "metadata": {
    "papermill": {
     "duration": 0.004883,
     "end_time": "2025-06-23T20:37:43.427106",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.422223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea446a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:43.438512Z",
     "iopub.status.busy": "2025-06-23T20:37:43.438277Z",
     "iopub.status.idle": "2025-06-23T20:37:43.449619Z",
     "shell.execute_reply": "2025-06-23T20:37:43.449099Z"
    },
    "papermill": {
     "duration": 0.018286,
     "end_time": "2025-06-23T20:37:43.450672",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.432386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m, std=0.02):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, std) \n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m, scale=1):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_orthogonal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='kaiming', scale=1, std=0.02):\n",
    "    # scale for 'kaiming', std for 'normal'.\n",
    "    logger.info('Initialization method [{:s}]'.format(init_type))\n",
    "    if init_type == 'normal':\n",
    "        weights_init_normal_ = functools.partial(weights_init_normal, std=std)\n",
    "        net.apply(weights_init_normal_)\n",
    "    elif init_type == 'kaiming':\n",
    "        weights_init_kaiming_ = functools.partial(\n",
    "            weights_init_kaiming, scale=scale)\n",
    "        net.apply(weights_init_kaiming_)\n",
    "    elif init_type == 'orthogonal':\n",
    "        net.apply(weights_init_orthogonal)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'initialization method [{:s}] not implemented'.format(init_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c61f8ed",
   "metadata": {},
   "source": [
    "Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "def define_G(opt):\n",
    "    model_opt = opt['model']\n",
    "    if ('norm_groups' not in model_opt['unet']) or model_opt['unet']['norm_groups'] is None:\n",
    "        model_opt['unet']['norm_groups']=32\n",
    "    model = UNet(\n",
    "        in_channel=model_opt['unet']['in_channel'],\n",
    "        out_channel=model_opt['unet']['out_channel'],\n",
    "        norm_groups=model_opt['unet']['norm_groups'],\n",
    "        inner_channel=model_opt['unet']['inner_channel'],\n",
    "        channel_mults=model_opt['unet']['channel_multiplier'],\n",
    "        attn_res=model_opt['unet']['attn_res'],\n",
    "        res_blocks=model_opt['unet']['res_blocks'],\n",
    "        dropout=model_opt['unet']['dropout'],\n",
    "        image_size=model_opt['diffusion']['image_size']\n",
    "    )\n",
    "    netG = GaussianDiffusion(\n",
    "        model,\n",
    "        image_size=model_opt['diffusion']['image_size'],\n",
    "        channels=model_opt['diffusion']['channels'],\n",
    "        loss_type='l2',    # L1 or L2\n",
    "        conditional=model_opt['diffusion']['conditional'],\n",
    "        schedule_opt=model_opt['beta_schedule']['train']\n",
    "    )\n",
    "    if opt['phase'] == 'train':\n",
    "        # init_weights(netG, init_type='kaiming', scale=0.1)\n",
    "        init_weights(netG, init_type='orthogonal')\n",
    "    if opt['gpu_ids']:\n",
    "        assert torch.cuda.is_available()\n",
    "    return netG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e687dd65",
   "metadata": {
    "papermill": {
     "duration": 0.004894,
     "end_time": "2025-06-23T20:37:43.460742",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.455848",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbcbada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:43.471983Z",
     "iopub.status.busy": "2025-06-23T20:37:43.471689Z",
     "iopub.status.idle": "2025-06-23T20:37:43.492599Z",
     "shell.execute_reply": "2025-06-23T20:37:43.492060Z"
    },
    "papermill": {
     "duration": 0.02799,
     "end_time": "2025-06-23T20:37:43.493679",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.465689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SR3():\n",
    "\n",
    "    def __init__(self, opt):       \n",
    "        self.opt = opt\n",
    "        self.device = torch.device(\n",
    "            'cuda' if opt['gpu_ids'] is not None else 'cpu')\n",
    "\n",
    "        # mixed precision training\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        self.begin_step = 0\n",
    "        self.begin_epoch = 0\n",
    "        # define network and load pretrained models\n",
    "        self.netG = self.set_device(define_G(opt))\n",
    "        self.schedule_phase = None\n",
    "        \n",
    "\n",
    "        # set loss and load resume state\n",
    "        self.set_loss()\n",
    "        self.set_new_noise_schedule(\n",
    "            opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "        if self.opt['phase'] == 'train':\n",
    "            self.netG.train()\n",
    "            # find the parameters to optimize\n",
    "            if opt['model']['finetune_norm']:\n",
    "                optim_params = []\n",
    "                for k, v in self.netG.named_parameters():\n",
    "                    v.requires_grad = False\n",
    "                    if k.find('transformer') >= 0:\n",
    "                        v.requires_grad = True\n",
    "                        v.data.zero_()\n",
    "                        optim_params.append(v)\n",
    "                        logger.info(\n",
    "                            'Params [{:s}] initialized to 0 and will optimize.'.format(k))\n",
    "            else:\n",
    "                optim_params = list(self.netG.parameters())\n",
    "\n",
    "            self.optG = torch.optim.Adam(\n",
    "                optim_params, lr=opt['train'][\"optimizer\"][\"lr\"],\n",
    "                weight_decay=1e-6)\n",
    "\n",
    "            #learning rate scheduler\n",
    "            self.schedulerG = lr_scheduler.CosineAnnealingLR(\n",
    "                self.optG, T_max=self.opt['train']['n_iter'], eta_min=1e-6)\n",
    "            \n",
    "            self.log_dict = OrderedDict()\n",
    "        self.load_network()\n",
    "        self.print_network()\n",
    "\n",
    "    def set_device(self, x):\n",
    "        if isinstance(x, dict):\n",
    "            for key, item in x.items():\n",
    "                if item is not None and type(item)==torch.Tensor:\n",
    "                    x[key] = item.to(self.device)\n",
    "        elif isinstance(x, list):\n",
    "            for item in x:\n",
    "                if item is not None:\n",
    "                    item = item.to(self.device)\n",
    "        else:\n",
    "            x = x.to(self.device)\n",
    "        return x\n",
    "\n",
    "    def get_network_description(self, network):\n",
    "        '''Get the string and total parameters of the network'''\n",
    "        if isinstance(network, nn.DataParallel):\n",
    "            network = network.module\n",
    "        s = str(network)\n",
    "        n = sum(map(lambda x: x.numel(), network.parameters()))\n",
    "        return s, n\n",
    "\n",
    "    def feed_data(self, data):\n",
    "        self.data = self.set_device(data)\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.optG.zero_grad()\n",
    "\n",
    "        # mixed precision\n",
    "        with torch.cuda.amp.autocast(): \n",
    "            l_pix = self.netG(self.data)\n",
    "            b, c, h, w = self.data['GT'].shape\n",
    "            l_pix = l_pix.sum()/int(b*c*h*w)\n",
    "\n",
    "        self.scaler.scale(l_pix).backward()\n",
    "\n",
    "        # Unscale gradients before clipping (if using GradScaler)\n",
    "        self.scaler.unscale_(self.optG)\n",
    "        torch.nn.utils.clip_grad_norm_(self.netG.parameters(), max_norm=1.0) \n",
    "\n",
    "        self.scaler.step(self.optG)\n",
    "        self.scaler.update()  \n",
    "\n",
    "        #scheduler step\n",
    "        self.schedulerG.step()\n",
    "\n",
    "        # set log\n",
    "        self.log_dict['l_pix'] = l_pix.item()\n",
    "\n",
    "        return l_pix.item()\n",
    "\n",
    "    def evaluate_loss(self, data):\n",
    "        \"\"\"\n",
    "        Calculates the diffusion loss for a given batch of data without training.\n",
    "        Sets model to eval mode and uses torch.no_grad() for efficiency.\n",
    "        \"\"\"\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            self.feed_data(data)\n",
    "     \n",
    "            with torch.cuda.amp.autocast():\n",
    "                l_pix = self.netG(self.data)\n",
    "                b, c, h, w = self.data['GT'].shape\n",
    "                l_pix = l_pix.sum() / int(b * c * h * w)\n",
    "        self.netG.train() \n",
    "        return l_pix.item()\n",
    "    \n",
    "    def test(self, continous=False):\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            noisy_input = self.data['Noisy']\n",
    "            mask_input = self.data['Mask']\n",
    "            \n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.SR = self.netG.module.super_resolution(\n",
    "                    noisy_input, mask_input, continous)\n",
    "            else:\n",
    "                self.SR = self.netG.super_resolution(\n",
    "                    noisy_input, mask_input, continous)\n",
    "        self.netG.train()\n",
    "\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.SR = self.netG.module.sample(batch_size, continous)\n",
    "            else:\n",
    "                self.SR = self.netG.sample(batch_size, continous)\n",
    "        self.netG.train()\n",
    "\n",
    "    def set_loss(self):\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            self.netG.module.set_loss(self.device)\n",
    "        else:\n",
    "            self.netG.set_loss(self.device)\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, schedule_phase='train'):\n",
    "        if self.schedule_phase is None or self.schedule_phase != schedule_phase:\n",
    "            self.schedule_phase = schedule_phase\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.netG.module.set_new_noise_schedule(\n",
    "                    schedule_opt, self.device)\n",
    "            else:\n",
    "                self.netG.set_new_noise_schedule(schedule_opt, self.device)\n",
    "\n",
    "    def get_current_log(self):\n",
    "        return self.log_dict\n",
    "\n",
    "    def get_current_visuals(self, need_LR=True, sample=False):\n",
    "        out_dict = OrderedDict()\n",
    "        if sample:\n",
    "            out_dict['SAM'] = self.SR.detach().float().cpu()\n",
    "        else:\n",
    "            out_dict['SR'] = self.SR.detach().float().cpu()\n",
    "            out_dict['Noisy'] = self.data['Noisy'].detach().float().cpu()\n",
    "            out_dict['GT'] = self.data['GT'].detach().float().cpu()\n",
    "        return out_dict\n",
    "\n",
    "    def print_network(self):\n",
    "        s, n = self.get_network_description(self.netG)\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            net_struc_str = '{} - {}'.format(self.netG.__class__.__name__,\n",
    "                                             self.netG.module.__class__.__name__)\n",
    "        else:\n",
    "            net_struc_str = '{}'.format(self.netG.__class__.__name__)\n",
    "\n",
    "        logger.info(\n",
    "            'Network G structure: {}, with parameters: {:,d}'.format(net_struc_str, n))\n",
    "        logger.info(s)\n",
    "\n",
    "    def save_network(self, epoch, iter_step, is_final=False):\n",
    "        if is_final:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        else:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        # gen\n",
    "        network = self.netG\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            network = network.module\n",
    "        state_dict = network.state_dict()\n",
    "        for key, param in state_dict.items():\n",
    "            state_dict[key] = param.cpu()\n",
    "        torch.save(state_dict, gen_path)\n",
    "        # opt\n",
    "        opt_state = {'epoch': epoch, 'iter': iter_step,\n",
    "                     'scheduler': None, 'optimizer': None}\n",
    "        opt_state['optimizer'] = self.optG.state_dict()\n",
    "        torch.save(opt_state, opt_path)\n",
    "\n",
    "        logger.info(\n",
    "            'Saved model in [{:s}] ...'.format(gen_path))\n",
    "\n",
    "    def load_network(self):\n",
    "        load_path = self.opt['path']['resume_state']\n",
    "        if load_path is not None:\n",
    "            logger.info(\n",
    "                'Loading pretrained model for G [{:s}] ...'.format(load_path))\n",
    "            gen_path = '{}_gen.pth'.format(load_path)\n",
    "            opt_path = '{}_opt.pth'.format(load_path)\n",
    "            # gen\n",
    "            network = self.netG\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                network = network.module\n",
    "            network.load_state_dict(torch.load(\n",
    "                gen_path), strict=(not self.opt['model']['finetune_norm']))\n",
    "\n",
    "            if self.opt['phase'] == 'train':\n",
    "                # optimizer\n",
    "                opt = torch.load(opt_path)\n",
    "                self.optG.load_state_dict(opt['optimizer'])\n",
    "                self.begin_step = opt['iter']\n",
    "                self.begin_epoch = opt['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88118f4",
   "metadata": {
    "papermill": {
     "duration": 0.004873,
     "end_time": "2025-06-23T20:37:43.503691",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.498818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a3c12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:43.514514Z",
     "iopub.status.busy": "2025-06-23T20:37:43.514118Z",
     "iopub.status.idle": "2025-06-23T20:37:49.747143Z",
     "shell.execute_reply": "2025-06-23T20:37:49.746282Z"
    },
    "papermill": {
     "duration": 6.240274,
     "end_time": "2025-06-23T20:37:49.748959",
     "exception": false,
     "start_time": "2025-06-23T20:37:43.508685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1314524419.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler()\n",
      "25-06-23 20:37:43.944 - INFO: Initialization method [orthogonal]\n",
      "25-06-23 20:37:49.742 - INFO: Network G structure: GaussianDiffusion, with parameters: 42,051,969\n",
      "25-06-23 20:37:49.743 - INFO: GaussianDiffusion(\n",
      "  (denoise_fn): UNet(\n",
      "    (noise_level_mlp): Sequential(\n",
      "      (0): PositionalEncoding()\n",
      "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (2): Swish()\n",
      "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "    )\n",
      "    (downs): ModuleList(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Downsample(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): Downsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (5): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (6): Downsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (attn): SelfAttention(\n",
      "          (norm): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "          (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mid): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "        (attn): SelfAttention(\n",
      "          (norm): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "          (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ups): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (attn): SelfAttention(\n",
      "          (norm): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "          (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (attn): SelfAttention(\n",
      "          (norm): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "          (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (6): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (8): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (9): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (10): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Dropout(p=0.1, inplace=False)\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): Block(\n",
      "      (block): Sequential(\n",
      "        (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "        (1): Swish()\n",
      "        (2): Identity()\n",
      "        (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss_func): MSELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "diffusion = SR3(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf91c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:37:49.762285Z",
     "iopub.status.busy": "2025-06-23T20:37:49.761605Z",
     "iopub.status.idle": "2025-06-24T05:44:05.767526Z",
     "shell.execute_reply": "2025-06-24T05:44:05.766914Z"
    },
    "papermill": {
     "duration": 32776.013453,
     "end_time": "2025-06-24T05:44:05.768654",
     "exception": false,
     "start_time": "2025-06-23T20:37:49.755201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1314524419.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(): # <--- Add this context manager\n",
      "25-06-23 20:42:32.329 - INFO: <epoch:  1, iter:     100> l_pix: 6.8591e-02 \n",
      "25-06-23 20:45:33.650 - INFO: <epoch:  1, iter:     200> l_pix: 4.0743e-02 \n",
      "25-06-23 20:48:34.797 - INFO: <epoch:  1, iter:     300> l_pix: 4.0823e-02 \n",
      "25-06-23 20:51:35.950 - INFO: <epoch:  1, iter:     400> l_pix: 2.7566e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.20184037442836497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 20:54:38.249 - INFO: <epoch:  2, iter:     500> l_pix: 1.6971e-01 \n",
      "25-06-23 20:57:39.558 - INFO: <epoch:  2, iter:     600> l_pix: 2.6395e-02 \n",
      "25-06-23 21:00:40.696 - INFO: <epoch:  2, iter:     700> l_pix: 3.6169e-02 \n",
      "25-06-23 21:03:41.849 - INFO: <epoch:  2, iter:     800> l_pix: 1.8330e-02 \n",
      "25-06-23 21:06:43.017 - INFO: <epoch:  2, iter:     900> l_pix: 1.3735e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.08586113380061255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 21:09:45.560 - INFO: <epoch:  3, iter:   1,000> l_pix: 2.7249e-02 \n",
      "25-06-23 21:12:46.716 - INFO: <epoch:  3, iter:   1,100> l_pix: 1.4435e-02 \n",
      "25-06-23 21:15:47.874 - INFO: <epoch:  3, iter:   1,200> l_pix: 1.1901e-02 \n",
      "25-06-23 21:18:49.027 - INFO: <epoch:  3, iter:   1,300> l_pix: 3.0016e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.07985949934356742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 21:21:51.566 - INFO: <epoch:  4, iter:   1,400> l_pix: 3.2783e-01 \n",
      "25-06-23 21:24:52.723 - INFO: <epoch:  4, iter:   1,500> l_pix: 1.2054e-02 \n",
      "25-06-23 21:27:53.886 - INFO: <epoch:  4, iter:   1,600> l_pix: 7.4098e-02 \n",
      "25-06-23 21:30:55.039 - INFO: <epoch:  4, iter:   1,700> l_pix: 9.1579e-03 \n",
      "25-06-23 21:33:56.205 - INFO: <epoch:  4, iter:   1,800> l_pix: 1.2586e-02 \n",
      "25-06-23 21:33:56.206 - INFO: Saving models and training states.\n",
      "25-06-23 21:33:57.056 - INFO: Saved model in [/kaggle/working/checkpoint/I1800_E4_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.08906318487806453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 21:36:59.623 - INFO: <epoch:  5, iter:   1,900> l_pix: 9.1028e-03 \n",
      "25-06-23 21:40:00.770 - INFO: <epoch:  5, iter:   2,000> l_pix: 2.0125e-02 \n",
      "25-06-23 21:43:01.917 - INFO: <epoch:  5, iter:   2,100> l_pix: 2.7869e-02 \n",
      "25-06-23 21:46:03.067 - INFO: <epoch:  5, iter:   2,200> l_pix: 1.6958e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.06878256116786764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 21:49:05.704 - INFO: <epoch:  6, iter:   2,300> l_pix: 1.3637e-02 \n",
      "25-06-23 21:52:06.870 - INFO: <epoch:  6, iter:   2,400> l_pix: 8.9097e-03 \n",
      "25-06-23 21:55:08.038 - INFO: <epoch:  6, iter:   2,500> l_pix: 9.4833e-02 \n",
      "25-06-23 21:58:09.207 - INFO: <epoch:  6, iter:   2,600> l_pix: 1.8271e-01 \n",
      "25-06-23 22:01:10.365 - INFO: <epoch:  6, iter:   2,700> l_pix: 6.8747e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.05979896244282524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 22:04:12.986 - INFO: <epoch:  7, iter:   2,800> l_pix: 5.5219e-03 \n",
      "25-06-23 22:07:14.156 - INFO: <epoch:  7, iter:   2,900> l_pix: 1.4172e-01 \n",
      "25-06-23 22:10:15.303 - INFO: <epoch:  7, iter:   3,000> l_pix: 1.8219e-01 \n",
      "25-06-23 22:13:16.444 - INFO: <epoch:  7, iter:   3,100> l_pix: 5.5446e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.06266896576310198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 22:16:19.136 - INFO: <epoch:  8, iter:   3,200> l_pix: 2.0611e-02 \n",
      "25-06-23 22:19:20.286 - INFO: <epoch:  8, iter:   3,300> l_pix: 5.9816e-03 \n",
      "25-06-23 22:22:21.444 - INFO: <epoch:  8, iter:   3,400> l_pix: 7.5819e-02 \n",
      "25-06-23 22:25:22.587 - INFO: <epoch:  8, iter:   3,500> l_pix: 9.0140e-03 \n",
      "25-06-23 22:28:23.733 - INFO: <epoch:  8, iter:   3,600> l_pix: 5.3379e-01 \n",
      "25-06-23 22:28:23.734 - INFO: Saving models and training states.\n",
      "25-06-23 22:28:24.560 - INFO: Saved model in [/kaggle/working/checkpoint/I3600_E8_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.06125485396530065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 22:31:27.027 - INFO: <epoch:  9, iter:   3,700> l_pix: 2.9899e-01 \n",
      "25-06-23 22:34:28.196 - INFO: <epoch:  9, iter:   3,800> l_pix: 6.2444e-02 \n",
      "25-06-23 22:37:29.339 - INFO: <epoch:  9, iter:   3,900> l_pix: 4.0743e-02 \n",
      "25-06-23 22:40:30.495 - INFO: <epoch:  9, iter:   4,000> l_pix: 5.8880e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04846959919668734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 22:43:33.198 - INFO: <epoch: 10, iter:   4,100> l_pix: 2.8251e-02 \n",
      "25-06-23 22:46:34.372 - INFO: <epoch: 10, iter:   4,200> l_pix: 5.3296e-03 \n",
      "25-06-23 22:49:35.530 - INFO: <epoch: 10, iter:   4,300> l_pix: 1.2203e-02 \n",
      "25-06-23 22:52:36.694 - INFO: <epoch: 10, iter:   4,400> l_pix: 1.9737e-01 \n",
      "25-06-23 22:55:37.823 - INFO: <epoch: 10, iter:   4,500> l_pix: 7.3273e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.05451242830707795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 22:58:40.564 - INFO: <epoch: 11, iter:   4,600> l_pix: 1.4010e-02 \n",
      "25-06-23 23:01:41.726 - INFO: <epoch: 11, iter:   4,700> l_pix: 3.7330e-02 \n",
      "25-06-23 23:04:42.879 - INFO: <epoch: 11, iter:   4,800> l_pix: 1.5871e-02 \n",
      "25-06-23 23:07:44.039 - INFO: <epoch: 11, iter:   4,900> l_pix: 1.8523e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04832744118757546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 23:10:46.588 - INFO: <epoch: 12, iter:   5,000> l_pix: 1.2150e-02 \n",
      "25-06-23 23:13:47.744 - INFO: <epoch: 12, iter:   5,100> l_pix: 1.2389e-01 \n",
      "25-06-23 23:16:48.883 - INFO: <epoch: 12, iter:   5,200> l_pix: 7.3284e-02 \n",
      "25-06-23 23:19:50.033 - INFO: <epoch: 12, iter:   5,300> l_pix: 1.2969e-01 \n",
      "25-06-23 23:22:51.188 - INFO: <epoch: 12, iter:   5,400> l_pix: 7.0702e-03 \n",
      "25-06-23 23:22:51.189 - INFO: Saving models and training states.\n",
      "25-06-23 23:22:51.992 - INFO: Saved model in [/kaggle/working/checkpoint/I5400_E12_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.05679146895236853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 23:25:54.477 - INFO: <epoch: 13, iter:   5,500> l_pix: 6.4563e-03 \n",
      "25-06-23 23:28:55.640 - INFO: <epoch: 13, iter:   5,600> l_pix: 1.1489e-02 \n",
      "25-06-23 23:31:56.800 - INFO: <epoch: 13, iter:   5,700> l_pix: 8.2947e-03 \n",
      "25-06-23 23:34:57.980 - INFO: <epoch: 13, iter:   5,800> l_pix: 2.5369e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.0525455779944443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 23:38:00.480 - INFO: <epoch: 14, iter:   5,900> l_pix: 5.6528e-03 \n",
      "25-06-23 23:41:01.651 - INFO: <epoch: 14, iter:   6,000> l_pix: 4.4706e-03 \n",
      "25-06-23 23:44:02.810 - INFO: <epoch: 14, iter:   6,100> l_pix: 6.3310e-03 \n",
      "25-06-23 23:47:04.033 - INFO: <epoch: 14, iter:   6,200> l_pix: 2.1402e-01 \n",
      "25-06-23 23:50:05.179 - INFO: <epoch: 14, iter:   6,300> l_pix: 1.8693e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04927208459780862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 23:53:07.573 - INFO: <epoch: 15, iter:   6,400> l_pix: 7.9475e-03 \n",
      "25-06-23 23:56:08.716 - INFO: <epoch: 15, iter:   6,500> l_pix: 5.0496e-03 \n",
      "25-06-23 23:59:09.989 - INFO: <epoch: 15, iter:   6,600> l_pix: 1.3921e-02 \n",
      "25-06-24 00:02:11.136 - INFO: <epoch: 15, iter:   6,700> l_pix: 7.6952e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04591639588638726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 00:05:13.712 - INFO: <epoch: 16, iter:   6,800> l_pix: 8.5308e-02 \n",
      "25-06-24 00:08:14.864 - INFO: <epoch: 16, iter:   6,900> l_pix: 1.0411e-02 \n",
      "25-06-24 00:11:16.170 - INFO: <epoch: 16, iter:   7,000> l_pix: 2.8227e-02 \n",
      "25-06-24 00:14:17.357 - INFO: <epoch: 16, iter:   7,100> l_pix: 7.4013e-03 \n",
      "25-06-24 00:17:18.536 - INFO: <epoch: 16, iter:   7,200> l_pix: 6.7654e-03 \n",
      "25-06-24 00:17:18.537 - INFO: Saving models and training states.\n",
      "25-06-24 00:17:19.318 - INFO: Saved model in [/kaggle/working/checkpoint/I7200_E16_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.049215639841018455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 00:20:21.919 - INFO: <epoch: 17, iter:   7,300> l_pix: 4.9683e-03 \n",
      "25-06-24 00:23:23.098 - INFO: <epoch: 17, iter:   7,400> l_pix: 1.2787e-02 \n",
      "25-06-24 00:26:24.328 - INFO: <epoch: 17, iter:   7,500> l_pix: 3.2674e-03 \n",
      "25-06-24 00:29:25.494 - INFO: <epoch: 17, iter:   7,600> l_pix: 3.6229e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04287198286710514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 00:32:27.943 - INFO: <epoch: 18, iter:   7,700> l_pix: 1.0400e-01 \n",
      "25-06-24 00:35:29.292 - INFO: <epoch: 18, iter:   7,800> l_pix: 8.3108e-03 \n",
      "25-06-24 00:38:30.456 - INFO: <epoch: 18, iter:   7,900> l_pix: 7.9852e-03 \n",
      "25-06-24 00:41:31.618 - INFO: <epoch: 18, iter:   8,000> l_pix: 2.2225e-02 \n",
      "25-06-24 00:44:32.726 - INFO: <epoch: 18, iter:   8,100> l_pix: 2.9594e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.046427767946798766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 00:47:35.420 - INFO: <epoch: 19, iter:   8,200> l_pix: 6.5218e-03 \n",
      "25-06-24 00:50:36.510 - INFO: <epoch: 19, iter:   8,300> l_pix: 2.0816e-02 \n",
      "25-06-24 00:53:37.617 - INFO: <epoch: 19, iter:   8,400> l_pix: 3.1921e-03 \n",
      "25-06-24 00:56:38.722 - INFO: <epoch: 19, iter:   8,500> l_pix: 3.0356e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.05139212550078001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 00:59:41.280 - INFO: <epoch: 20, iter:   8,600> l_pix: 3.0474e-02 \n",
      "25-06-24 01:02:42.437 - INFO: <epoch: 20, iter:   8,700> l_pix: 5.6376e-02 \n",
      "25-06-24 01:05:43.586 - INFO: <epoch: 20, iter:   8,800> l_pix: 3.5143e-03 \n",
      "25-06-24 01:08:44.746 - INFO: <epoch: 20, iter:   8,900> l_pix: 9.4258e-03 \n",
      "25-06-24 01:11:45.926 - INFO: <epoch: 20, iter:   9,000> l_pix: 9.5662e-02 \n",
      "25-06-24 01:11:45.927 - INFO: Saving models and training states.\n",
      "25-06-24 01:11:46.741 - INFO: Saved model in [/kaggle/working/checkpoint/I9000_E20_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.05157966233789921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 01:14:49.370 - INFO: <epoch: 21, iter:   9,100> l_pix: 2.8985e-02 \n",
      "25-06-24 01:17:50.553 - INFO: <epoch: 21, iter:   9,200> l_pix: 2.4047e-02 \n",
      "25-06-24 01:20:51.725 - INFO: <epoch: 21, iter:   9,300> l_pix: 6.8952e-03 \n",
      "25-06-24 01:23:52.884 - INFO: <epoch: 21, iter:   9,400> l_pix: 2.8543e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04463545130203581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 01:26:55.518 - INFO: <epoch: 22, iter:   9,500> l_pix: 2.9408e-03 \n",
      "25-06-24 01:29:56.848 - INFO: <epoch: 22, iter:   9,600> l_pix: 8.1110e-02 \n",
      "25-06-24 01:32:58.019 - INFO: <epoch: 22, iter:   9,700> l_pix: 8.1917e-02 \n",
      "25-06-24 01:35:59.176 - INFO: <epoch: 22, iter:   9,800> l_pix: 1.8131e-02 \n",
      "25-06-24 01:39:00.342 - INFO: <epoch: 22, iter:   9,900> l_pix: 2.9886e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04495555074523307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 01:42:02.958 - INFO: <epoch: 23, iter:  10,000> l_pix: 5.1604e-03 \n",
      "25-06-24 01:45:04.134 - INFO: <epoch: 23, iter:  10,100> l_pix: 4.2519e-03 \n",
      "25-06-24 01:48:05.340 - INFO: <epoch: 23, iter:  10,200> l_pix: 4.8298e-03 \n",
      "25-06-24 01:51:06.499 - INFO: <epoch: 23, iter:  10,300> l_pix: 4.7502e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.040477345331778956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 01:54:09.122 - INFO: <epoch: 24, iter:  10,400> l_pix: 1.4659e-02 \n",
      "25-06-24 01:57:10.277 - INFO: <epoch: 24, iter:  10,500> l_pix: 2.6864e-03 \n",
      "25-06-24 02:00:11.452 - INFO: <epoch: 24, iter:  10,600> l_pix: 7.1830e-03 \n",
      "25-06-24 02:03:12.621 - INFO: <epoch: 24, iter:  10,700> l_pix: 6.4603e-03 \n",
      "25-06-24 02:06:13.784 - INFO: <epoch: 24, iter:  10,800> l_pix: 2.7228e-01 \n",
      "25-06-24 02:06:13.785 - INFO: Saving models and training states.\n",
      "25-06-24 02:06:14.537 - INFO: Saved model in [/kaggle/working/checkpoint/I10800_E24_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04319603762951576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 02:09:16.961 - INFO: <epoch: 25, iter:  10,900> l_pix: 7.7157e-02 \n",
      "25-06-24 02:12:18.126 - INFO: <epoch: 25, iter:  11,000> l_pix: 8.9082e-03 \n",
      "25-06-24 02:15:19.278 - INFO: <epoch: 25, iter:  11,100> l_pix: 2.3929e-02 \n",
      "25-06-24 02:18:20.477 - INFO: <epoch: 25, iter:  11,200> l_pix: 1.4859e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.03667893422094898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 02:21:23.114 - INFO: <epoch: 26, iter:  11,300> l_pix: 2.4995e-02 \n",
      "25-06-24 02:24:24.300 - INFO: <epoch: 26, iter:  11,400> l_pix: 9.7680e-03 \n",
      "25-06-24 02:27:25.480 - INFO: <epoch: 26, iter:  11,500> l_pix: 2.1213e-02 \n",
      "25-06-24 02:30:26.762 - INFO: <epoch: 26, iter:  11,600> l_pix: 6.2455e-02 \n",
      "25-06-24 02:33:27.937 - INFO: <epoch: 26, iter:  11,700> l_pix: 3.3317e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04688141434246467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 02:36:30.462 - INFO: <epoch: 27, iter:  11,800> l_pix: 2.6679e-02 \n",
      "25-06-24 02:39:31.822 - INFO: <epoch: 27, iter:  11,900> l_pix: 4.2128e-03 \n",
      "25-06-24 02:42:33.013 - INFO: <epoch: 27, iter:  12,000> l_pix: 2.3345e-03 \n",
      "25-06-24 02:45:34.190 - INFO: <epoch: 27, iter:  12,100> l_pix: 4.6015e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04176093319017026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 02:48:36.787 - INFO: <epoch: 28, iter:  12,200> l_pix: 4.1680e-02 \n",
      "25-06-24 02:51:38.135 - INFO: <epoch: 28, iter:  12,300> l_pix: 1.4238e-01 \n",
      "25-06-24 02:54:39.298 - INFO: <epoch: 28, iter:  12,400> l_pix: 5.6375e-03 \n",
      "25-06-24 02:57:40.457 - INFO: <epoch: 28, iter:  12,500> l_pix: 3.2013e-03 \n",
      "25-06-24 03:00:41.623 - INFO: <epoch: 28, iter:  12,600> l_pix: 9.9315e-02 \n",
      "25-06-24 03:00:41.623 - INFO: Saving models and training states.\n",
      "25-06-24 03:00:42.428 - INFO: Saved model in [/kaggle/working/checkpoint/I12600_E28_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.0383491902358623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 03:03:44.974 - INFO: <epoch: 29, iter:  12,700> l_pix: 2.5093e-01 \n",
      "25-06-24 03:06:46.151 - INFO: <epoch: 29, iter:  12,800> l_pix: 6.4767e-03 \n",
      "25-06-24 03:09:47.407 - INFO: <epoch: 29, iter:  12,900> l_pix: 1.2829e-02 \n",
      "25-06-24 03:12:48.571 - INFO: <epoch: 29, iter:  13,000> l_pix: 4.4230e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.03574839008454647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 03:15:51.004 - INFO: <epoch: 30, iter:  13,100> l_pix: 2.3009e-03 \n",
      "25-06-24 03:18:52.347 - INFO: <epoch: 30, iter:  13,200> l_pix: 2.3778e-03 \n",
      "25-06-24 03:21:53.525 - INFO: <epoch: 30, iter:  13,300> l_pix: 3.1687e-03 \n",
      "25-06-24 03:24:54.681 - INFO: <epoch: 30, iter:  13,400> l_pix: 1.2204e-02 \n",
      "25-06-24 03:27:55.844 - INFO: <epoch: 30, iter:  13,500> l_pix: 1.7383e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.041075975959603155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 03:30:58.530 - INFO: <epoch: 31, iter:  13,600> l_pix: 1.6879e-02 \n",
      "25-06-24 03:33:59.722 - INFO: <epoch: 31, iter:  13,700> l_pix: 2.8733e-03 \n",
      "25-06-24 03:37:00.878 - INFO: <epoch: 31, iter:  13,800> l_pix: 6.9178e-03 \n",
      "25-06-24 03:40:02.038 - INFO: <epoch: 31, iter:  13,900> l_pix: 8.0296e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.03665126723237336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 03:43:04.685 - INFO: <epoch: 32, iter:  14,000> l_pix: 1.1665e-02 \n",
      "25-06-24 03:46:05.883 - INFO: <epoch: 32, iter:  14,100> l_pix: 1.1541e-02 \n",
      "25-06-24 03:49:07.032 - INFO: <epoch: 32, iter:  14,200> l_pix: 2.3006e-03 \n",
      "25-06-24 03:52:08.204 - INFO: <epoch: 32, iter:  14,300> l_pix: 2.8985e-03 \n",
      "25-06-24 03:55:09.366 - INFO: <epoch: 32, iter:  14,400> l_pix: 3.5070e-03 \n",
      "25-06-24 03:55:09.367 - INFO: Saving models and training states.\n",
      "25-06-24 03:55:10.164 - INFO: Saved model in [/kaggle/working/checkpoint/I14400_E32_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.033211472714319824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 03:58:12.747 - INFO: <epoch: 33, iter:  14,500> l_pix: 4.2400e-03 \n",
      "25-06-24 04:01:13.918 - INFO: <epoch: 33, iter:  14,600> l_pix: 6.8199e-03 \n",
      "25-06-24 04:04:15.084 - INFO: <epoch: 33, iter:  14,700> l_pix: 2.2635e-03 \n",
      "25-06-24 04:07:16.272 - INFO: <epoch: 33, iter:  14,800> l_pix: 3.5222e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.039810155130301915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 04:10:18.783 - INFO: <epoch: 34, iter:  14,900> l_pix: 1.2911e-02 \n",
      "25-06-24 04:13:19.955 - INFO: <epoch: 34, iter:  15,000> l_pix: 2.3392e-01 \n",
      "25-06-24 04:16:21.107 - INFO: <epoch: 34, iter:  15,100> l_pix: 2.2145e-03 \n",
      "25-06-24 04:19:22.312 - INFO: <epoch: 34, iter:  15,200> l_pix: 1.2700e-02 \n",
      "25-06-24 04:22:23.482 - INFO: <epoch: 34, iter:  15,300> l_pix: 1.9986e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.0358422141822262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 04:25:25.975 - INFO: <epoch: 35, iter:  15,400> l_pix: 3.6775e-03 \n",
      "25-06-24 04:28:27.300 - INFO: <epoch: 35, iter:  15,500> l_pix: 6.7638e-03 \n",
      "25-06-24 04:31:28.472 - INFO: <epoch: 35, iter:  15,600> l_pix: 3.2135e-03 \n",
      "25-06-24 04:34:29.656 - INFO: <epoch: 35, iter:  15,700> l_pix: 6.7457e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.033536219341783885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 04:37:32.156 - INFO: <epoch: 36, iter:  15,800> l_pix: 4.3401e-02 \n",
      "25-06-24 04:40:33.430 - INFO: <epoch: 36, iter:  15,900> l_pix: 2.5172e-03 \n",
      "25-06-24 04:43:34.599 - INFO: <epoch: 36, iter:  16,000> l_pix: 5.5905e-03 \n",
      "25-06-24 04:46:35.772 - INFO: <epoch: 36, iter:  16,100> l_pix: 5.6166e-02 \n",
      "25-06-24 04:49:36.940 - INFO: <epoch: 36, iter:  16,200> l_pix: 6.9370e-02 \n",
      "25-06-24 04:49:36.942 - INFO: Saving models and training states.\n",
      "25-06-24 04:49:37.751 - INFO: Saved model in [/kaggle/working/checkpoint/I16200_E36_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.04073322481113589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 04:52:40.121 - INFO: <epoch: 37, iter:  16,300> l_pix: 1.6621e-02 \n",
      "25-06-24 04:55:41.410 - INFO: <epoch: 37, iter:  16,400> l_pix: 9.5984e-02 \n",
      "25-06-24 04:58:42.545 - INFO: <epoch: 37, iter:  16,500> l_pix: 3.9307e-03 \n",
      "25-06-24 05:01:43.704 - INFO: <epoch: 37, iter:  16,600> l_pix: 4.5701e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.031333279146088494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 05:04:46.204 - INFO: <epoch: 38, iter:  16,700> l_pix: 1.9628e-02 \n",
      "25-06-24 05:07:47.505 - INFO: <epoch: 38, iter:  16,800> l_pix: 2.8515e-01 \n",
      "25-06-24 05:10:48.670 - INFO: <epoch: 38, iter:  16,900> l_pix: 2.3939e-02 \n",
      "25-06-24 05:13:49.819 - INFO: <epoch: 38, iter:  17,000> l_pix: 1.2919e-02 \n",
      "25-06-24 05:16:50.978 - INFO: <epoch: 38, iter:  17,100> l_pix: 1.1654e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.0461842274117387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 05:19:53.673 - INFO: <epoch: 39, iter:  17,200> l_pix: 4.7350e-02 \n",
      "25-06-24 05:22:54.790 - INFO: <epoch: 39, iter:  17,300> l_pix: 1.6450e-02 \n",
      "25-06-24 05:25:55.908 - INFO: <epoch: 39, iter:  17,400> l_pix: 8.8375e-03 \n",
      "25-06-24 05:28:57.021 - INFO: <epoch: 39, iter:  17,500> l_pix: 5.3056e-03 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.041490775254141125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-24 05:31:59.547 - INFO: <epoch: 40, iter:  17,600> l_pix: 2.2089e-03 \n",
      "25-06-24 05:35:00.703 - INFO: <epoch: 40, iter:  17,700> l_pix: 2.2832e-03 \n",
      "25-06-24 05:38:01.840 - INFO: <epoch: 40, iter:  17,800> l_pix: 1.6452e-02 \n",
      "25-06-24 05:41:02.974 - INFO: <epoch: 40, iter:  17,900> l_pix: 1.5424e-02 \n",
      "25-06-24 05:44:04.095 - INFO: <epoch: 40, iter:  18,000> l_pix: 8.7398e-03 \n",
      "25-06-24 05:44:04.096 - INFO: Saving models and training states.\n",
      "25-06-24 05:44:04.851 - INFO: Saved model in [/kaggle/working/checkpoint/I18000_E40_gen.pth] ...\n",
      "25-06-24 05:44:04.853 - INFO: Saving final model\n",
      "25-06-24 05:44:05.648 - INFO: Saved model in [/kaggle/working/checkpoint/Final_I18000_E40_gen.pth] ...\n",
      "25-06-24 05:44:05.763 - INFO: End of training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.03496190855848706\n",
      "Epoch Loss List:  [0.20184037442836497, 0.08586113380061255, 0.07985949934356742, 0.08906318487806453, 0.06878256116786764, 0.05979896244282524, 0.06266896576310198, 0.06125485396530065, 0.04846959919668734, 0.05451242830707795, 0.04832744118757546, 0.05679146895236853, 0.0525455779944443, 0.04927208459780862, 0.04591639588638726, 0.049215639841018455, 0.04287198286710514, 0.046427767946798766, 0.05139212550078001, 0.05157966233789921, 0.04463545130203581, 0.04495555074523307, 0.040477345331778956, 0.04319603762951576, 0.03667893422094898, 0.04688141434246467, 0.04176093319017026, 0.0383491902358623, 0.03574839008454647, 0.041075975959603155, 0.03665126723237336, 0.033211472714319824, 0.039810155130301915, 0.0358422141822262, 0.033536219341783885, 0.04073322481113589, 0.031333279146088494, 0.0461842274117387, 0.041490775254141125, 0.03496190855848706]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epoch_loss_list = []\n",
    "\n",
    "current_step = diffusion.begin_step\n",
    "current_epoch = diffusion.begin_epoch\n",
    "n_iter = opt['train']['n_iter']\n",
    "\n",
    "if opt['path']['resume_state']:\n",
    "    logger.info('Resuming training from epoch: {}, iter: {}.'.format(\n",
    "        current_epoch, current_step))\n",
    "\n",
    "diffusion.set_new_noise_schedule(\n",
    "    opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])\n",
    "\n",
    "\n",
    "if opt['phase'] == 'train':\n",
    "    while current_step < n_iter:\n",
    "        current_epoch += 1\n",
    "        epoch_loss_values = []\n",
    "\n",
    "        diffusion.optG.zero_grad() \n",
    "        \n",
    "        for _, train_data in enumerate(train_loader): \n",
    "            current_step += 1\n",
    "            if current_step > n_iter:\n",
    "                break\n",
    "            diffusion.feed_data(train_data)\n",
    "\n",
    "            current_l_pix = diffusion.optimize_parameters()\n",
    "            epoch_loss_values.append(current_l_pix)\n",
    "                \n",
    "            # log\n",
    "            if current_step % opt['train']['print_freq'] == 0:\n",
    "                logs = diffusion.get_current_log()\n",
    "                message = '<epoch:{:3d}, iter:{:8,d}> '.format(\n",
    "                    current_epoch, current_step)\n",
    "                for k, v in logs.items():\n",
    "                    message += '{:s}: {:.4e} '.format(k, v)\n",
    "                logger.info(message)\n",
    "                \n",
    "            if current_step % opt['train']['save_checkpoint_freq'] == 0:\n",
    "                logger.info('Saving models and training states.')\n",
    "                diffusion.save_network(current_epoch, current_step)\n",
    "            \n",
    "            if current_step == n_iter:\n",
    "                logger.info(\"Saving final model\")\n",
    "                diffusion.save_network(current_epoch, current_step, is_final=True)\n",
    "\n",
    "\n",
    "        epoch_loss = sum(epoch_loss_values)/len(epoch_loss_values)\n",
    "        print('Epoch Loss: ', epoch_loss)\n",
    "        epoch_loss_list.append(epoch_loss)\n",
    "\n",
    "    # save model\n",
    "    print('Epoch Loss List: ', epoch_loss_list)\n",
    "    logger.info('End of training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a954b0",
   "metadata": {
    "papermill": {
     "duration": 0.014362,
     "end_time": "2025-06-24T05:44:05.798846",
     "exception": false,
     "start_time": "2025-06-24T05:44:05.784484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3f5d99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T05:44:05.829787Z",
     "iopub.status.busy": "2025-06-24T05:44:05.829504Z",
     "iopub.status.idle": "2025-06-24T05:44:05.834267Z",
     "shell.execute_reply": "2025-06-24T05:44:05.833714Z"
    },
    "papermill": {
     "duration": 0.021683,
     "end_time": "2025-06-24T05:44:05.835226",
     "exception": false,
     "start_time": "2025-06-24T05:44:05.813543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_loss_curve(epoch_loss_list, filename='loss_curve.png'):\n",
    "    epochs = range(1, len(epoch_loss_list) + 1)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, epoch_loss_list, marker='o', label='Training Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(epochs)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18df2716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T05:44:05.865271Z",
     "iopub.status.busy": "2025-06-24T05:44:05.865062Z",
     "iopub.status.idle": "2025-06-24T05:44:06.152410Z",
     "shell.execute_reply": "2025-06-24T05:44:06.151847Z"
    },
    "papermill": {
     "duration": 0.303979,
     "end_time": "2025-06-24T05:44:06.153779",
     "exception": false,
     "start_time": "2025-06-24T05:44:05.849800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_loss_curve(epoch_loss_list, \"/kaggle/working/train_loss.png\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7419713,
     "sourceId": 11813224,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7419718,
     "sourceId": 11813229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7419725,
     "sourceId": 11813237,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7421178,
     "sourceId": 11815303,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7717803,
     "sourceId": 12248669,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32831.911896,
   "end_time": "2025-06-24T05:44:09.569334",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-23T20:36:57.657438",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
