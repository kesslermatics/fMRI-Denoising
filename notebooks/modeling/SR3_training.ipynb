{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3541da",
   "metadata": {},
   "source": [
    "# Training of the SR3 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42da46",
   "metadata": {},
   "source": [
    "Based on https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement. Adaptions were made to fit our denoising objective instead of super-resolution and all relevant code parts were consolidated into this notebook to allow for Kaggle training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d91a519",
   "metadata": {
    "papermill": {
     "duration": 0.006813,
     "end_time": "2025-05-14T18:08:47.298305",
     "exception": false,
     "start_time": "2025-05-14T18:08:47.291492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e158f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:08:47.310701Z",
     "iopub.status.busy": "2025-05-14T18:08:47.310433Z",
     "iopub.status.idle": "2025-05-14T18:08:47.314463Z",
     "shell.execute_reply": "2025-05-14T18:08:47.313878Z"
    },
    "papermill": {
     "duration": 0.011744,
     "end_time": "2025-05-14T18:08:47.315609",
     "exception": false,
     "start_time": "2025-05-14T18:08:47.303865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c4ff90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:08:47.328387Z",
     "iopub.status.busy": "2025-05-14T18:08:47.328125Z",
     "iopub.status.idle": "2025-05-14T18:08:51.139274Z",
     "shell.execute_reply": "2025-05-14T18:08:51.138699Z"
    },
    "papermill": {
     "duration": 3.819653,
     "end_time": "2025-05-14T18:08:51.140677",
     "exception": false,
     "start_time": "2025-05-14T18:08:47.321024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import logging\n",
    "#from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from re import split\n",
    "import torch.utils.data\n",
    "\n",
    "# import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "import functools\n",
    "from torch.nn import init\n",
    "from torch.nn import modules\n",
    "\n",
    "# u-net\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from inspect import isfunction\n",
    "\n",
    "# diffusion\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012ff85",
   "metadata": {
    "papermill": {
     "duration": 0.004842,
     "end_time": "2025-05-14T18:08:51.150906",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.146064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f52608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:08:51.161635Z",
     "iopub.status.busy": "2025-05-14T18:08:51.161345Z",
     "iopub.status.idle": "2025-05-14T18:08:51.168064Z",
     "shell.execute_reply": "2025-05-14T18:08:51.167449Z"
    },
    "papermill": {
     "duration": 0.013557,
     "end_time": "2025-05-14T18:08:51.169266",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.155709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"denoising\",\n",
    "    \"phase\": \"train\", # train or test (or val?? -> what is phase even used for also?)\n",
    "    \"gpu_ids\": [0, 1], \n",
    "    \"debug\": False,  \n",
    "    \"enable_wandb\": False,  \n",
    "    \"log_wandb_ckpt\": False,  \n",
    "    \"log_eval\": False,  \n",
    "    \"path\": {\n",
    "        \"log\": \"/kaggle/working/logs\",\n",
    "        \"tb_logger\": \"/kaggle/working/tb_logger\",\n",
    "        \"results\": \"/kaggle/working/results\",\n",
    "        \"checkpoint\": \"/kaggle/working/checkpoint\",\n",
    "        \"resume_state\": None\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-train-1-norm-v3/data/noisy_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-norm-v3/data/noisy_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-norm-v3/data/noisy_func_train_3.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-train-1-norm-v3/data/gt_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-norm-v3/data/gt_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-norm-v3/data/gt_func_train_3.npy'],\n",
    "            \"batch_size\": 1,\n",
    "            \"num_workers\": 1,\n",
    "            \"use_shuffle\": True\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-test/data/noisy_func_test.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-test/data/gt_func_test.npy']\n",
    "        }\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\",\n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 2,\n",
    "            \"out_channel\": 1,\n",
    "            \"inner_channel\": 64,\n",
    "            \"norm_groups\": 16,\n",
    "            \"channel_multiplier\": [1, 2, 4, 8],\n",
    "            \"attn_res\": [],\n",
    "            \"res_blocks\": 1,\n",
    "            \"dropout\": 0\n",
    "        },\n",
    "        \"beta_schedule\": {\n",
    "            \"train\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 64,\n",
    "            \"channels\": 1,\n",
    "            \"conditional\": True\n",
    "        }\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"n_iter\": 4500,\n",
    "        \"val_freq\": 1e4,\n",
    "        \"save_checkpoint_freq\": 2700,\n",
    "        \"print_freq\": 100,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"lr\": 3e-4\n",
    "        },\n",
    "        \"ema_scheduler\": {\n",
    "            \"step_start_ema\": 22500,\n",
    "            \"update_ema_every\": 1,\n",
    "            \"ema_decay\": 0.996\n",
    "        }\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        \"project\": \"distributed_high_sr_ffhq\"\n",
    "    },\n",
    "    \"config_file\": \"config/sr_sr3_16_128.json\"  # from CLI\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054421f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:08:51.186733Z",
     "iopub.status.busy": "2025-05-14T18:08:51.185987Z",
     "iopub.status.idle": "2025-05-14T18:08:51.191100Z",
     "shell.execute_reply": "2025-05-14T18:08:51.190464Z"
    },
    "papermill": {
     "duration": 0.015697,
     "end_time": "2025-05-14T18:08:51.192212",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.176515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(opt['path']['log'], exist_ok=True)\n",
    "os.makedirs(opt['path']['tb_logger'], exist_ok=True)\n",
    "os.makedirs(opt['path']['results'], exist_ok=True)\n",
    "os.makedirs(opt['path']['checkpoint'], exist_ok=True)\n",
    "#os.makedirs(opt['path']['resume_state'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88547263",
   "metadata": {
    "papermill": {
     "duration": 0.009758,
     "end_time": "2025-05-14T18:08:51.206822",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.197064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145492ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:08:51.223151Z",
     "iopub.status.busy": "2025-05-14T18:08:51.222949Z",
     "iopub.status.idle": "2025-05-14T18:08:51.230528Z",
     "shell.execute_reply": "2025-05-14T18:08:51.229812Z"
    },
    "papermill": {
     "duration": 0.015604,
     "end_time": "2025-05-14T18:08:51.231644",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.216040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logging\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def dict2str(opt, indent_l=1):\n",
    "    '''dict to string for logger'''\n",
    "    msg = ''\n",
    "    for k, v in opt.items():\n",
    "        if isinstance(v, dict):\n",
    "            msg += ' ' * (indent_l * 2) + k + ':[\\n'\n",
    "            msg += dict2str(v, indent_l + 1)\n",
    "            msg += ' ' * (indent_l * 2) + ']\\n'\n",
    "        else:\n",
    "            msg += ' ' * (indent_l * 2) + k + ': ' + str(v) + '\\n'\n",
    "    return msg\n",
    "\n",
    "def setup_logger(logger_name, root, phase, level=logging.INFO, screen=False):\n",
    "    '''set up logger'''\n",
    "    l = logging.getLogger(logger_name)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s.%(msecs)03d - %(levelname)s: %(message)s', datefmt='%y-%m-%d %H:%M:%S')\n",
    "    log_file = os.path.join(root, '{}.log'.format(phase))\n",
    "    fh = logging.FileHandler(log_file, mode='w')\n",
    "    fh.setFormatter(formatter)\n",
    "    l.setLevel(level)\n",
    "    l.addHandler(fh)\n",
    "    if screen:\n",
    "        sh = logging.StreamHandler()\n",
    "        sh.setFormatter(formatter)\n",
    "        l.addHandler(sh)\n",
    "\n",
    "\n",
    "setup_logger(None, opt['path']['log'],\n",
    "                    'train', level=logging.INFO, screen=True)\n",
    "setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "logger = logging.getLogger('base')\n",
    "#logger.info(dict2str(opt))\n",
    "#tb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])\n",
    "\n",
    "# # Initialize WandbLogger\n",
    "# if opt['enable_wandb']:\n",
    "#     import wandb\n",
    "#     wandb_logger = WandbLogger(opt)\n",
    "#     wandb.define_metric('validation/val_step')\n",
    "#     wandb.define_metric('epoch')\n",
    "#     wandb.define_metric(\"validation/*\", step_metric=\"val_step\")\n",
    "#     val_step = 0\n",
    "# else:\n",
    "#     wandb_logger = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86523c6b",
   "metadata": {
    "papermill": {
     "duration": 0.004896,
     "end_time": "2025-05-14T18:08:51.241457",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.236561",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f10f6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:08:51.252236Z",
     "iopub.status.busy": "2025-05-14T18:08:51.252004Z",
     "iopub.status.idle": "2025-05-14T18:08:51.258610Z",
     "shell.execute_reply": "2025-05-14T18:08:51.258042Z"
    },
    "papermill": {
     "duration": 0.013298,
     "end_time": "2025-05-14T18:08:51.259675",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.246377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, noisy_images_paths: list, gt_images_paths: list):\n",
    "        \"\"\"Initialize fMRI dataset for denoising with memory-efficient loading.\n",
    "        \n",
    "        Args:\n",
    "            noisy_images_paths (list): List of paths to noisy fMRI volumes (.npy files)\n",
    "            gt_images_paths (list): List of paths to ground truth fMRI volumes (.npy files)\n",
    "        \"\"\"\n",
    "        self.noisy_paths = noisy_images_paths\n",
    "        self.gt_paths = gt_images_paths\n",
    "        \n",
    "        # Get the data shape and total slices without loading all data\n",
    "        # Just load file info and calculate indices\n",
    "        self.file_slice_mapping = []\n",
    "        self.z_t_dimension_sizes = []\n",
    "        total_slices = 0\n",
    "        dataset_length = 0 # in terms of indeces that can be iteratet over at the end (less than slice number due to batch loading within get_item)\n",
    "        \n",
    "        for i, path in enumerate(noisy_images_paths):\n",
    "            # Load metadata about the file shape without loading full content\n",
    "            data_shape = np.load(path, mmap_mode='r').shape\n",
    "            num_slices = data_shape[2] * data_shape[3]  # z * t\n",
    "            self.z_t_dimension_sizes.append((data_shape[2], data_shape[3]))\n",
    "            \n",
    "            # Store mapping information: which file and which t index (has been done due to more efficient data loading, no information aggregation based thinking behind that)\n",
    "            for batch_idx in range(0, data_shape[3]):\n",
    "                self.file_slice_mapping.append((i, batch_idx))\n",
    "                dataset_length += 1\n",
    "            \n",
    "            total_slices += num_slices \n",
    "            \n",
    "        self.data_len = dataset_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Use the mapping to determine which file and slice to load\n",
    "        file_idx, t_idx = self.file_slice_mapping[index]\n",
    "        \n",
    "        # Load data from the specific file\n",
    "        noisy_file_path = self.noisy_paths[file_idx]\n",
    "        gt_file_path = self.gt_paths[file_idx]\n",
    "        \n",
    "        # Load the full 4D array with mmap_mode to avoid loading everything\n",
    "        noisy_volume = np.load(noisy_file_path, mmap_mode='r')\n",
    "        gt_volume = np.load(gt_file_path, mmap_mode='r')\n",
    "        \n",
    "        # Extract only the slice we need\n",
    "        noisy_slice = noisy_volume[:, :, :, t_idx].copy()  # Force copy from mmap\n",
    "        gt_slice = gt_volume[:, :, :, t_idx].copy()\n",
    "        \n",
    "        return {\n",
    "            'GT': torch.tensor(gt_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Noisy': torch.tensor(noisy_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Index': index\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acd80d69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:08:51.270223Z",
     "iopub.status.busy": "2025-05-14T18:08:51.269994Z",
     "iopub.status.idle": "2025-05-14T18:08:51.275212Z",
     "shell.execute_reply": "2025-05-14T18:08:51.274552Z"
    },
    "papermill": {
     "duration": 0.011714,
     "end_time": "2025-05-14T18:08:51.276231",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.264517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_merge_batches(batch):\n",
    "    merged = {\n",
    "        'Noisy': torch.cat([item['Noisy'] for item in batch], dim=0),\n",
    "        'GT': torch.cat([item['GT'] for item in batch], dim=0),\n",
    "        'Index': [item['Index'] for item in batch]\n",
    "    }\n",
    "    return merged\n",
    "\n",
    "def create_dataloader(dataset, dataset_opt, phase):\n",
    "    '''create dataloader '''\n",
    "    if phase == 'train':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=dataset_opt['batch_size'],\n",
    "            shuffle=dataset_opt['use_shuffle'],\n",
    "            num_workers=dataset_opt['num_workers'],\n",
    "            pin_memory=True,\n",
    "            collate_fn = collate_merge_batches)\n",
    "    elif phase == 'test':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True, collate_fn = lambda x: x[0])\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Dataloader [{:s}] is not found.'.format(phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6d4ba9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:08:51.286629Z",
     "iopub.status.busy": "2025-05-14T18:08:51.286435Z",
     "iopub.status.idle": "2025-05-14T18:08:51.351802Z",
     "shell.execute_reply": "2025-05-14T18:08:51.351183Z"
    },
    "papermill": {
     "duration": 0.071983,
     "end_time": "2025-05-14T18:08:51.352987",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.281004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "for phase, dataset_opt in opt['datasets'].items():\n",
    "    if phase == 'train' and opt['phase'] != 'test':\n",
    "        train_set = PairwiseDataset(dataset_opt['noisy_data_paths'], dataset_opt['gt_data_paths'])\n",
    "        train_loader = create_dataloader(\n",
    "            train_set, dataset_opt, phase)\n",
    "    elif phase == 'test' and opt['phase'] != 'train':\n",
    "        test_set = PairwiseDataset(dataset_opt['noisy_data_paths'], dataset_opt['gt_data_paths'])\n",
    "        test_loader = create_dataloader(\n",
    "            test_set, dataset_opt, phase)\n",
    "# logger.info('Initial Dataset Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7477c29f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:08:51.364277Z",
     "iopub.status.busy": "2025-05-14T18:08:51.364013Z",
     "iopub.status.idle": "2025-05-14T18:09:20.091085Z",
     "shell.execute_reply": "2025-05-14T18:09:20.090289Z"
    },
    "papermill": {
     "duration": 28.734288,
     "end_time": "2025-05-14T18:09:20.092689",
     "exception": false,
     "start_time": "2025-05-14T18:08:51.358401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noisy_slice = train_set[400][\"Noisy\"]\n",
    "gt_slice = train_set[400][\"GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf83d7ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:09:20.104117Z",
     "iopub.status.busy": "2025-05-14T18:09:20.103879Z",
     "iopub.status.idle": "2025-05-14T18:09:20.106922Z",
     "shell.execute_reply": "2025-05-14T18:09:20.106377Z"
    },
    "papermill": {
     "duration": 0.009724,
     "end_time": "2025-05-14T18:09:20.108037",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.098313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for _, data in train_loader:\n",
    "#     print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e682fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:09:20.118803Z",
     "iopub.status.busy": "2025-05-14T18:09:20.118577Z",
     "iopub.status.idle": "2025-05-14T18:09:20.464352Z",
     "shell.execute_reply": "2025-05-14T18:09:20.463654Z"
    },
    "papermill": {
     "duration": 0.352377,
     "end_time": "2025-05-14T18:09:20.465420",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.113043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x78aa3f56b650>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot ground truth image\n",
    "axes[0].imshow(noisy_slice[0,0,:,:], cmap='gray')\n",
    "axes[1].imshow(gt_slice[0,0,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6de5f2",
   "metadata": {
    "papermill": {
     "duration": 0.005269,
     "end_time": "2025-05-14T18:09:20.476562",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.471293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44b809",
   "metadata": {
    "papermill": {
     "duration": 0.005258,
     "end_time": "2025-05-14T18:09:20.487250",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.481992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21d3df0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:09:20.498833Z",
     "iopub.status.busy": "2025-05-14T18:09:20.498629Z",
     "iopub.status.idle": "2025-05-14T18:09:20.502529Z",
     "shell.execute_reply": "2025-05-14T18:09:20.501827Z"
    },
    "papermill": {
     "duration": 0.011076,
     "end_time": "2025-05-14T18:09:20.503626",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.492550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generic functions\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d7c4452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:09:20.515519Z",
     "iopub.status.busy": "2025-05-14T18:09:20.515319Z",
     "iopub.status.idle": "2025-05-14T18:09:20.538798Z",
     "shell.execute_reply": "2025-05-14T18:09:20.538280Z"
    },
    "papermill": {
     "duration": 0.030837,
     "end_time": "2025-05-14T18:09:20.539787",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.508950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### U-Net ###\n",
    "\n",
    "# PositionalEncoding Source https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        count = self.dim // 2\n",
    "        step = torch.arange(count, dtype=noise_level.dtype,\n",
    "                            device=noise_level.device) / count\n",
    "        encoding = noise_level.unsqueeze(\n",
    "            1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n",
    "        encoding = torch.cat(\n",
    "            [torch.sin(encoding), torch.cos(encoding)], dim=-1)\n",
    "        return encoding\n",
    "\n",
    "\n",
    "class FeatureWiseAffine(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_affine_level=False):\n",
    "        super(FeatureWiseAffine, self).__init__()\n",
    "        self.use_affine_level = use_affine_level\n",
    "        self.noise_func = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, noise_embed):\n",
    "        batch = x.shape[0]\n",
    "        if self.use_affine_level:\n",
    "            gamma, beta = self.noise_func(noise_embed).view(\n",
    "                batch, -1, 1, 1).chunk(2, dim=1)\n",
    "            x = (1 + gamma) * x + beta\n",
    "        else:\n",
    "            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.up(x))\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# building block modules\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=32, dropout=0):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, dim),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32):\n",
    "        super().__init__()\n",
    "        self.noise_func = FeatureWiseAffine(\n",
    "            noise_level_emb_dim, dim_out, use_affine_level)\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=norm_groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout)\n",
    "        self.res_conv = nn.Conv2d(\n",
    "            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        b, c, h, w = x.shape\n",
    "        h = self.block1(x)\n",
    "        h = self.noise_func(h, time_emb)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channel, n_head=1, norm_groups=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.norm = nn.GroupNorm(norm_groups, in_channel)\n",
    "        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch, channel, height, width = input.shape\n",
    "        n_head = self.n_head\n",
    "        head_dim = channel // n_head\n",
    "\n",
    "        norm = self.norm(input)\n",
    "        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n",
    "        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n",
    "\n",
    "        attn = torch.einsum(\n",
    "            \"bnchw, bncyx -> bnhwyx\", query, key\n",
    "        ).contiguous() / math.sqrt(channel)\n",
    "        attn = attn.view(batch, n_head, height, width, -1)\n",
    "        attn = torch.softmax(attn, -1)\n",
    "        attn = attn.view(batch, n_head, height, width, height, width)\n",
    "\n",
    "        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n",
    "        out = self.out(out.view(batch, channel, height, width))\n",
    "\n",
    "        return out + input\n",
    "\n",
    "\n",
    "class ResnetBlocWithAttn(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False):\n",
    "        super().__init__()\n",
    "        self.with_attn = with_attn\n",
    "        self.res_block = ResnetBlock(\n",
    "            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout)\n",
    "        if with_attn:\n",
    "            self.attn = SelfAttention(dim_out, norm_groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        x = self.res_block(x, time_emb)\n",
    "        if(self.with_attn):\n",
    "            x = self.attn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=6,\n",
    "        out_channel=3,\n",
    "        inner_channel=32,\n",
    "        norm_groups=32,\n",
    "        channel_mults=(1, 2, 4, 8, 8),\n",
    "        attn_res=(8),\n",
    "        res_blocks=3,\n",
    "        dropout=0,\n",
    "        with_noise_level_emb=True,\n",
    "        image_size=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if with_noise_level_emb:\n",
    "            noise_level_channel = inner_channel\n",
    "            self.noise_level_mlp = nn.Sequential(\n",
    "                PositionalEncoding(inner_channel),\n",
    "                nn.Linear(inner_channel, inner_channel * 4),\n",
    "                Swish(),\n",
    "                nn.Linear(inner_channel * 4, inner_channel)\n",
    "            )\n",
    "        else:\n",
    "            noise_level_channel = None\n",
    "            self.noise_level_mlp = None\n",
    "\n",
    "        num_mults = len(channel_mults)\n",
    "        pre_channel = inner_channel\n",
    "        feat_channels = [pre_channel]\n",
    "        now_res = image_size\n",
    "        downs = [nn.Conv2d(in_channel, inner_channel,\n",
    "                           kernel_size=3, padding=1)]\n",
    "        for ind in range(num_mults):\n",
    "            is_last = (ind == num_mults - 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks):\n",
    "                downs.append(ResnetBlocWithAttn(\n",
    "                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn))\n",
    "                feat_channels.append(channel_mult)\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                downs.append(Downsample(pre_channel))\n",
    "                feat_channels.append(pre_channel)\n",
    "                now_res = now_res//2\n",
    "        self.downs = nn.ModuleList(downs)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=True),\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=False)\n",
    "        ])\n",
    "\n",
    "        ups = []\n",
    "        for ind in reversed(range(num_mults)):\n",
    "            is_last = (ind < 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks+1):\n",
    "                ups.append(ResnetBlocWithAttn(\n",
    "                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                        dropout=dropout, with_attn=use_attn))\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                ups.append(Upsample(pre_channel))\n",
    "                now_res = now_res*2\n",
    "\n",
    "        self.ups = nn.ModuleList(ups)\n",
    "\n",
    "        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        t = self.noise_level_mlp(time) if exists(\n",
    "            self.noise_level_mlp) else None\n",
    "\n",
    "        feats = []\n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        for layer in self.ups:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(torch.cat((x, feats.pop()), dim=1), t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98adbc65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:09:20.552018Z",
     "iopub.status.busy": "2025-05-14T18:09:20.551801Z",
     "iopub.status.idle": "2025-05-14T18:09:20.574501Z",
     "shell.execute_reply": "2025-05-14T18:09:20.573926Z"
    },
    "papermill": {
     "duration": 0.03017,
     "end_time": "2025-05-14T18:09:20.575668",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.545498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Diffusion ###\n",
    "def _warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n",
    "    betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    warmup_time = int(n_timestep * warmup_frac)\n",
    "    betas[:warmup_time] = np.linspace(\n",
    "        linear_start, linear_end, warmup_time, dtype=np.float64)\n",
    "    return betas\n",
    "\n",
    "\n",
    "def make_beta_schedule(schedule, n_timestep, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n",
    "    if schedule == 'quad':\n",
    "        betas = np.linspace(linear_start ** 0.5, linear_end ** 0.5,\n",
    "                            n_timestep, dtype=np.float64) ** 2\n",
    "    elif schedule == 'linear':\n",
    "        betas = np.linspace(linear_start, linear_end,\n",
    "                            n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'warmup10':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.1)\n",
    "    elif schedule == 'warmup50':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.5)\n",
    "    elif schedule == 'const':\n",
    "        betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        betas = 1. / np.linspace(n_timestep,\n",
    "                                 1, n_timestep, dtype=np.float64)\n",
    "    elif schedule == \"cosine\":\n",
    "        timesteps = (\n",
    "            torch.arange(n_timestep + 1, dtype=torch.float64) /\n",
    "            n_timestep + cosine_s\n",
    "        )\n",
    "        alphas = timesteps / (1 + cosine_s) * math.pi / 2\n",
    "        alphas = torch.cos(alphas).pow(2)\n",
    "        alphas = alphas / alphas[0]\n",
    "        betas = 1 - alphas[1:] / alphas[:-1]\n",
    "        betas = betas.clamp(max=0.999)\n",
    "    else:\n",
    "        raise NotImplementedError(schedule)\n",
    "    return betas\n",
    "\n",
    "\n",
    "# gaussian diffusion trainer class\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        denoise_fn,\n",
    "        image_size,\n",
    "        channels=3,\n",
    "        loss_type='l1',\n",
    "        conditional=True,\n",
    "        schedule_opt=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.denoise_fn = denoise_fn\n",
    "        self.loss_type = loss_type\n",
    "        self.conditional = conditional\n",
    "        if schedule_opt is not None:\n",
    "            pass\n",
    "            # self.set_new_noise_schedule(schedule_opt)\n",
    "\n",
    "    def set_loss(self, device):\n",
    "        if self.loss_type == 'l1':\n",
    "            self.loss_func = nn.L1Loss(reduction='sum').to(device)\n",
    "        elif self.loss_type == 'l2':\n",
    "            self.loss_func = nn.MSELoss(reduction='sum').to(device)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, device):\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32, device=device)\n",
    "\n",
    "        betas = make_beta_schedule(\n",
    "            schedule=schedule_opt['schedule'],\n",
    "            n_timestep=schedule_opt['n_timestep'],\n",
    "            linear_start=schedule_opt['linear_start'],\n",
    "            linear_end=schedule_opt['linear_end'])\n",
    "        betas = betas.detach().cpu().numpy() if isinstance(\n",
    "            betas, torch.Tensor) else betas\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n",
    "        self.sqrt_alphas_cumprod_prev = np.sqrt(\n",
    "            np.append(1., alphas_cumprod))\n",
    "\n",
    "        timesteps, = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.register_buffer('betas', to_torch(betas))\n",
    "        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n",
    "        self.register_buffer('alphas_cumprod_prev',\n",
    "                             to_torch(alphas_cumprod_prev))\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer('sqrt_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. - alphas_cumprod)))\n",
    "        self.register_buffer('log_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.log(1. - alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recip_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recipm1_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = betas * \\\n",
    "            (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "        self.register_buffer('posterior_variance',\n",
    "                             to_torch(posterior_variance))\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "        self.register_buffer('posterior_log_variance_clipped', to_torch(\n",
    "            np.log(np.maximum(posterior_variance, 1e-20))))\n",
    "        self.register_buffer('posterior_mean_coef1', to_torch(\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n",
    "        self.register_buffer('posterior_mean_coef2', to_torch(\n",
    "            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return self.sqrt_recip_alphas_cumprod[t] * x_t - \\\n",
    "            self.sqrt_recipm1_alphas_cumprod[t] * noise\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = self.posterior_mean_coef1[t] * \\\n",
    "            x_start + self.posterior_mean_coef2[t] * x_t\n",
    "        posterior_log_variance_clipped = self.posterior_log_variance_clipped[t]\n",
    "        return posterior_mean, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, x, t, clip_denoised: bool, condition_x=None):\n",
    "        batch_size = x.shape[0]\n",
    "        noise_level = torch.FloatTensor(\n",
    "            [self.sqrt_alphas_cumprod_prev[t+1]]).repeat(batch_size, 1).to(x.device)\n",
    "        if condition_x is not None:\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(torch.cat([condition_x, x], dim=1), noise_level))\n",
    "        else:\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(x, noise_level))\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1., 1.)\n",
    "\n",
    "        model_mean, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t)\n",
    "        return model_mean, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, clip_denoised=True, condition_x=None):\n",
    "        model_mean, model_log_variance = self.p_mean_variance(\n",
    "            x=x, t=t, clip_denoised=clip_denoised, condition_x=condition_x)\n",
    "        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "        return model_mean + noise * (0.5 * model_log_variance).exp()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, x_in, continous=False):\n",
    "        device = self.betas.device\n",
    "        sample_inter = (1 | (self.num_timesteps//10))\n",
    "        if not self.conditional:\n",
    "            shape = x_in\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = img\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        else:\n",
    "            x = x_in\n",
    "            shape = x.shape\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = x\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i, condition_x=x)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        if continous:\n",
    "            return ret_img\n",
    "        else:\n",
    "            return ret_img[-1]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        image_size = self.image_size\n",
    "        channels = self.channels\n",
    "        return self.p_sample_loop((batch_size, channels, image_size, image_size), continous)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def super_resolution(self, x_in, continous=False):\n",
    "        return self.p_sample_loop(x_in, continous)\n",
    "\n",
    "    def q_sample(self, x_start, continuous_sqrt_alpha_cumprod, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        # random gama\n",
    "        return (\n",
    "            continuous_sqrt_alpha_cumprod * x_start +\n",
    "            (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_in, noise=None):\n",
    "        x_start = x_in['GT']\n",
    "        [b, c, h, w] = x_start.shape\n",
    "        t = np.random.randint(1, self.num_timesteps + 1)\n",
    "        continuous_sqrt_alpha_cumprod = torch.FloatTensor(\n",
    "            np.random.uniform(\n",
    "                self.sqrt_alphas_cumprod_prev[t-1],\n",
    "                self.sqrt_alphas_cumprod_prev[t],\n",
    "                size=b\n",
    "            )\n",
    "        ).to(x_start.device)\n",
    "        continuous_sqrt_alpha_cumprod = continuous_sqrt_alpha_cumprod.view(\n",
    "            b, -1)\n",
    "\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        x_noisy = self.q_sample(\n",
    "            x_start=x_start, continuous_sqrt_alpha_cumprod=continuous_sqrt_alpha_cumprod.view(-1, 1, 1, 1), noise=noise)\n",
    "\n",
    "        if not self.conditional:\n",
    "            x_recon = self.denoise_fn(x_noisy, continuous_sqrt_alpha_cumprod)\n",
    "        else:\n",
    "            x_recon = self.denoise_fn(\n",
    "                torch.cat([x_in['Noisy'], x_noisy], dim=1), continuous_sqrt_alpha_cumprod)\n",
    "                # Everything has to be 4D! Otherwise concatenation on this axis is not possible!!!\n",
    "                # The concatenated representation is automatically 4D anyways at the end!!!\n",
    "        loss = self.loss_func(noise, x_recon)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.p_losses(x, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe4019",
   "metadata": {
    "papermill": {
     "duration": 0.005394,
     "end_time": "2025-05-14T18:09:20.586823",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.581429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b91902b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:09:20.598775Z",
     "iopub.status.busy": "2025-05-14T18:09:20.598553Z",
     "iopub.status.idle": "2025-05-14T18:09:20.609655Z",
     "shell.execute_reply": "2025-05-14T18:09:20.609151Z"
    },
    "papermill": {
     "duration": 0.018563,
     "end_time": "2025-05-14T18:09:20.610760",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.592197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m, std=0.02):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, std)  # BN also uses norm\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m, scale=1):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_orthogonal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='kaiming', scale=1, std=0.02):\n",
    "    # scale for 'kaiming', std for 'normal'.\n",
    "    logger.info('Initialization method [{:s}]'.format(init_type))\n",
    "    if init_type == 'normal':\n",
    "        weights_init_normal_ = functools.partial(weights_init_normal, std=std)\n",
    "        net.apply(weights_init_normal_)\n",
    "    elif init_type == 'kaiming':\n",
    "        weights_init_kaiming_ = functools.partial(\n",
    "            weights_init_kaiming, scale=scale)\n",
    "        net.apply(weights_init_kaiming_)\n",
    "    elif init_type == 'orthogonal':\n",
    "        net.apply(weights_init_orthogonal)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'initialization method [{:s}] not implemented'.format(init_type))\n",
    "\n",
    "\n",
    "####################\n",
    "# define network\n",
    "####################\n",
    "\n",
    "\n",
    "# Generator\n",
    "def define_G(opt):\n",
    "    model_opt = opt['model']\n",
    "    if ('norm_groups' not in model_opt['unet']) or model_opt['unet']['norm_groups'] is None:\n",
    "        model_opt['unet']['norm_groups']=32\n",
    "    model = UNet(\n",
    "        in_channel=model_opt['unet']['in_channel'],\n",
    "        out_channel=model_opt['unet']['out_channel'],\n",
    "        norm_groups=model_opt['unet']['norm_groups'],\n",
    "        inner_channel=model_opt['unet']['inner_channel'],\n",
    "        channel_mults=model_opt['unet']['channel_multiplier'],\n",
    "        attn_res=model_opt['unet']['attn_res'],\n",
    "        res_blocks=model_opt['unet']['res_blocks'],\n",
    "        dropout=model_opt['unet']['dropout'],\n",
    "        image_size=model_opt['diffusion']['image_size']\n",
    "    )\n",
    "    netG = GaussianDiffusion(\n",
    "        model,\n",
    "        image_size=model_opt['diffusion']['image_size'],\n",
    "        channels=model_opt['diffusion']['channels'],\n",
    "        loss_type='l1',    # L1 or L2\n",
    "        conditional=model_opt['diffusion']['conditional'],\n",
    "        schedule_opt=model_opt['beta_schedule']['train']\n",
    "    )\n",
    "    if opt['phase'] == 'train':\n",
    "        # init_weights(netG, init_type='kaiming', scale=0.1)\n",
    "        init_weights(netG, init_type='orthogonal')\n",
    "    if opt['gpu_ids']:\n",
    "        assert torch.cuda.is_available()\n",
    "    # if opt['gpu_ids'] and opt['distributed']:\n",
    "    #     assert torch.cuda.is_available()\n",
    "    #     netG = nn.DataParallel(netG)\n",
    "    return netG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80137e16",
   "metadata": {
    "papermill": {
     "duration": 0.005299,
     "end_time": "2025-05-14T18:09:20.621765",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.616466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a4cb041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:09:20.634022Z",
     "iopub.status.busy": "2025-05-14T18:09:20.633806Z",
     "iopub.status.idle": "2025-05-14T18:09:20.652222Z",
     "shell.execute_reply": "2025-05-14T18:09:20.651613Z"
    },
    "papermill": {
     "duration": 0.026168,
     "end_time": "2025-05-14T18:09:20.653328",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.627160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SR3():\n",
    "    def __init__(self, opt):       \n",
    "        self.opt = opt\n",
    "        self.device = torch.device(\n",
    "            'cuda' if opt['gpu_ids'] is not None else 'cpu')\n",
    "        self.begin_step = 0\n",
    "        self.begin_epoch = 0\n",
    "        # define network and load pretrained models\n",
    "        self.netG = self.set_device(define_G(opt))\n",
    "        self.schedule_phase = None\n",
    "\n",
    "        # set loss and load resume state\n",
    "        self.set_loss()\n",
    "        self.set_new_noise_schedule(\n",
    "            opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "        if self.opt['phase'] == 'train':\n",
    "            self.netG.train()\n",
    "            # find the parameters to optimize\n",
    "            if opt['model']['finetune_norm']:\n",
    "                optim_params = []\n",
    "                for k, v in self.netG.named_parameters():\n",
    "                    v.requires_grad = False\n",
    "                    if k.find('transformer') >= 0:\n",
    "                        v.requires_grad = True\n",
    "                        v.data.zero_()\n",
    "                        optim_params.append(v)\n",
    "                        logger.info(\n",
    "                            'Params [{:s}] initialized to 0 and will optimize.'.format(k))\n",
    "            else:\n",
    "                optim_params = list(self.netG.parameters())\n",
    "\n",
    "            self.optG = torch.optim.Adam(\n",
    "                optim_params, lr=opt['train'][\"optimizer\"][\"lr\"])\n",
    "            self.log_dict = OrderedDict()\n",
    "        self.load_network()\n",
    "        self.print_network()\n",
    "\n",
    "    def set_device(self, x):\n",
    "        if isinstance(x, dict):\n",
    "            for key, item in x.items():\n",
    "                if item is not None and type(item)==torch.Tensor:\n",
    "                    x[key] = item.to(self.device)\n",
    "        elif isinstance(x, list):\n",
    "            for item in x:\n",
    "                if item is not None:\n",
    "                    item = item.to(self.device)\n",
    "        else:\n",
    "            x = x.to(self.device)\n",
    "        return x\n",
    "\n",
    "    def get_network_description(self, network):\n",
    "        '''Get the string and total parameters of the network'''\n",
    "        if isinstance(network, nn.DataParallel):\n",
    "            network = network.module\n",
    "        s = str(network)\n",
    "        n = sum(map(lambda x: x.numel(), network.parameters()))\n",
    "        return s, n\n",
    "\n",
    "    def feed_data(self, data):\n",
    "        self.data = self.set_device(data)\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.optG.zero_grad()\n",
    "        l_pix = self.netG(self.data)\n",
    "        b, c, h, w = self.data['GT'].shape\n",
    "        l_pix = l_pix.sum()/int(b*c*h*w)\n",
    "        l_pix.backward()\n",
    "        self.optG.step()\n",
    "\n",
    "        # set log\n",
    "        self.log_dict['l_pix'] = l_pix.item()\n",
    "\n",
    "        return l_pix.item()\n",
    "\n",
    "    def test(self, continous=False):\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.SR = self.netG.module.super_resolution(\n",
    "                    self.data['SR'], continous)\n",
    "            else:\n",
    "                self.SR = self.netG.super_resolution(\n",
    "                    self.data['SR'], continous)\n",
    "        self.netG.train()\n",
    "\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.SR = self.netG.module.sample(batch_size, continous)\n",
    "            else:\n",
    "                self.SR = self.netG.sample(batch_size, continous)\n",
    "        self.netG.train()\n",
    "\n",
    "    def set_loss(self):\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            self.netG.module.set_loss(self.device)\n",
    "        else:\n",
    "            self.netG.set_loss(self.device)\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, schedule_phase='train'):\n",
    "        if self.schedule_phase is None or self.schedule_phase != schedule_phase:\n",
    "            self.schedule_phase = schedule_phase\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.netG.module.set_new_noise_schedule(\n",
    "                    schedule_opt, self.device)\n",
    "            else:\n",
    "                self.netG.set_new_noise_schedule(schedule_opt, self.device)\n",
    "\n",
    "    def get_current_log(self):\n",
    "        return self.log_dict\n",
    "\n",
    "    def get_current_visuals(self, need_LR=True, sample=False):\n",
    "        out_dict = OrderedDict()\n",
    "        if sample:\n",
    "            out_dict['SAM'] = self.SR.detach().float().cpu()\n",
    "        else:\n",
    "            out_dict['SR'] = self.SR.detach().float().cpu()\n",
    "            out_dict['INF'] = self.data['SR'].detach().float().cpu()\n",
    "            out_dict['HR'] = self.data['HR'].detach().float().cpu()\n",
    "            if need_LR and 'LR' in self.data:\n",
    "                out_dict['LR'] = self.data['LR'].detach().float().cpu()\n",
    "            else:\n",
    "                out_dict['LR'] = out_dict['INF']\n",
    "        return out_dict\n",
    "\n",
    "    def print_network(self):\n",
    "        s, n = self.get_network_description(self.netG)\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            net_struc_str = '{} - {}'.format(self.netG.__class__.__name__,\n",
    "                                             self.netG.module.__class__.__name__)\n",
    "        else:\n",
    "            net_struc_str = '{}'.format(self.netG.__class__.__name__)\n",
    "\n",
    "        logger.info(\n",
    "            'Network G structure: {}, with parameters: {:,d}'.format(net_struc_str, n))\n",
    "        logger.info(s)\n",
    "\n",
    "    def save_network(self, epoch, iter_step, is_final=False):\n",
    "        if is_final:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        else:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        # gen\n",
    "        network = self.netG\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            network = network.module\n",
    "        state_dict = network.state_dict()\n",
    "        for key, param in state_dict.items():\n",
    "            state_dict[key] = param.cpu()\n",
    "        torch.save(state_dict, gen_path)\n",
    "        # opt\n",
    "        opt_state = {'epoch': epoch, 'iter': iter_step,\n",
    "                     'scheduler': None, 'optimizer': None}\n",
    "        opt_state['optimizer'] = self.optG.state_dict()\n",
    "        torch.save(opt_state, opt_path)\n",
    "\n",
    "        logger.info(\n",
    "            'Saved model in [{:s}] ...'.format(gen_path))\n",
    "\n",
    "    def load_network(self):\n",
    "        load_path = self.opt['path']['resume_state']\n",
    "        if load_path is not None:\n",
    "            logger.info(\n",
    "                'Loading pretrained model for G [{:s}] ...'.format(load_path))\n",
    "            gen_path = '{}_gen.pth'.format(load_path)\n",
    "            opt_path = '{}_opt.pth'.format(load_path)\n",
    "            # gen\n",
    "            network = self.netG\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                network = network.module\n",
    "            network.load_state_dict(torch.load(\n",
    "                gen_path), strict=(not self.opt['model']['finetune_norm']))\n",
    "            # network.load_state_dict(torch.load(\n",
    "            #     gen_path), strict=False)\n",
    "            if self.opt['phase'] == 'train':\n",
    "                # optimizer\n",
    "                opt = torch.load(opt_path)\n",
    "                self.optG.load_state_dict(opt['optimizer'])\n",
    "                self.begin_step = opt['iter']\n",
    "                self.begin_epoch = opt['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235f4f9",
   "metadata": {
    "papermill": {
     "duration": 0.005496,
     "end_time": "2025-05-14T18:09:20.664377",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.658881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34aeeb83",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-14T18:09:20.676197Z",
     "iopub.status.busy": "2025-05-14T18:09:20.675950Z",
     "iopub.status.idle": "2025-05-14T18:09:28.292323Z",
     "shell.execute_reply": "2025-05-14T18:09:28.290552Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 7.624625,
     "end_time": "2025-05-14T18:09:28.294429",
     "exception": false,
     "start_time": "2025-05-14T18:09:20.669804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 18:09:21.010 - INFO: Initialization method [orthogonal]\n",
      "25-05-14 18:09:28.287 - INFO: Network G structure: GaussianDiffusion, with parameters: 38,901,057\n",
      "25-05-14 18:09:28.288 - INFO: GaussianDiffusion(\n",
      "  (denoise_fn): UNet(\n",
      "    (noise_level_mlp): Sequential(\n",
      "      (0): PositionalEncoding()\n",
      "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (2): Swish()\n",
      "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "    )\n",
      "    (downs): ModuleList(\n",
      "      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Downsample(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): Downsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (5): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (6): Downsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mid): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "        (attn): SelfAttention(\n",
      "          (norm): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "          (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ups): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (6): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (8): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (9): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (10): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): Block(\n",
      "      (block): Sequential(\n",
      "        (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "        (1): Swish()\n",
      "        (2): Identity()\n",
      "        (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss_func): L1Loss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "diffusion = SR3(opt)\n",
    "# logger.info('Initial Model Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d69a4e68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T18:09:28.310187Z",
     "iopub.status.busy": "2025-05-14T18:09:28.309858Z",
     "iopub.status.idle": "2025-05-14T19:00:59.151854Z",
     "shell.execute_reply": "2025-05-14T19:00:59.150882Z"
    },
    "papermill": {
     "duration": 3090.850296,
     "end_time": "2025-05-14T19:00:59.153355",
     "exception": false,
     "start_time": "2025-05-14T18:09:28.303059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 18:11:23.971 - INFO: <epoch:  1, iter:     100> l_pix: 1.4514e-01 \n",
      "25-05-14 18:12:31.529 - INFO: <epoch:  1, iter:     200> l_pix: 1.2678e-01 \n",
      "25-05-14 18:13:39.084 - INFO: <epoch:  1, iter:     300> l_pix: 1.2634e-01 \n",
      "25-05-14 18:14:46.634 - INFO: <epoch:  1, iter:     400> l_pix: 7.3569e-02 \n",
      "25-05-14 18:15:54.193 - INFO: <epoch:  1, iter:     500> l_pix: 9.0550e-02 \n",
      "25-05-14 18:17:01.738 - INFO: <epoch:  1, iter:     600> l_pix: 5.0868e-02 \n",
      "25-05-14 18:18:09.289 - INFO: <epoch:  1, iter:     700> l_pix: 4.6360e-02 \n",
      "25-05-14 18:19:16.845 - INFO: <epoch:  1, iter:     800> l_pix: 7.4689e-02 \n",
      "25-05-14 18:20:24.395 - INFO: <epoch:  1, iter:     900> l_pix: 3.2571e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1519975646150609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 18:21:32.343 - INFO: <epoch:  2, iter:   1,000> l_pix: 5.4201e-02 \n",
      "25-05-14 18:22:39.887 - INFO: <epoch:  2, iter:   1,100> l_pix: 5.9910e-02 \n",
      "25-05-14 18:23:47.434 - INFO: <epoch:  2, iter:   1,200> l_pix: 2.9716e-02 \n",
      "25-05-14 18:24:54.991 - INFO: <epoch:  2, iter:   1,300> l_pix: 7.4937e-02 \n",
      "25-05-14 18:26:02.545 - INFO: <epoch:  2, iter:   1,400> l_pix: 1.2426e-01 \n",
      "25-05-14 18:27:10.092 - INFO: <epoch:  2, iter:   1,500> l_pix: 8.2162e-01 \n",
      "25-05-14 18:28:17.639 - INFO: <epoch:  2, iter:   1,600> l_pix: 1.0681e-01 \n",
      "25-05-14 18:29:25.196 - INFO: <epoch:  2, iter:   1,700> l_pix: 3.2313e-02 \n",
      "25-05-14 18:30:32.749 - INFO: <epoch:  2, iter:   1,800> l_pix: 2.7714e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.08754630751286943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 18:31:40.719 - INFO: <epoch:  3, iter:   1,900> l_pix: 9.6128e-02 \n",
      "25-05-14 18:32:48.272 - INFO: <epoch:  3, iter:   2,000> l_pix: 7.1281e-02 \n",
      "25-05-14 18:33:55.823 - INFO: <epoch:  3, iter:   2,100> l_pix: 4.7592e-02 \n",
      "25-05-14 18:35:03.382 - INFO: <epoch:  3, iter:   2,200> l_pix: 2.5235e-01 \n",
      "25-05-14 18:36:10.933 - INFO: <epoch:  3, iter:   2,300> l_pix: 1.6481e-01 \n",
      "25-05-14 18:37:18.498 - INFO: <epoch:  3, iter:   2,400> l_pix: 1.5196e-01 \n",
      "25-05-14 18:38:26.056 - INFO: <epoch:  3, iter:   2,500> l_pix: 9.1455e-02 \n",
      "25-05-14 18:39:33.601 - INFO: <epoch:  3, iter:   2,600> l_pix: 2.9006e-02 \n",
      "25-05-14 18:40:41.144 - INFO: <epoch:  3, iter:   2,700> l_pix: 2.3010e-02 \n",
      "25-05-14 18:40:41.145 - INFO: Saving models and training states.\n",
      "25-05-14 18:40:41.895 - INFO: Saved model in [/kaggle/working/checkpoint/I2700_E3_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.07573402124974463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 18:41:49.871 - INFO: <epoch:  4, iter:   2,800> l_pix: 2.3620e-02 \n",
      "25-05-14 18:42:57.425 - INFO: <epoch:  4, iter:   2,900> l_pix: 2.6180e-01 \n",
      "25-05-14 18:44:04.968 - INFO: <epoch:  4, iter:   3,000> l_pix: 4.3705e-02 \n",
      "25-05-14 18:45:12.507 - INFO: <epoch:  4, iter:   3,100> l_pix: 6.2744e-02 \n",
      "25-05-14 18:46:20.046 - INFO: <epoch:  4, iter:   3,200> l_pix: 2.1480e-02 \n",
      "25-05-14 18:47:27.579 - INFO: <epoch:  4, iter:   3,300> l_pix: 3.4095e-02 \n",
      "25-05-14 18:48:35.110 - INFO: <epoch:  4, iter:   3,400> l_pix: 3.9474e-02 \n",
      "25-05-14 18:49:42.634 - INFO: <epoch:  4, iter:   3,500> l_pix: 2.4040e-02 \n",
      "25-05-14 18:50:50.163 - INFO: <epoch:  4, iter:   3,600> l_pix: 3.3700e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.07185148063633177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 18:51:58.085 - INFO: <epoch:  5, iter:   3,700> l_pix: 9.2261e-02 \n",
      "25-05-14 18:53:05.619 - INFO: <epoch:  5, iter:   3,800> l_pix: 4.4040e-02 \n",
      "25-05-14 18:54:13.157 - INFO: <epoch:  5, iter:   3,900> l_pix: 6.6781e-02 \n",
      "25-05-14 18:55:20.685 - INFO: <epoch:  5, iter:   4,000> l_pix: 3.7477e-02 \n",
      "25-05-14 18:56:28.215 - INFO: <epoch:  5, iter:   4,100> l_pix: 4.1079e-02 \n",
      "25-05-14 18:57:35.745 - INFO: <epoch:  5, iter:   4,200> l_pix: 4.9804e-01 \n",
      "25-05-14 18:58:43.268 - INFO: <epoch:  5, iter:   4,300> l_pix: 3.2359e-02 \n",
      "25-05-14 18:59:50.792 - INFO: <epoch:  5, iter:   4,400> l_pix: 5.4785e-02 \n",
      "25-05-14 19:00:58.331 - INFO: <epoch:  5, iter:   4,500> l_pix: 1.5396e-01 \n",
      "25-05-14 19:00:58.332 - INFO: Saving final model\n",
      "25-05-14 19:00:59.110 - INFO: Saved model in [/kaggle/working/checkpoint/Final_I4500_E5_gen.pth] ...\n",
      "25-05-14 19:00:59.147 - INFO: End of training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.06812162574173676\n",
      "Epoch Loss List:  [0.1519975646150609, 0.08754630751286943, 0.07573402124974463, 0.07185148063633177, 0.06812162574173676]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epoch_loss_list = []\n",
    "\n",
    "current_step = diffusion.begin_step\n",
    "current_epoch = diffusion.begin_epoch\n",
    "n_iter = opt['train']['n_iter']\n",
    "\n",
    "if opt['path']['resume_state']:\n",
    "    logger.info('Resuming training from epoch: {}, iter: {}.'.format(\n",
    "        current_epoch, current_step))\n",
    "\n",
    "diffusion.set_new_noise_schedule(\n",
    "    opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])\n",
    "if opt['phase'] == 'train':\n",
    "    while current_step < n_iter:\n",
    "        current_epoch += 1\n",
    "        epoch_loss_values = []\n",
    "        for _, train_data in enumerate(train_loader):\n",
    "            current_step += 1\n",
    "            if current_step > n_iter:\n",
    "                break\n",
    "            diffusion.feed_data(train_data)\n",
    "            current_l_pix = diffusion.optimize_parameters()\n",
    "            epoch_loss_values.append(current_l_pix)\n",
    "            # log\n",
    "            if current_step % opt['train']['print_freq'] == 0:\n",
    "                logs = diffusion.get_current_log()\n",
    "                message = '<epoch:{:3d}, iter:{:8,d}> '.format(\n",
    "                    current_epoch, current_step)\n",
    "                for k, v in logs.items():\n",
    "                    message += '{:s}: {:.4e} '.format(k, v)\n",
    "                    #tb_logger.add_scalar(k, v, current_step)\n",
    "                logger.info(message)\n",
    "                \n",
    "        \n",
    "\n",
    "                # if wandb_logger:\n",
    "                #     wandb_logger.log_metrics(logs)\n",
    "\n",
    "    #         # validation\n",
    "    #         if current_step % opt['train']['val_freq'] == 0:\n",
    "    #             avg_psnr = 0.0\n",
    "    #             idx = 0\n",
    "    #             result_path = '{}/{}'.format(opt['path']\n",
    "    #                                             ['results'], current_epoch)\n",
    "    #             os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "    #             diffusion.set_new_noise_schedule(\n",
    "    #                 opt['model']['beta_schedule']['val'], schedule_phase='val')\n",
    "    #             for _,  val_data in enumerate(val_loader):\n",
    "    #                 idx += 1\n",
    "    #                 diffusion.feed_data(val_data)\n",
    "    #                 diffusion.test(continous=False)\n",
    "    #                 visuals = diffusion.get_current_visuals()\n",
    "    #                 sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "    #                 hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "    #                 lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "    #                 fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "\n",
    "    #                 # generation\n",
    "    #                 Metrics.save_img(\n",
    "    #                     hr_img, '{}/{}_{}_hr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     sr_img, '{}/{}_{}_sr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     lr_img, '{}/{}_{}_lr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     fake_img, '{}/{}_{}_inf.png'.format(result_path, current_step, idx))\n",
    "    #                 tb_logger.add_image(\n",
    "    #                     'Iter_{}'.format(current_step),\n",
    "    #                     np.transpose(np.concatenate(\n",
    "    #                         (fake_img, sr_img, hr_img), axis=1), [2, 0, 1]),\n",
    "    #                     idx)\n",
    "    #                 avg_psnr += Metrics.calculate_psnr(\n",
    "    #                     sr_img, hr_img)\n",
    "\n",
    "    #                 if wandb_logger:\n",
    "    #                     wandb_logger.log_image(\n",
    "    #                         f'validation_{idx}', \n",
    "    #                         np.concatenate((fake_img, sr_img, hr_img), axis=1)\n",
    "    #                     )\n",
    "\n",
    "    #             avg_psnr = avg_psnr / idx\n",
    "    #             diffusion.set_new_noise_schedule(\n",
    "    #                 opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "    #             # log\n",
    "    #             logger.info('# Validation # PSNR: {:.4e}'.format(avg_psnr))\n",
    "    #             logger_val = logging.getLogger('val')  # validation logger\n",
    "    #             logger_val.info('<epoch:{:3d}, iter:{:8,d}> psnr: {:.4e}'.format(\n",
    "    #                 current_epoch, current_step, avg_psnr))\n",
    "    #             # tensorboard logger\n",
    "    #             tb_logger.add_scalar('psnr', avg_psnr, current_step)\n",
    "\n",
    "    #             if wandb_logger:\n",
    "    #                 wandb_logger.log_metrics({\n",
    "    #                     'validation/val_psnr': avg_psnr,\n",
    "    #                     'validation/val_step': val_step\n",
    "    #                 })\n",
    "    #                 val_step += 1\n",
    "                \n",
    "            if current_step % opt['train']['save_checkpoint_freq'] == 0:\n",
    "                logger.info('Saving models and training states.')\n",
    "                diffusion.save_network(current_epoch, current_step)\n",
    "            \n",
    "            if current_step == n_iter:\n",
    "                logger.info(\"Saving final model\")\n",
    "                diffusion.save_network(current_epoch, current_step, is_final=True)\n",
    "\n",
    "                # if wandb_logger and opt['log_wandb_ckpt']:\n",
    "                #     wandb_logger.log_checkpoint(current_epoch, current_step)\n",
    "\n",
    "        epoch_loss = sum(epoch_loss_values)/len(epoch_loss_values)\n",
    "        print('Epoch Loss: ', epoch_loss)\n",
    "        epoch_loss_list.append(epoch_loss)\n",
    "\n",
    "        # if wandb_logger:\n",
    "        #     wandb_logger.log_metrics({'epoch': current_epoch-1})\n",
    "\n",
    "    # save model\n",
    "    print('Epoch Loss List: ', epoch_loss_list)\n",
    "    logger.info('End of training.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542573d",
   "metadata": {
    "papermill": {
     "duration": 0.007605,
     "end_time": "2025-05-14T19:00:59.169862",
     "exception": false,
     "start_time": "2025-05-14T19:00:59.162257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b57c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T19:00:59.186854Z",
     "iopub.status.busy": "2025-05-14T19:00:59.186614Z",
     "iopub.status.idle": "2025-05-14T19:00:59.191521Z",
     "shell.execute_reply": "2025-05-14T19:00:59.190975Z"
    },
    "papermill": {
     "duration": 0.014758,
     "end_time": "2025-05-14T19:00:59.192662",
     "exception": false,
     "start_time": "2025-05-14T19:00:59.177904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_loss_curve(epoch_loss_list, filename='loss_curve.png'):\n",
    "    epochs = range(1, len(epoch_loss_list) + 1)  # X-axis starts at 1\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, epoch_loss_list, marker='o', label='Training Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(epochs)  # Set integer ticks\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8df1acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T19:00:59.209207Z",
     "iopub.status.busy": "2025-05-14T19:00:59.208981Z",
     "iopub.status.idle": "2025-05-14T19:00:59.357959Z",
     "shell.execute_reply": "2025-05-14T19:00:59.357466Z"
    },
    "papermill": {
     "duration": 0.158525,
     "end_time": "2025-05-14T19:00:59.359271",
     "exception": false,
     "start_time": "2025-05-14T19:00:59.200746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_loss_curve(epoch_loss_list, \"/kaggle/working/train_loss.png\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7419713,
     "sourceId": 11813224,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7419718,
     "sourceId": 11813229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7419725,
     "sourceId": 11813237,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3138.6196,
   "end_time": "2025-05-14T19:01:01.754315",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-14T18:08:43.134715",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
