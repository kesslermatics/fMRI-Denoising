{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0907e8f",
   "metadata": {},
   "source": [
    "### Denoising fMRI Scans with Diffusion Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5df443",
   "metadata": {},
   "source": [
    "## Training with Anatomy as Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2537c3",
   "metadata": {},
   "source": [
    "This Code is based on the implementation of the Super-Resolution Network SR3: https://github.com/Janspiry/Image-Super-Resolution-via-Iterative-Refinement.git\n",
    "\n",
    "Changes were made throughout the full code to convert the super-resolution architecture to a denoising-architecture with an additional condition (Structural MRI / anatomy).\n",
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1f1b9",
   "metadata": {
    "papermill": {
     "duration": 0.004288,
     "end_time": "2025-06-23T20:59:45.189260",
     "exception": false,
     "start_time": "2025-06-23T20:59:45.184972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e25170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:59:45.198969Z",
     "iopub.status.busy": "2025-06-23T20:59:45.198536Z",
     "iopub.status.idle": "2025-06-23T20:59:52.832371Z",
     "shell.execute_reply": "2025-06-23T20:59:52.831547Z"
    },
    "papermill": {
     "duration": 7.640218,
     "end_time": "2025-06-23T20:59:52.833838",
     "exception": false,
     "start_time": "2025-06-23T20:59:45.193620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from re import split\n",
    "import torch.utils.data\n",
    "from collections import OrderedDict\n",
    "import functools\n",
    "from torch.nn import init\n",
    "from torch.nn import modules\n",
    "\n",
    "# u-net\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from inspect import isfunction\n",
    "\n",
    "# diffusion\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "# learning rate scheduler\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# mixed precision training for memory\n",
    "from torch.amp import GradScaler\n",
    "from torch.amp import autocast\n",
    "\n",
    "# activation checkpointing\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "# read masks\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345e9b3e",
   "metadata": {
    "papermill": {
     "duration": 0.004355,
     "end_time": "2025-06-23T20:59:52.843017",
     "exception": false,
     "start_time": "2025-06-23T20:59:52.838662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b4a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:59:52.852986Z",
     "iopub.status.busy": "2025-06-23T20:59:52.852631Z",
     "iopub.status.idle": "2025-06-23T20:59:52.859524Z",
     "shell.execute_reply": "2025-06-23T20:59:52.858970Z"
    },
    "papermill": {
     "duration": 0.013117,
     "end_time": "2025-06-23T20:59:52.860496",
     "exception": false,
     "start_time": "2025-06-23T20:59:52.847379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"denoising\",\n",
    "    \"phase\": \"train\",\n",
    "    \"gpu_ids\": [0, 1], \n",
    "    \"debug\": False,  \n",
    "    \"enable_wandb\": False,  \n",
    "    \"log_wandb_ckpt\": False,  \n",
    "    \"log_eval\": False,  \n",
    "    \"path\": {\n",
    "        \"log\": \"/kaggle/working/logs\",\n",
    "        \"tb_logger\": \"/kaggle/working/tb_logger\",\n",
    "        \"results\": \"/kaggle/working/results\",\n",
    "        \"checkpoint\": \"/kaggle/working/checkpoint\",\n",
    "        \"resume_state\": None\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-train-1-norm-v3/data/noisy_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-norm-v3/data/noisy_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-norm-v3/data/noisy_func_train_3.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-train-1-norm-v3/data/gt_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-norm-v3/data/gt_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-norm-v3/data/gt_func_train_3.npy'],\n",
    "            \"mask_data_paths\": ['/kaggle/input/coregistered-anatomy/coregistered_outputs/sub-01_smri_coregistered.nii',\n",
    "                '/kaggle/input/coregistered-anatomy/coregistered_outputs/sub-dd_smri_coregistered.nii',\n",
    "                '/kaggle/input/coregistered-anatomy/coregistered_outputs/sub-gg_smri_coregistered.nii'],\n",
    "\n",
    "            \"batch_size\": 2,\n",
    "            \"num_workers\": 4,\n",
    "            \"use_shuffle\": True\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-test-norm-v3/data/noisy_func_test.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-test/data/gt_func_test.npy'],\n",
    "            \"mask_data_paths\": ['/kaggle/input/coregistered-anatomy/coregistered_outputs/sub-uu_smri_coregistered.nii'],\n",
    "        }\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\",\n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 3,\n",
    "            \"out_channel\": 1,\n",
    "            \"inner_channel\": 64,\n",
    "            \"norm_groups\": 16,\n",
    "            \"channel_multiplier\": [1, 2, 4, 8],\n",
    "            \"attn_res\": [8],\n",
    "            \"res_blocks\": 1,\n",
    "            \"dropout\": 0.1\n",
    "        },\n",
    "        \"beta_schedule\": {\n",
    "            \"train\": {\n",
    "                \"schedule\": \"cosine\",\n",
    "                \"n_timestep\": 1000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"schedule\": \"cosine\",\n",
    "                \"n_timestep\": 1000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 64,\n",
    "            \"channels\": 1,\n",
    "            \"conditional\": True\n",
    "        }\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"n_iter\": 18000,\n",
    "        \"val_freq\": 1e4,\n",
    "        \"save_checkpoint_freq\": 1800,\n",
    "        \"print_freq\": 100,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"lr\": 5e-5\n",
    "        },\n",
    "        \"ema_scheduler\": {\n",
    "            \"step_start_ema\": 1000,\n",
    "            \"update_ema_every\": 10,\n",
    "            \"ema_decay\": 0.999\n",
    "        }\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        \"project\": \"distributed_high_sr_ffhq\"\n",
    "    },\n",
    "    \"config_file\": \"config/sr_sr3_16_128.json\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e6bf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:59:52.870003Z",
     "iopub.status.busy": "2025-06-23T20:59:52.869606Z",
     "iopub.status.idle": "2025-06-23T20:59:52.873714Z",
     "shell.execute_reply": "2025-06-23T20:59:52.873146Z"
    },
    "papermill": {
     "duration": 0.010215,
     "end_time": "2025-06-23T20:59:52.874990",
     "exception": false,
     "start_time": "2025-06-23T20:59:52.864775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(opt['path']['log'], exist_ok=True)\n",
    "os.makedirs(opt['path']['tb_logger'], exist_ok=True)\n",
    "os.makedirs(opt['path']['results'], exist_ok=True)\n",
    "os.makedirs(opt['path']['checkpoint'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c1a78",
   "metadata": {
    "papermill": {
     "duration": 0.004122,
     "end_time": "2025-06-23T20:59:52.883402",
     "exception": false,
     "start_time": "2025-06-23T20:59:52.879280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424ae84c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:59:52.893161Z",
     "iopub.status.busy": "2025-06-23T20:59:52.892595Z",
     "iopub.status.idle": "2025-06-23T20:59:52.899445Z",
     "shell.execute_reply": "2025-06-23T20:59:52.898915Z"
    },
    "papermill": {
     "duration": 0.01289,
     "end_time": "2025-06-23T20:59:52.900551",
     "exception": false,
     "start_time": "2025-06-23T20:59:52.887661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logging\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def dict2str(opt, indent_l=1):\n",
    "    '''dict to string for logger'''\n",
    "    msg = ''\n",
    "    for k, v in opt.items():\n",
    "        if isinstance(v, dict):\n",
    "            msg += ' ' * (indent_l * 2) + k + ':[\\n'\n",
    "            msg += dict2str(v, indent_l + 1)\n",
    "            msg += ' ' * (indent_l * 2) + ']\\n'\n",
    "        else:\n",
    "            msg += ' ' * (indent_l * 2) + k + ': ' + str(v) + '\\n'\n",
    "    return msg\n",
    "\n",
    "def setup_logger(logger_name, root, phase, level=logging.INFO, screen=False):\n",
    "    '''set up logger'''\n",
    "    l = logging.getLogger(logger_name)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s.%(msecs)03d - %(levelname)s: %(message)s', datefmt='%y-%m-%d %H:%M:%S')\n",
    "    log_file = os.path.join(root, '{}.log'.format(phase))\n",
    "    fh = logging.FileHandler(log_file, mode='w')\n",
    "    fh.setFormatter(formatter)\n",
    "    l.setLevel(level)\n",
    "    l.addHandler(fh)\n",
    "    if screen:\n",
    "        sh = logging.StreamHandler()\n",
    "        sh.setFormatter(formatter)\n",
    "        l.addHandler(sh)\n",
    "\n",
    "\n",
    "setup_logger(None, opt['path']['log'],\n",
    "                    'train', level=logging.INFO, screen=True)\n",
    "setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "logger = logging.getLogger('base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e8c6d",
   "metadata": {
    "papermill": {
     "duration": 0.004137,
     "end_time": "2025-06-23T20:59:52.909107",
     "exception": false,
     "start_time": "2025-06-23T20:59:52.904970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f530a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:59:52.919173Z",
     "iopub.status.busy": "2025-06-23T20:59:52.918835Z",
     "iopub.status.idle": "2025-06-23T20:59:52.926606Z",
     "shell.execute_reply": "2025-06-23T20:59:52.926142Z"
    },
    "papermill": {
     "duration": 0.013806,
     "end_time": "2025-06-23T20:59:52.927637",
     "exception": false,
     "start_time": "2025-06-23T20:59:52.913831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairwiseDataset(Dataset):\n",
    "\n",
    "    def __init__(self, noisy_images_paths: list, gt_images_paths: list, mask_images_paths: list):\n",
    "        \"\"\"Initialize fMRI dataset for denoising with memory-efficient loading.\n",
    "        \n",
    "        Args:\n",
    "            noisy_images_paths (list): List of paths to noisy fMRI volumes (.npy files)\n",
    "            gt_images_paths (list): List of paths to ground truth fMRI volumes (.npy files)\n",
    "            mask_images_paths (list): List of paths to brain mask volumes (.nii files)\n",
    "        \"\"\"\n",
    "        self.noisy_paths = noisy_images_paths\n",
    "        self.gt_paths = gt_images_paths\n",
    "        self.mask_paths = mask_images_paths\n",
    "        \n",
    "\n",
    "        self.mask_volumes = [np.rot90(nib.load(path).get_fdata(), k=1, axes=(0, 1)) for path in mask_images_paths]\n",
    "        \n",
    "        self.file_slice_mapping = []\n",
    "        self.z_t_dimension_sizes = []\n",
    "        total_slices = 0\n",
    "        dataset_length = 0\n",
    "        \n",
    "        for i, path in enumerate(noisy_images_paths):\n",
    "            data_shape = np.load(path, mmap_mode='r').shape\n",
    "            num_slices = data_shape[2] * data_shape[3]  # z * t\n",
    "            self.z_t_dimension_sizes.append((data_shape[2], data_shape[3]))\n",
    "            \n",
    "            for batch_idx in range(0, data_shape[3]):\n",
    "                self.file_slice_mapping.append((i, batch_idx))\n",
    "                dataset_length += 1\n",
    "            \n",
    "            total_slices += num_slices \n",
    "            \n",
    "        self.data_len = dataset_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # although named \"mask\" it refers to the sMRI and deals with it as additional condition\n",
    "        file_idx, t_idx = self.file_slice_mapping[index]\n",
    "        \n",
    "        noisy_file_path = self.noisy_paths[file_idx]\n",
    "        gt_file_path = self.gt_paths[file_idx]\n",
    "        \n",
    "        mask_volume = self.mask_volumes[file_idx]\n",
    "\n",
    "        noisy_volume = np.load(noisy_file_path, mmap_mode='r')\n",
    "        gt_volume = np.load(gt_file_path, mmap_mode='r')\n",
    "        \n",
    "        noisy_slice = noisy_volume[:, :, :, t_idx].copy()\n",
    "        gt_slice = gt_volume[:, :, :, t_idx].copy()\n",
    "\n",
    "        \n",
    "        return {\n",
    "            'GT': torch.tensor(gt_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Noisy': torch.tensor(noisy_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Mask': torch.tensor(mask_volume.copy()).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Index': index\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e2b9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:59:52.937195Z",
     "iopub.status.busy": "2025-06-23T20:59:52.936987Z",
     "iopub.status.idle": "2025-06-23T20:59:52.942232Z",
     "shell.execute_reply": "2025-06-23T20:59:52.941723Z"
    },
    "papermill": {
     "duration": 0.011241,
     "end_time": "2025-06-23T20:59:52.943219",
     "exception": false,
     "start_time": "2025-06-23T20:59:52.931978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_merge_batches(batch):\n",
    "    merged = {\n",
    "        'Noisy': torch.cat([item['Noisy'] for item in batch], dim=0),\n",
    "        'GT': torch.cat([item['GT'] for item in batch], dim=0),\n",
    "        'Mask': torch.cat([item['Mask'] for item in batch], dim=0),\n",
    "        'Index': [item['Index'] for item in batch]\n",
    "    }\n",
    "    return merged\n",
    "\n",
    "def create_dataloader(dataset, dataset_opt, phase):\n",
    "    '''create dataloader '''\n",
    "    if phase == 'train':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=dataset_opt['batch_size'],\n",
    "            shuffle=dataset_opt['use_shuffle'],\n",
    "            num_workers=dataset_opt['num_workers'],\n",
    "            pin_memory=True,\n",
    "            collate_fn = collate_merge_batches)\n",
    "    elif phase == 'test':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True, collate_fn = lambda x: x[0])\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Dataloader [{:s}] is not found.'.format(phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73b4a45b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T20:59:52.952616Z",
     "iopub.status.busy": "2025-06-23T20:59:52.952443Z",
     "iopub.status.idle": "2025-06-23T20:59:53.142581Z",
     "shell.execute_reply": "2025-06-23T20:59:53.141828Z"
    },
    "papermill": {
     "duration": 0.196089,
     "end_time": "2025-06-23T20:59:53.143793",
     "exception": false,
     "start_time": "2025-06-23T20:59:52.947704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 20:59:53.118 - INFO: Training dataset with 900 instances created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 20:59:53.139 - INFO: Test dataset with 300 instances created.\n"
     ]
    }
   ],
   "source": [
    "# Create training dataset and dataloader\n",
    "train_set = PairwiseDataset(\n",
    "    opt['datasets']['train']['noisy_data_paths'], \n",
    "    opt['datasets']['train']['gt_data_paths'],\n",
    "    opt['datasets']['train']['mask_data_paths']\n",
    ")\n",
    "train_loader = create_dataloader(\n",
    "    train_set, \n",
    "    opt['datasets']['train'], \n",
    "    'train'\n",
    ")\n",
    "logger.info('Training dataset with {} instances created.'.format(len(train_set)))\n",
    "\n",
    "# Create testing dataset and dataloader\n",
    "test_set = PairwiseDataset(\n",
    "    opt['datasets']['test']['noisy_data_paths'], \n",
    "    opt['datasets']['test']['gt_data_paths'],\n",
    "    opt['datasets']['test']['mask_data_paths']\n",
    ")\n",
    "test_loader = create_dataloader(\n",
    "    test_set, \n",
    "    opt['datasets']['test'], \n",
    "    'test'\n",
    ")\n",
    "logger.info('Test dataset with {} instances created.'.format(len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b95ec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T21:00:23.604411Z",
     "iopub.status.busy": "2025-06-23T21:00:23.604209Z",
     "iopub.status.idle": "2025-06-23T21:00:23.944865Z",
     "shell.execute_reply": "2025-06-23T21:00:23.944158Z"
    },
    "papermill": {
     "duration": 0.34689,
     "end_time": "2025-06-23T21:00:23.946147",
     "exception": false,
     "start_time": "2025-06-23T21:00:23.599257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9b3b1400d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#example visualization of mask and gt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "gt_slice = train_set[400][\"GT\"]\n",
    "mask_slice = train_set[400][\"Mask\"]\n",
    "\n",
    "# Plot ground truth image\n",
    "axes[0].imshow(gt_slice[0,0,:,:], cmap='gray')\n",
    "axes[1].imshow(mask_slice[0,0,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61855986",
   "metadata": {
    "papermill": {
     "duration": 0.004769,
     "end_time": "2025-06-23T21:00:23.956427",
     "exception": false,
     "start_time": "2025-06-23T21:00:23.951658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3bfd8d",
   "metadata": {
    "papermill": {
     "duration": 0.004768,
     "end_time": "2025-06-23T21:00:23.966050",
     "exception": false,
     "start_time": "2025-06-23T21:00:23.961282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e846d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T21:00:23.977003Z",
     "iopub.status.busy": "2025-06-23T21:00:23.976420Z",
     "iopub.status.idle": "2025-06-23T21:00:23.980008Z",
     "shell.execute_reply": "2025-06-23T21:00:23.979503Z"
    },
    "papermill": {
     "duration": 0.010032,
     "end_time": "2025-06-23T21:00:23.980973",
     "exception": false,
     "start_time": "2025-06-23T21:00:23.970941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generic functions\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926cad98",
   "metadata": {},
   "source": [
    "\n",
    "U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b12e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T21:00:23.992052Z",
     "iopub.status.busy": "2025-06-23T21:00:23.991834Z",
     "iopub.status.idle": "2025-06-23T21:00:24.015759Z",
     "shell.execute_reply": "2025-06-23T21:00:24.015214Z"
    },
    "papermill": {
     "duration": 0.030861,
     "end_time": "2025-06-23T21:00:24.016714",
     "exception": false,
     "start_time": "2025-06-23T21:00:23.985853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PositionalEncoding Source： https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        count = self.dim // 2\n",
    "        step = torch.arange(count, dtype=noise_level.dtype,\n",
    "                            device=noise_level.device) / count\n",
    "        encoding = noise_level.unsqueeze(\n",
    "            1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n",
    "        encoding = torch.cat(\n",
    "            [torch.sin(encoding), torch.cos(encoding)], dim=-1)\n",
    "        return encoding\n",
    "\n",
    "\n",
    "class FeatureWiseAffine(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_affine_level=False):\n",
    "        super(FeatureWiseAffine, self).__init__()\n",
    "        self.use_affine_level = use_affine_level\n",
    "        self.noise_func = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, noise_embed):\n",
    "        batch = x.shape[0]\n",
    "        if self.use_affine_level:\n",
    "            gamma, beta = self.noise_func(noise_embed).view(\n",
    "                batch, -1, 1, 1).chunk(2, dim=1)\n",
    "            x = (1 + gamma) * x + beta\n",
    "        else:\n",
    "            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.up(x))\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# building block modules\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=32, dropout=0):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, dim),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32):\n",
    "        super().__init__()\n",
    "        self.noise_func = FeatureWiseAffine(\n",
    "            noise_level_emb_dim, dim_out, use_affine_level)\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=norm_groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout)\n",
    "        self.res_conv = nn.Conv2d(\n",
    "            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        b, c, h, w = x.shape\n",
    "        h = self.block1(x)\n",
    "        h = self.noise_func(h, time_emb)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channel, n_head=1, norm_groups=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.norm = nn.GroupNorm(norm_groups, in_channel)\n",
    "        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch, channel, height, width = input.shape\n",
    "        n_head = self.n_head\n",
    "        head_dim = channel // n_head\n",
    "\n",
    "        norm = self.norm(input)\n",
    "        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n",
    "        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n",
    "\n",
    "        attn = torch.einsum(\n",
    "            \"bnchw, bncyx -> bnhwyx\", query, key\n",
    "        ).contiguous() / math.sqrt(channel)\n",
    "        attn = attn.view(batch, n_head, height, width, -1)\n",
    "        attn = torch.softmax(attn, -1)\n",
    "        attn = attn.view(batch, n_head, height, width, height, width)\n",
    "\n",
    "        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n",
    "        out = self.out(out.view(batch, channel, height, width))\n",
    "\n",
    "        return out + input\n",
    "\n",
    "\n",
    "class ResnetBlocWithAttn(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False):\n",
    "        super().__init__()\n",
    "        self.with_attn = with_attn\n",
    "        self.res_block = ResnetBlock(\n",
    "            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout)\n",
    "        if with_attn:\n",
    "            self.attn = SelfAttention(dim_out, norm_groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        x = self.res_block(x, time_emb)\n",
    "        if(self.with_attn):\n",
    "            x = self.attn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=6,\n",
    "        out_channel=3,\n",
    "        inner_channel=32,\n",
    "        norm_groups=32,\n",
    "        channel_mults=(1, 2, 4, 8, 8),\n",
    "        attn_res=(8),\n",
    "        res_blocks=3,\n",
    "        dropout=0,\n",
    "        with_noise_level_emb=True,\n",
    "        image_size=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if with_noise_level_emb:\n",
    "            noise_level_channel = inner_channel\n",
    "            self.noise_level_mlp = nn.Sequential(\n",
    "                PositionalEncoding(inner_channel),\n",
    "                nn.Linear(inner_channel, inner_channel * 4),\n",
    "                Swish(),\n",
    "                nn.Linear(inner_channel * 4, inner_channel)\n",
    "            )\n",
    "        else:\n",
    "            noise_level_channel = None\n",
    "            self.noise_level_mlp = None\n",
    "\n",
    "        num_mults = len(channel_mults)\n",
    "        pre_channel = inner_channel\n",
    "        feat_channels = [pre_channel]\n",
    "        now_res = image_size\n",
    "        downs = [nn.Conv2d(in_channel, inner_channel,\n",
    "                           kernel_size=3, padding=1)]\n",
    "        for ind in range(num_mults):\n",
    "            is_last = (ind == num_mults - 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks):\n",
    "                downs.append(ResnetBlocWithAttn(\n",
    "                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn))\n",
    "                feat_channels.append(channel_mult)\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                downs.append(Downsample(pre_channel))\n",
    "                feat_channels.append(pre_channel)\n",
    "                now_res = now_res//2\n",
    "        self.downs = nn.ModuleList(downs)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=True),\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=False)\n",
    "        ])\n",
    "\n",
    "        ups = []\n",
    "        for ind in reversed(range(num_mults)):\n",
    "            is_last = (ind < 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks+1):\n",
    "                ups.append(ResnetBlocWithAttn(\n",
    "                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                        dropout=dropout, with_attn=use_attn))\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                ups.append(Upsample(pre_channel))\n",
    "                now_res = now_res*2\n",
    "\n",
    "        self.ups = nn.ModuleList(ups)\n",
    "\n",
    "        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        t = self.noise_level_mlp(time) if exists(\n",
    "            self.noise_level_mlp) else None\n",
    "\n",
    "        feats = []\n",
    "    \n",
    "        \n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = checkpoint.checkpoint(layer, x, t, use_reentrant=False) # wrapped memory intensive parts\n",
    "                #x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = checkpoint.checkpoint(layer, x, t, use_reentrant=False)\n",
    "                #x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        for layer in self.ups:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = checkpoint.checkpoint(layer, torch.cat((x, feats.pop()), dim=1), t, use_reentrant=False)\n",
    "\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3e342",
   "metadata": {},
   "source": [
    "Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a8188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T21:00:24.028189Z",
     "iopub.status.busy": "2025-06-23T21:00:24.027963Z",
     "iopub.status.idle": "2025-06-23T21:00:24.051120Z",
     "shell.execute_reply": "2025-06-23T21:00:24.050539Z"
    },
    "papermill": {
     "duration": 0.030328,
     "end_time": "2025-06-23T21:00:24.052249",
     "exception": false,
     "start_time": "2025-06-23T21:00:24.021921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Diffusion ###\n",
    "def _warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n",
    "    betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    warmup_time = int(n_timestep * warmup_frac)\n",
    "    betas[:warmup_time] = np.linspace(\n",
    "        linear_start, linear_end, warmup_time, dtype=np.float64)\n",
    "    return betas\n",
    "\n",
    "\n",
    "def make_beta_schedule(schedule, n_timestep, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n",
    "    if schedule == 'quad':\n",
    "        betas = np.linspace(linear_start ** 0.5, linear_end ** 0.5,\n",
    "                            n_timestep, dtype=np.float64) ** 2\n",
    "    elif schedule == 'linear':\n",
    "        betas = np.linspace(linear_start, linear_end,\n",
    "                            n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'warmup10':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.1)\n",
    "    elif schedule == 'warmup50':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.5)\n",
    "    elif schedule == 'const':\n",
    "        betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        betas = 1. / np.linspace(n_timestep,\n",
    "                                 1, n_timestep, dtype=np.float64)\n",
    "    elif schedule == \"cosine\":\n",
    "        timesteps = (\n",
    "            torch.arange(n_timestep + 1, dtype=torch.float64) /\n",
    "            n_timestep + cosine_s\n",
    "        )\n",
    "        alphas = timesteps / (1 + cosine_s) * math.pi / 2\n",
    "        alphas = torch.cos(alphas).pow(2)\n",
    "        alphas = alphas / alphas[0]\n",
    "        betas = 1 - alphas[1:] / alphas[:-1]\n",
    "        betas = betas.clamp(max=0.999)\n",
    "    else:\n",
    "        raise NotImplementedError(schedule)\n",
    "    return betas\n",
    "\n",
    "\n",
    "# gaussian diffusion trainer class\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        denoise_fn,\n",
    "        image_size,\n",
    "        channels=3,\n",
    "        loss_type='l1',\n",
    "        conditional=True,\n",
    "        schedule_opt=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.denoise_fn = denoise_fn\n",
    "        self.loss_type = loss_type\n",
    "        self.conditional = conditional\n",
    "        if schedule_opt is not None:\n",
    "            pass\n",
    "\n",
    "    def set_loss(self, device):\n",
    "        if self.loss_type == 'l1':\n",
    "            self.loss_func = nn.L1Loss(reduction='sum').to(device)\n",
    "        elif self.loss_type == 'l2':\n",
    "            self.loss_func = nn.MSELoss(reduction='sum').to(device)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, device):\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32, device=device)\n",
    "\n",
    "        betas = make_beta_schedule(\n",
    "            schedule=schedule_opt['schedule'],\n",
    "            n_timestep=schedule_opt['n_timestep'],\n",
    "            linear_start=schedule_opt['linear_start'],\n",
    "            linear_end=schedule_opt['linear_end'])\n",
    "        betas = betas.detach().cpu().numpy() if isinstance(\n",
    "            betas, torch.Tensor) else betas\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n",
    "        self.sqrt_alphas_cumprod_prev = np.sqrt(\n",
    "            np.append(1., alphas_cumprod))\n",
    "\n",
    "        timesteps, = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.register_buffer('betas', to_torch(betas))\n",
    "        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n",
    "        self.register_buffer('alphas_cumprod_prev',\n",
    "                             to_torch(alphas_cumprod_prev))\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer('sqrt_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. - alphas_cumprod)))\n",
    "        self.register_buffer('log_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.log(1. - alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recip_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recipm1_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = betas * \\\n",
    "            (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "        self.register_buffer('posterior_variance',\n",
    "                             to_torch(posterior_variance))\n",
    "        self.register_buffer('posterior_log_variance_clipped', to_torch(\n",
    "            np.log(np.maximum(posterior_variance, 1e-20))))\n",
    "        self.register_buffer('posterior_mean_coef1', to_torch(\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n",
    "        self.register_buffer('posterior_mean_coef2', to_torch(\n",
    "            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return self.sqrt_recip_alphas_cumprod[t] * x_t - \\\n",
    "            self.sqrt_recipm1_alphas_cumprod[t] * noise\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = self.posterior_mean_coef1[t] * \\\n",
    "            x_start + self.posterior_mean_coef2[t] * x_t\n",
    "        posterior_log_variance_clipped = self.posterior_log_variance_clipped[t]\n",
    "        return posterior_mean, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, x, t, clip_denoised: bool, condition_x=None, mask=None):\n",
    "        batch_size = x.shape[0]\n",
    "        noise_level = torch.tensor(\n",
    "            [self.sqrt_alphas_cumprod_prev[t+1]], dtype=torch.float32).repeat(batch_size, 1).to(x.device)\n",
    "        if condition_x is not None:\n",
    "            if condition_x.shape[0] != mask.shape[0]:\n",
    "                repeats = condition_x.shape[0] // mask.shape[0]\n",
    "                mask = mask.repeat(repeats, 1, 1, 1)\n",
    "\n",
    "            denoise_input = torch.cat([condition_x, mask, x], dim=1)\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(denoise_input, noise_level))\n",
    "        else:\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(x, noise_level))\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1., 1.)\n",
    "\n",
    "        model_mean, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t)\n",
    "        return model_mean, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, clip_denoised=True, condition_x=None, mask=None):\n",
    "        model_mean, model_log_variance = self.p_mean_variance(\n",
    "            x=x, t=t, clip_denoised=clip_denoised, condition_x=condition_x, mask=mask)\n",
    "        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "        return model_mean + noise * (0.5 * model_log_variance).exp()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, x_in, mask, continous=False):\n",
    "        device = self.betas.device\n",
    "        sample_inter = (1 | (self.num_timesteps//10))\n",
    "        if not self.conditional:\n",
    "            shape = x_in\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = img\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        else:\n",
    "            x = x_in\n",
    "            shape = x.shape\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = x\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i, condition_x=x, mask=mask)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        if continous:\n",
    "            return ret_img\n",
    "        else:\n",
    "            return ret_img[-1]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        image_size = self.image_size\n",
    "        channels = self.channels\n",
    "        return self.p_sample_loop((batch_size, channels, image_size, image_size), continous)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def super_resolution(self, x_in, mask, continous=False):\n",
    "        return self.p_sample_loop(x_in, mask, continous)\n",
    "\n",
    "    def q_sample(self, x_start, continuous_sqrt_alpha_cumprod, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        return (\n",
    "            continuous_sqrt_alpha_cumprod * x_start +\n",
    "            (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_in, noise=None):\n",
    "        x_start = x_in['GT']\n",
    "        noisy_input = x_in['Noisy']\n",
    "        mask_input = x_in['Mask']\n",
    "        \n",
    "\n",
    "        if noisy_input.shape[0] != mask_input.shape[0]:\n",
    "            repeats = noisy_input.shape[0] // mask_input.shape[0]\n",
    "            mask_input = mask_input.repeat(repeats, 1, 1, 1)\n",
    "\n",
    "        [b, c, h, w] = x_start.shape\n",
    "        t = np.random.randint(1, self.num_timesteps + 1)\n",
    "        continuous_sqrt_alpha_cumprod = torch.tensor(\n",
    "            np.random.uniform(\n",
    "                self.sqrt_alphas_cumprod_prev[t-1],\n",
    "                self.sqrt_alphas_cumprod_prev[t],\n",
    "                size=b\n",
    "            ),\n",
    "            dtype=torch.float32\n",
    "        ).to(x_start.device)\n",
    "        continuous_sqrt_alpha_cumprod = continuous_sqrt_alpha_cumprod.view(b, -1)\n",
    "\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        x_noisy = self.q_sample(\n",
    "            x_start=x_start, continuous_sqrt_alpha_cumprod=continuous_sqrt_alpha_cumprod.view(-1, 1, 1, 1), noise=noise)\n",
    "\n",
    "        if not self.conditional:\n",
    "            x_recon = self.denoise_fn(x_noisy, continuous_sqrt_alpha_cumprod)\n",
    "        else:\n",
    "            x_recon = self.denoise_fn(\n",
    "                torch.cat([noisy_input, mask_input, x_noisy], dim=1), continuous_sqrt_alpha_cumprod)\n",
    "\n",
    "        loss = self.loss_func(noise, x_recon)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.p_losses(x, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa58b3c5",
   "metadata": {
    "papermill": {
     "duration": 0.00493,
     "end_time": "2025-06-23T21:00:24.062210",
     "exception": false,
     "start_time": "2025-06-23T21:00:24.057280",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c1761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T21:00:24.073196Z",
     "iopub.status.busy": "2025-06-23T21:00:24.072963Z",
     "iopub.status.idle": "2025-06-23T21:00:24.083781Z",
     "shell.execute_reply": "2025-06-23T21:00:24.083300Z"
    },
    "papermill": {
     "duration": 0.017531,
     "end_time": "2025-06-23T21:00:24.084743",
     "exception": false,
     "start_time": "2025-06-23T21:00:24.067212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m, std=0.02):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, std)  # BN also uses norm\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m, scale=1):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_orthogonal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='kaiming', scale=1, std=0.02):\n",
    "    # scale for 'kaiming', std for 'normal'.\n",
    "    logger.info('Initialization method [{:s}]'.format(init_type))\n",
    "    if init_type == 'normal':\n",
    "        weights_init_normal_ = functools.partial(weights_init_normal, std=std)\n",
    "        net.apply(weights_init_normal_)\n",
    "    elif init_type == 'kaiming':\n",
    "        weights_init_kaiming_ = functools.partial(\n",
    "            weights_init_kaiming, scale=scale)\n",
    "        net.apply(weights_init_kaiming_)\n",
    "    elif init_type == 'orthogonal':\n",
    "        net.apply(weights_init_orthogonal)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'initialization method [{:s}] not implemented'.format(init_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8701d",
   "metadata": {},
   "source": [
    "Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5901ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "def define_G(opt):\n",
    "    model_opt = opt['model']\n",
    "    if ('norm_groups' not in model_opt['unet']) or model_opt['unet']['norm_groups'] is None:\n",
    "        model_opt['unet']['norm_groups']=32\n",
    "    model = UNet(\n",
    "        in_channel=model_opt['unet']['in_channel'],\n",
    "        out_channel=model_opt['unet']['out_channel'],\n",
    "        norm_groups=model_opt['unet']['norm_groups'],\n",
    "        inner_channel=model_opt['unet']['inner_channel'],\n",
    "        channel_mults=model_opt['unet']['channel_multiplier'],\n",
    "        attn_res=model_opt['unet']['attn_res'],\n",
    "        res_blocks=model_opt['unet']['res_blocks'],\n",
    "        dropout=model_opt['unet']['dropout'],\n",
    "        image_size=model_opt['diffusion']['image_size']\n",
    "    )\n",
    "    netG = GaussianDiffusion(\n",
    "        model,\n",
    "        image_size=model_opt['diffusion']['image_size'],\n",
    "        channels=model_opt['diffusion']['channels'],\n",
    "        loss_type='l2',    # L1 or L2\n",
    "        conditional=model_opt['diffusion']['conditional'],\n",
    "        schedule_opt=model_opt['beta_schedule']['train']\n",
    "    )\n",
    "    if opt['phase'] == 'train':\n",
    "        # init_weights(netG, init_type='kaiming', scale=0.1)\n",
    "        init_weights(netG, init_type='orthogonal')\n",
    "    if opt['gpu_ids']:\n",
    "        assert torch.cuda.is_available()\n",
    "    return netG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4acb07",
   "metadata": {
    "papermill": {
     "duration": 0.004884,
     "end_time": "2025-06-23T21:00:24.094739",
     "exception": false,
     "start_time": "2025-06-23T21:00:24.089855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c704d02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T21:00:24.105636Z",
     "iopub.status.busy": "2025-06-23T21:00:24.105426Z",
     "iopub.status.idle": "2025-06-23T21:00:24.126491Z",
     "shell.execute_reply": "2025-06-23T21:00:24.125989Z"
    },
    "papermill": {
     "duration": 0.027995,
     "end_time": "2025-06-23T21:00:24.127609",
     "exception": false,
     "start_time": "2025-06-23T21:00:24.099614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SR3():\n",
    "    def __init__(self, opt):       \n",
    "        self.opt = opt\n",
    "        self.device = torch.device(\n",
    "            'cuda' if opt['gpu_ids'] is not None else 'cpu')\n",
    "\n",
    "        # mixed precision training\n",
    "        self.scaler = GradScaler()\n",
    "        \n",
    "        self.begin_step = 0\n",
    "        self.begin_epoch = 0\n",
    "\n",
    "        # define network and load pretrained models\n",
    "        self.netG = self.set_device(define_G(opt))\n",
    "        self.schedule_phase = None\n",
    "        \n",
    "\n",
    "        # set loss and load resume state\n",
    "        self.set_loss()\n",
    "        self.set_new_noise_schedule(\n",
    "            opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "        if self.opt['phase'] == 'train':\n",
    "            self.netG.train()\n",
    "            if opt['model']['finetune_norm']:\n",
    "                optim_params = []\n",
    "                for k, v in self.netG.named_parameters():\n",
    "                    v.requires_grad = False\n",
    "                    if k.find('transformer') >= 0:\n",
    "                        v.requires_grad = True\n",
    "                        v.data.zero_()\n",
    "                        optim_params.append(v)\n",
    "                        logger.info(\n",
    "                            'Params [{:s}] initialized to 0 and will optimize.'.format(k))\n",
    "            else:\n",
    "                optim_params = list(self.netG.parameters())\n",
    "\n",
    "            self.optG = torch.optim.Adam(\n",
    "                optim_params, lr=opt['train'][\"optimizer\"][\"lr\"],\n",
    "                weight_decay=1e-6)\n",
    "\n",
    "            #learning rate scheduler\n",
    "            self.schedulerG = lr_scheduler.CosineAnnealingLR(\n",
    "                self.optG, T_max=self.opt['train']['n_iter'], eta_min=1e-6)\n",
    "            \n",
    "            self.log_dict = OrderedDict()\n",
    "        self.load_network()\n",
    "        self.print_network()\n",
    "\n",
    "    def set_device(self, x):\n",
    "        if isinstance(x, dict):\n",
    "            for key, item in x.items():\n",
    "                if item is not None and type(item)==torch.Tensor:\n",
    "                    x[key] = item.to(self.device)\n",
    "        elif isinstance(x, list):\n",
    "            for item in x:\n",
    "                if item is not None:\n",
    "                    item = item.to(self.device)\n",
    "        else:\n",
    "            x = x.to(self.device)\n",
    "        return x\n",
    "\n",
    "    def get_network_description(self, network):\n",
    "        '''Get the string and total parameters of the network'''\n",
    "        if isinstance(network, nn.DataParallel):\n",
    "            network = network.module\n",
    "        s = str(network)\n",
    "        n = sum(map(lambda x: x.numel(), network.parameters()))\n",
    "        return s, n\n",
    "\n",
    "    def feed_data(self, data):\n",
    "        self.data = self.set_device(data)\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.optG.zero_grad()\n",
    "\n",
    "        # mixed precision\n",
    "        with torch.cuda.amp.autocast(): \n",
    "            l_pix = self.netG(self.data)\n",
    "            b, c, h, w = self.data['GT'].shape\n",
    "            l_pix = l_pix.sum()/int(b*c*h*w)\n",
    "\n",
    "        self.scaler.scale(l_pix).backward()\n",
    "\n",
    "        self.scaler.unscale_(self.optG)\n",
    "        torch.nn.utils.clip_grad_norm_(self.netG.parameters(), max_norm=0.5)\n",
    "\n",
    "        self.scaler.step(self.optG)\n",
    "        self.scaler.update()  \n",
    "\n",
    "        #scheduler step\n",
    "        self.schedulerG.step()\n",
    "\n",
    "        # set log\n",
    "        self.log_dict['l_pix'] = l_pix.item()\n",
    "\n",
    "        return l_pix.item()\n",
    "\n",
    "    def evaluate_loss(self, data):\n",
    "        \"\"\"\n",
    "        Calculates the diffusion loss for a given batch of data without training.\n",
    "        Sets model to eval mode and uses torch.no_grad() for efficiency.\n",
    "        \"\"\"\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            self.feed_data(data)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                l_pix = self.netG(self.data)\n",
    "                b, c, h, w = self.data['GT'].shape\n",
    "                l_pix = l_pix.sum() / int(b * c * h * w)\n",
    "        self.netG.train() \n",
    "        return l_pix.item()\n",
    "    \n",
    "    def test(self, continous=False):\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            noisy_input = self.data['Noisy']\n",
    "            mask_input = self.data['Mask']\n",
    "            \n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.SR = self.netG.module.super_resolution(\n",
    "                    noisy_input, mask_input, continous)\n",
    "            else:\n",
    "                self.SR = self.netG.super_resolution(\n",
    "                    noisy_input, mask_input, continous)\n",
    "        self.netG.train()\n",
    "\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.SR = self.netG.module.sample(batch_size, continous)\n",
    "            else:\n",
    "                self.SR = self.netG.sample(batch_size, continous)\n",
    "        self.netG.train()\n",
    "\n",
    "    def set_loss(self):\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            self.netG.module.set_loss(self.device)\n",
    "        else:\n",
    "            self.netG.set_loss(self.device)\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, schedule_phase='train'):\n",
    "        if self.schedule_phase is None or self.schedule_phase != schedule_phase:\n",
    "            self.schedule_phase = schedule_phase\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.netG.module.set_new_noise_schedule(\n",
    "                    schedule_opt, self.device)\n",
    "            else:\n",
    "                self.netG.set_new_noise_schedule(schedule_opt, self.device)\n",
    "\n",
    "    def get_current_log(self):\n",
    "        return self.log_dict\n",
    "\n",
    "    def get_current_visuals(self, need_LR=True, sample=False):\n",
    "        out_dict = OrderedDict()\n",
    "        if sample:\n",
    "            out_dict['SAM'] = self.SR.detach().float().cpu()\n",
    "        else:\n",
    "            out_dict['SR'] = self.SR.detach().float().cpu()\n",
    "            out_dict['Noisy'] = self.data['Noisy'].detach().float().cpu()\n",
    "            out_dict['GT'] = self.data['GT'].detach().float().cpu()\n",
    "        return out_dict\n",
    "\n",
    "    def print_network(self):\n",
    "        s, n = self.get_network_description(self.netG)\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            net_struc_str = '{} - {}'.format(self.netG.__class__.__name__,\n",
    "                                             self.netG.module.__class__.__name__)\n",
    "        else:\n",
    "            net_struc_str = '{}'.format(self.netG.__class__.__name__)\n",
    "\n",
    "        logger.info(\n",
    "            'Network G structure: {}, with parameters: {:,d}'.format(net_struc_str, n))\n",
    "        logger.info(s)\n",
    "\n",
    "    def save_network(self, epoch, iter_step, is_final=False):\n",
    "        if is_final:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        else:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        # gen\n",
    "        network = self.netG\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            network = network.module\n",
    "        state_dict = network.state_dict()\n",
    "        for key, param in state_dict.items():\n",
    "            state_dict[key] = param.cpu()\n",
    "        torch.save(state_dict, gen_path)\n",
    "        # opt\n",
    "        opt_state = {'epoch': epoch, 'iter': iter_step,\n",
    "                     'scheduler': None, 'optimizer': None}\n",
    "        opt_state['optimizer'] = self.optG.state_dict()\n",
    "        torch.save(opt_state, opt_path)\n",
    "\n",
    "        logger.info(\n",
    "            'Saved model in [{:s}] ...'.format(gen_path))\n",
    "\n",
    "    def load_network(self):\n",
    "        load_path = self.opt['path']['resume_state']\n",
    "        if load_path is not None:\n",
    "            logger.info(\n",
    "                'Loading pretrained model for G [{:s}] ...'.format(load_path))\n",
    "            gen_path = '{}_gen.pth'.format(load_path)\n",
    "            opt_path = '{}_opt.pth'.format(load_path)\n",
    "            network = self.netG\n",
    "\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                network = network.module\n",
    "            network.load_state_dict(torch.load(\n",
    "                gen_path), strict=(not self.opt['model']['finetune_norm']))\n",
    "            \n",
    "            if self.opt['phase'] == 'train':\n",
    "\n",
    "                opt = torch.load(opt_path)\n",
    "                self.optG.load_state_dict(opt['optimizer'])\n",
    "                self.begin_step = opt['iter']\n",
    "                self.begin_epoch = opt['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8d2a3",
   "metadata": {
    "papermill": {
     "duration": 0.004928,
     "end_time": "2025-06-23T21:00:24.137830",
     "exception": false,
     "start_time": "2025-06-23T21:00:24.132902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ed37c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-23T21:00:30.211483Z",
     "iopub.status.busy": "2025-06-23T21:00:30.210991Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-06-23T21:00:30.204552",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3055643826.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(): # <--- Add this context manager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 21:05:11.331 - INFO: <epoch:  1, iter:     100> l_pix: inf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 21:08:12.537 - INFO: <epoch:  1, iter:     200> l_pix: inf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 21:11:13.739 - INFO: <epoch:  1, iter:     300> l_pix: inf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-06-23 21:14:14.950 - INFO: <epoch:  1, iter:     400> l_pix: inf \n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "diffusion = SR3(opt)\n",
    "\n",
    "# Train\n",
    "epoch_loss_list = []\n",
    "\n",
    "current_step = diffusion.begin_step\n",
    "current_epoch = diffusion.begin_epoch\n",
    "n_iter = opt['train']['n_iter']\n",
    "\n",
    "if opt['path']['resume_state']:\n",
    "    logger.info('Resuming training from epoch: {}, iter: {}.'.format(\n",
    "        current_epoch, current_step))\n",
    "\n",
    "diffusion.set_new_noise_schedule(\n",
    "    opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])\n",
    "\n",
    "\n",
    "if opt['phase'] == 'train':\n",
    "    while current_step < n_iter:\n",
    "        current_epoch += 1\n",
    "        epoch_loss_values = []\n",
    "\n",
    "        # Reset gradients at the beginning of each epoch\n",
    "        diffusion.optG.zero_grad() \n",
    "        \n",
    "        for _, train_data in enumerate(train_loader): \n",
    "            current_step += 1\n",
    "            if current_step > n_iter:\n",
    "                break\n",
    "            diffusion.feed_data(train_data)\n",
    "\n",
    "            current_l_pix = diffusion.optimize_parameters()\n",
    "            epoch_loss_values.append(current_l_pix)\n",
    "                \n",
    "            # log\n",
    "            if current_step % opt['train']['print_freq'] == 0:\n",
    "                logs = diffusion.get_current_log()\n",
    "                message = '<epoch:{:3d}, iter:{:8,d}> '.format(\n",
    "                    current_epoch, current_step)\n",
    "                for k, v in logs.items():\n",
    "                    message += '{:s}: {:.4e} '.format(k, v)\n",
    "                logger.info(message)\n",
    "                \n",
    "            if current_step % opt['train']['save_checkpoint_freq'] == 0:\n",
    "                logger.info('Saving models and training states.')\n",
    "                diffusion.save_network(current_epoch, current_step)\n",
    "            \n",
    "            if current_step == n_iter:\n",
    "                logger.info(\"Saving final model\")\n",
    "                diffusion.save_network(current_epoch, current_step, is_final=True)\n",
    "\n",
    "\n",
    "        epoch_loss = sum(epoch_loss_values)/len(epoch_loss_values)\n",
    "        print('Epoch Loss: ', epoch_loss)\n",
    "        epoch_loss_list.append(epoch_loss)\n",
    "\n",
    "    # save model\n",
    "    print('Epoch Loss List: ', epoch_loss_list)\n",
    "    logger.info('End of training.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b470a27a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d75ab2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_loss_curve(epoch_loss_list, filename='loss_curve.png'):\n",
    "    epochs = range(1, len(epoch_loss_list) + 1)  # X-axis starts at 1\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, epoch_loss_list, marker='o', label='Training Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(epochs)  # Set integer ticks\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61c5da",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_loss_curve(epoch_loss_list, \"/kaggle/working/train_loss.png\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7419713,
     "sourceId": 11813224,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7419718,
     "sourceId": 11813229,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7419725,
     "sourceId": 11813237,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7421178,
     "sourceId": 11815303,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7712535,
     "sourceId": 12240417,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7717803,
     "sourceId": 12248669,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-23T20:59:40.935809",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
