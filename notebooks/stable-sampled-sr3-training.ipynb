{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46f91fa",
   "metadata": {
    "papermill": {
     "duration": 0.00622,
     "end_time": "2025-05-13T23:10:41.157242",
     "exception": false,
     "start_time": "2025-05-13T23:10:41.151022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f2f37ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:10:41.168896Z",
     "iopub.status.busy": "2025-05-13T23:10:41.168607Z",
     "iopub.status.idle": "2025-05-13T23:10:41.172783Z",
     "shell.execute_reply": "2025-05-13T23:10:41.172099Z"
    },
    "papermill": {
     "duration": 0.011154,
     "end_time": "2025-05-13T23:10:41.173868",
     "exception": false,
     "start_time": "2025-05-13T23:10:41.162714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9c933e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:10:41.185336Z",
     "iopub.status.busy": "2025-05-13T23:10:41.185141Z",
     "iopub.status.idle": "2025-05-13T23:10:45.161347Z",
     "shell.execute_reply": "2025-05-13T23:10:45.160781Z"
    },
    "papermill": {
     "duration": 3.983911,
     "end_time": "2025-05-13T23:10:45.162724",
     "exception": false,
     "start_time": "2025-05-13T23:10:41.178813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import logging\n",
    "#from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from re import split\n",
    "import torch.utils.data\n",
    "\n",
    "# import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "import functools\n",
    "from torch.nn import init\n",
    "from torch.nn import modules\n",
    "\n",
    "# u-net\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from inspect import isfunction\n",
    "\n",
    "# diffusion\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ff17d",
   "metadata": {
    "papermill": {
     "duration": 0.004953,
     "end_time": "2025-05-13T23:10:45.173159",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.168206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac50743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:10:45.184556Z",
     "iopub.status.busy": "2025-05-13T23:10:45.184233Z",
     "iopub.status.idle": "2025-05-13T23:10:45.190375Z",
     "shell.execute_reply": "2025-05-13T23:10:45.189897Z"
    },
    "papermill": {
     "duration": 0.013128,
     "end_time": "2025-05-13T23:10:45.191450",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.178322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"denoising\",\n",
    "    \"phase\": \"train\", # train or test (or val?? -> what is phase even used for also?)\n",
    "    \"gpu_ids\": [0, 1], \n",
    "    \"debug\": False,  \n",
    "    \"enable_wandb\": False,  \n",
    "    \"log_wandb_ckpt\": False,  \n",
    "    \"log_eval\": False,  \n",
    "    \"path\": {\n",
    "        \"log\": \"/kaggle/working/logs\",\n",
    "        \"tb_logger\": \"/kaggle/working/tb_logger\",\n",
    "        \"results\": \"/kaggle/working/results\",\n",
    "        \"checkpoint\": \"/kaggle/working/checkpoint\",\n",
    "        \"resume_state\": None\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-train-1-normalized/data/noisy_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-normalized/data/noisy_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-normalized/data/noisy_func_train_3.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-train-1-normalized/data/gt_func_train_1.npy',\n",
    "                '/kaggle/input/fmri-train-2-normalized/data/gt_func_train_2.npy',\n",
    "                '/kaggle/input/fmri-train-3-normalized/data/gt_func_train_3.npy'],\n",
    "            \"batch_size\": 1,\n",
    "            \"num_workers\": 1,\n",
    "            \"use_shuffle\": True\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"noisy_data_paths\": ['/kaggle/input/fmri-test/data/noisy_func_test.npy'],\n",
    "            \"gt_data_paths\": ['/kaggle/input/fmri-test/data/gt_func_test.npy']\n",
    "        }\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\",\n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 2,\n",
    "            \"out_channel\": 1,\n",
    "            \"inner_channel\": 64,\n",
    "            \"norm_groups\": 16,\n",
    "            \"channel_multiplier\": [1, 2, 4, 8],\n",
    "            \"attn_res\": [],\n",
    "            \"res_blocks\": 1,\n",
    "            \"dropout\": 0\n",
    "        },\n",
    "        \"beta_schedule\": {\n",
    "            \"train\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 64,\n",
    "            \"channels\": 1,\n",
    "            \"conditional\": True\n",
    "        }\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"n_iter\": 27000,\n",
    "        \"val_freq\": 1e4,\n",
    "        \"save_checkpoint_freq\": 21600,\n",
    "        \"print_freq\": 100,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"lr\": 3e-4\n",
    "        },\n",
    "        \"ema_scheduler\": {\n",
    "            \"step_start_ema\": 22500,\n",
    "            \"update_ema_every\": 1,\n",
    "            \"ema_decay\": 0.996\n",
    "        }\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        \"project\": \"distributed_high_sr_ffhq\"\n",
    "    },\n",
    "    \"config_file\": \"config/sr_sr3_16_128.json\"  # from CLI\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9328ea56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:10:45.202007Z",
     "iopub.status.busy": "2025-05-13T23:10:45.201822Z",
     "iopub.status.idle": "2025-05-13T23:10:45.205803Z",
     "shell.execute_reply": "2025-05-13T23:10:45.205330Z"
    },
    "papermill": {
     "duration": 0.01052,
     "end_time": "2025-05-13T23:10:45.206860",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.196340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(opt['path']['log'], exist_ok=True)\n",
    "os.makedirs(opt['path']['tb_logger'], exist_ok=True)\n",
    "os.makedirs(opt['path']['results'], exist_ok=True)\n",
    "os.makedirs(opt['path']['checkpoint'], exist_ok=True)\n",
    "#os.makedirs(opt['path']['resume_state'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fbb08",
   "metadata": {
    "papermill": {
     "duration": 0.004755,
     "end_time": "2025-05-13T23:10:45.216450",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.211695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291837d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:10:45.227138Z",
     "iopub.status.busy": "2025-05-13T23:10:45.226942Z",
     "iopub.status.idle": "2025-05-13T23:10:45.233701Z",
     "shell.execute_reply": "2025-05-13T23:10:45.233219Z"
    },
    "papermill": {
     "duration": 0.013245,
     "end_time": "2025-05-13T23:10:45.234592",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.221347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logging\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def dict2str(opt, indent_l=1):\n",
    "    '''dict to string for logger'''\n",
    "    msg = ''\n",
    "    for k, v in opt.items():\n",
    "        if isinstance(v, dict):\n",
    "            msg += ' ' * (indent_l * 2) + k + ':[\\n'\n",
    "            msg += dict2str(v, indent_l + 1)\n",
    "            msg += ' ' * (indent_l * 2) + ']\\n'\n",
    "        else:\n",
    "            msg += ' ' * (indent_l * 2) + k + ': ' + str(v) + '\\n'\n",
    "    return msg\n",
    "\n",
    "def setup_logger(logger_name, root, phase, level=logging.INFO, screen=False):\n",
    "    '''set up logger'''\n",
    "    l = logging.getLogger(logger_name)\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s.%(msecs)03d - %(levelname)s: %(message)s', datefmt='%y-%m-%d %H:%M:%S')\n",
    "    log_file = os.path.join(root, '{}.log'.format(phase))\n",
    "    fh = logging.FileHandler(log_file, mode='w')\n",
    "    fh.setFormatter(formatter)\n",
    "    l.setLevel(level)\n",
    "    l.addHandler(fh)\n",
    "    if screen:\n",
    "        sh = logging.StreamHandler()\n",
    "        sh.setFormatter(formatter)\n",
    "        l.addHandler(sh)\n",
    "\n",
    "\n",
    "setup_logger(None, opt['path']['log'],\n",
    "                    'train', level=logging.INFO, screen=True)\n",
    "setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "logger = logging.getLogger('base')\n",
    "#logger.info(dict2str(opt))\n",
    "#tb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])\n",
    "\n",
    "# # Initialize WandbLogger\n",
    "# if opt['enable_wandb']:\n",
    "#     import wandb\n",
    "#     wandb_logger = WandbLogger(opt)\n",
    "#     wandb.define_metric('validation/val_step')\n",
    "#     wandb.define_metric('epoch')\n",
    "#     wandb.define_metric(\"validation/*\", step_metric=\"val_step\")\n",
    "#     val_step = 0\n",
    "# else:\n",
    "#     wandb_logger = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dbbd7d",
   "metadata": {
    "papermill": {
     "duration": 0.004588,
     "end_time": "2025-05-13T23:10:45.243957",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.239369",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862b7a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:10:45.254596Z",
     "iopub.status.busy": "2025-05-13T23:10:45.254405Z",
     "iopub.status.idle": "2025-05-13T23:10:45.261162Z",
     "shell.execute_reply": "2025-05-13T23:10:45.260500Z"
    },
    "papermill": {
     "duration": 0.01321,
     "end_time": "2025-05-13T23:10:45.262171",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.248961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, noisy_images_paths: list, gt_images_paths: list):\n",
    "        \"\"\"Initialize fMRI dataset for denoising with memory-efficient loading.\n",
    "        \n",
    "        Args:\n",
    "            noisy_images_paths (list): List of paths to noisy fMRI volumes (.npy files)\n",
    "            gt_images_paths (list): List of paths to ground truth fMRI volumes (.npy files)\n",
    "        \"\"\"\n",
    "        self.noisy_paths = noisy_images_paths\n",
    "        self.gt_paths = gt_images_paths\n",
    "        \n",
    "        # Get the data shape and total slices without loading all data\n",
    "        # Just load file info and calculate indices\n",
    "        self.file_slice_mapping = []\n",
    "        self.z_t_dimension_sizes = []\n",
    "        total_slices = 0\n",
    "        dataset_length = 0 # in terms of indeces that can be iteratet over at the end (less than slice number due to batch loading within get_item)\n",
    "        \n",
    "        for i, path in enumerate(noisy_images_paths):\n",
    "            # Load metadata about the file shape without loading full content\n",
    "            data_shape = np.load(path, mmap_mode='r').shape\n",
    "            num_slices = data_shape[2] * data_shape[3]  # z * t\n",
    "            self.z_t_dimension_sizes.append((data_shape[2], data_shape[3]))\n",
    "            \n",
    "            # Store mapping information: which file and which t index (has been done due to more efficient data loading, no information aggregation based thinking behind that)\n",
    "            for batch_idx in range(0, data_shape[3]):\n",
    "                self.file_slice_mapping.append((i, batch_idx))\n",
    "                dataset_length += 1\n",
    "            \n",
    "            total_slices += num_slices \n",
    "            \n",
    "        self.data_len = dataset_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Use the mapping to determine which file and slice to load\n",
    "        file_idx, t_idx = self.file_slice_mapping[index]\n",
    "        \n",
    "        # Load data from the specific file\n",
    "        noisy_file_path = self.noisy_paths[file_idx]\n",
    "        gt_file_path = self.gt_paths[file_idx]\n",
    "        \n",
    "        # Load the full 4D array with mmap_mode to avoid loading everything\n",
    "        noisy_volume = np.load(noisy_file_path, mmap_mode='r')\n",
    "        gt_volume = np.load(gt_file_path, mmap_mode='r')\n",
    "        \n",
    "        # Extract only the slice we need\n",
    "        noisy_slice = noisy_volume[:, :, :, t_idx].copy()  # Force copy from mmap\n",
    "        gt_slice = gt_volume[:, :, :, t_idx].copy()\n",
    "        \n",
    "        return {\n",
    "            'GT': torch.tensor(gt_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Noisy': torch.tensor(noisy_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n",
    "            'Index': index\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1468eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:10:45.272362Z",
     "iopub.status.busy": "2025-05-13T23:10:45.272178Z",
     "iopub.status.idle": "2025-05-13T23:10:45.276995Z",
     "shell.execute_reply": "2025-05-13T23:10:45.276472Z"
    },
    "papermill": {
     "duration": 0.011118,
     "end_time": "2025-05-13T23:10:45.278017",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.266899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_merge_batches(batch):\n",
    "    merged = {\n",
    "        'Noisy': torch.cat([item['Noisy'] for item in batch], dim=0),\n",
    "        'GT': torch.cat([item['GT'] for item in batch], dim=0),\n",
    "        'Index': [item['Index'] for item in batch]\n",
    "    }\n",
    "    return merged\n",
    "\n",
    "def create_dataloader(dataset, dataset_opt, phase):\n",
    "    '''create dataloader '''\n",
    "    if phase == 'train':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=dataset_opt['batch_size'],\n",
    "            shuffle=dataset_opt['use_shuffle'],\n",
    "            num_workers=dataset_opt['num_workers'],\n",
    "            pin_memory=True,\n",
    "            collate_fn = collate_merge_batches)\n",
    "    elif phase == 'test':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True, collate_fn = lambda x: x[0])\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Dataloader [{:s}] is not found.'.format(phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d649aa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:10:45.288424Z",
     "iopub.status.busy": "2025-05-13T23:10:45.288235Z",
     "iopub.status.idle": "2025-05-13T23:10:45.468279Z",
     "shell.execute_reply": "2025-05-13T23:10:45.467721Z"
    },
    "papermill": {
     "duration": 0.186646,
     "end_time": "2025-05-13T23:10:45.469570",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.282924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "for phase, dataset_opt in opt['datasets'].items():\n",
    "    if phase == 'train' and opt['phase'] != 'test':\n",
    "        train_set = PairwiseDataset(dataset_opt['noisy_data_paths'], dataset_opt['gt_data_paths'])\n",
    "        train_loader = create_dataloader(\n",
    "            train_set, dataset_opt, phase)\n",
    "    elif phase == 'test':\n",
    "        test_set = PairwiseDataset(dataset_opt['noisy_data_paths'], dataset_opt['gt_data_paths'])\n",
    "        test_loader = create_dataloader(\n",
    "            test_set, dataset_opt, phase)\n",
    "# logger.info('Initial Dataset Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc115033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:10:45.480778Z",
     "iopub.status.busy": "2025-05-13T23:10:45.480390Z",
     "iopub.status.idle": "2025-05-13T23:11:19.613410Z",
     "shell.execute_reply": "2025-05-13T23:11:19.612866Z"
    },
    "papermill": {
     "duration": 34.139826,
     "end_time": "2025-05-13T23:11:19.614752",
     "exception": false,
     "start_time": "2025-05-13T23:10:45.474926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noisy_slice = train_set[400][\"Noisy\"]\n",
    "gt_slice = train_set[400][\"GT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc71180",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:11:19.625902Z",
     "iopub.status.busy": "2025-05-13T23:11:19.625642Z",
     "iopub.status.idle": "2025-05-13T23:11:19.628553Z",
     "shell.execute_reply": "2025-05-13T23:11:19.628015Z"
    },
    "papermill": {
     "duration": 0.009393,
     "end_time": "2025-05-13T23:11:19.629519",
     "exception": false,
     "start_time": "2025-05-13T23:11:19.620126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for _, data in train_loader:\n",
    "#     print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ee1947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:11:19.640210Z",
     "iopub.status.busy": "2025-05-13T23:11:19.640018Z",
     "iopub.status.idle": "2025-05-13T23:11:19.990424Z",
     "shell.execute_reply": "2025-05-13T23:11:19.989879Z"
    },
    "papermill": {
     "duration": 0.357639,
     "end_time": "2025-05-13T23:11:19.992063",
     "exception": false,
     "start_time": "2025-05-13T23:11:19.634424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3f0024b610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot ground truth image\n",
    "axes[0].imshow(noisy_slice[0,0,:,:], cmap='gray')\n",
    "axes[1].imshow(gt_slice[0,0,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776bb5c6",
   "metadata": {
    "papermill": {
     "duration": 0.005418,
     "end_time": "2025-05-13T23:11:20.003663",
     "exception": false,
     "start_time": "2025-05-13T23:11:19.998245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838a56a",
   "metadata": {
    "papermill": {
     "duration": 0.005252,
     "end_time": "2025-05-13T23:11:20.014505",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.009253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb321af7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:11:20.026557Z",
     "iopub.status.busy": "2025-05-13T23:11:20.026347Z",
     "iopub.status.idle": "2025-05-13T23:11:20.029864Z",
     "shell.execute_reply": "2025-05-13T23:11:20.029384Z"
    },
    "papermill": {
     "duration": 0.010695,
     "end_time": "2025-05-13T23:11:20.030931",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.020236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generic functions\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3344388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:11:20.043420Z",
     "iopub.status.busy": "2025-05-13T23:11:20.043227Z",
     "iopub.status.idle": "2025-05-13T23:11:20.065791Z",
     "shell.execute_reply": "2025-05-13T23:11:20.065294Z"
    },
    "papermill": {
     "duration": 0.030056,
     "end_time": "2025-05-13T23:11:20.066829",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.036773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### U-Net ###\n",
    "\n",
    "# PositionalEncoding Source https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, noise_level):\n",
    "        count = self.dim // 2\n",
    "        step = torch.arange(count, dtype=noise_level.dtype,\n",
    "                            device=noise_level.device) / count\n",
    "        encoding = noise_level.unsqueeze(\n",
    "            1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n",
    "        encoding = torch.cat(\n",
    "            [torch.sin(encoding), torch.cos(encoding)], dim=-1)\n",
    "        return encoding\n",
    "\n",
    "\n",
    "class FeatureWiseAffine(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_affine_level=False):\n",
    "        super(FeatureWiseAffine, self).__init__()\n",
    "        self.use_affine_level = use_affine_level\n",
    "        self.noise_func = nn.Sequential(\n",
    "            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n",
    "        )\n",
    "\n",
    "    def forward(self, x, noise_embed):\n",
    "        batch = x.shape[0]\n",
    "        if self.use_affine_level:\n",
    "            gamma, beta = self.noise_func(noise_embed).view(\n",
    "                batch, -1, 1, 1).chunk(2, dim=1)\n",
    "            x = (1 + gamma) * x + beta\n",
    "        else:\n",
    "            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(self.up(x))\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# building block modules\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, dim_out, groups=32, dropout=0):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.GroupNorm(groups, dim),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32):\n",
    "        super().__init__()\n",
    "        self.noise_func = FeatureWiseAffine(\n",
    "            noise_level_emb_dim, dim_out, use_affine_level)\n",
    "\n",
    "        self.block1 = Block(dim, dim_out, groups=norm_groups)\n",
    "        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout)\n",
    "        self.res_conv = nn.Conv2d(\n",
    "            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        b, c, h, w = x.shape\n",
    "        h = self.block1(x)\n",
    "        h = self.noise_func(h, time_emb)\n",
    "        h = self.block2(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channel, n_head=1, norm_groups=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "\n",
    "        self.norm = nn.GroupNorm(norm_groups, in_channel)\n",
    "        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n",
    "        self.out = nn.Conv2d(in_channel, in_channel, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch, channel, height, width = input.shape\n",
    "        n_head = self.n_head\n",
    "        head_dim = channel // n_head\n",
    "\n",
    "        norm = self.norm(input)\n",
    "        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n",
    "        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n",
    "\n",
    "        attn = torch.einsum(\n",
    "            \"bnchw, bncyx -> bnhwyx\", query, key\n",
    "        ).contiguous() / math.sqrt(channel)\n",
    "        attn = attn.view(batch, n_head, height, width, -1)\n",
    "        attn = torch.softmax(attn, -1)\n",
    "        attn = attn.view(batch, n_head, height, width, height, width)\n",
    "\n",
    "        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n",
    "        out = self.out(out.view(batch, channel, height, width))\n",
    "\n",
    "        return out + input\n",
    "\n",
    "\n",
    "class ResnetBlocWithAttn(nn.Module):\n",
    "    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False):\n",
    "        super().__init__()\n",
    "        self.with_attn = with_attn\n",
    "        self.res_block = ResnetBlock(\n",
    "            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout)\n",
    "        if with_attn:\n",
    "            self.attn = SelfAttention(dim_out, norm_groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time_emb):\n",
    "        x = self.res_block(x, time_emb)\n",
    "        if(self.with_attn):\n",
    "            x = self.attn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channel=6,\n",
    "        out_channel=3,\n",
    "        inner_channel=32,\n",
    "        norm_groups=32,\n",
    "        channel_mults=(1, 2, 4, 8, 8),\n",
    "        attn_res=(8),\n",
    "        res_blocks=3,\n",
    "        dropout=0,\n",
    "        with_noise_level_emb=True,\n",
    "        image_size=128\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if with_noise_level_emb:\n",
    "            noise_level_channel = inner_channel\n",
    "            self.noise_level_mlp = nn.Sequential(\n",
    "                PositionalEncoding(inner_channel),\n",
    "                nn.Linear(inner_channel, inner_channel * 4),\n",
    "                Swish(),\n",
    "                nn.Linear(inner_channel * 4, inner_channel)\n",
    "            )\n",
    "        else:\n",
    "            noise_level_channel = None\n",
    "            self.noise_level_mlp = None\n",
    "\n",
    "        num_mults = len(channel_mults)\n",
    "        pre_channel = inner_channel\n",
    "        feat_channels = [pre_channel]\n",
    "        now_res = image_size\n",
    "        downs = [nn.Conv2d(in_channel, inner_channel,\n",
    "                           kernel_size=3, padding=1)]\n",
    "        for ind in range(num_mults):\n",
    "            is_last = (ind == num_mults - 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks):\n",
    "                downs.append(ResnetBlocWithAttn(\n",
    "                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn))\n",
    "                feat_channels.append(channel_mult)\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                downs.append(Downsample(pre_channel))\n",
    "                feat_channels.append(pre_channel)\n",
    "                now_res = now_res//2\n",
    "        self.downs = nn.ModuleList(downs)\n",
    "\n",
    "        self.mid = nn.ModuleList([\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=True),\n",
    "            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                               dropout=dropout, with_attn=False)\n",
    "        ])\n",
    "\n",
    "        ups = []\n",
    "        for ind in reversed(range(num_mults)):\n",
    "            is_last = (ind < 1)\n",
    "            use_attn = (now_res in attn_res)\n",
    "            channel_mult = inner_channel * channel_mults[ind]\n",
    "            for _ in range(0, res_blocks+1):\n",
    "                ups.append(ResnetBlocWithAttn(\n",
    "                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n",
    "                        dropout=dropout, with_attn=use_attn))\n",
    "                pre_channel = channel_mult\n",
    "            if not is_last:\n",
    "                ups.append(Upsample(pre_channel))\n",
    "                now_res = now_res*2\n",
    "\n",
    "        self.ups = nn.ModuleList(ups)\n",
    "\n",
    "        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        t = self.noise_level_mlp(time) if exists(\n",
    "            self.noise_level_mlp) else None\n",
    "\n",
    "        feats = []\n",
    "        for layer in self.downs:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "            feats.append(x)\n",
    "\n",
    "        for layer in self.mid:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(x, t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        for layer in self.ups:\n",
    "            if isinstance(layer, ResnetBlocWithAttn):\n",
    "                x = layer(torch.cat((x, feats.pop()), dim=1), t)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd1bfda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:11:20.079186Z",
     "iopub.status.busy": "2025-05-13T23:11:20.078973Z",
     "iopub.status.idle": "2025-05-13T23:11:20.101559Z",
     "shell.execute_reply": "2025-05-13T23:11:20.100890Z"
    },
    "papermill": {
     "duration": 0.030044,
     "end_time": "2025-05-13T23:11:20.102568",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.072524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Diffusion ###\n",
    "def _warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n",
    "    betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    warmup_time = int(n_timestep * warmup_frac)\n",
    "    betas[:warmup_time] = np.linspace(\n",
    "        linear_start, linear_end, warmup_time, dtype=np.float64)\n",
    "    return betas\n",
    "\n",
    "\n",
    "def make_beta_schedule(schedule, n_timestep, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n",
    "    if schedule == 'quad':\n",
    "        betas = np.linspace(linear_start ** 0.5, linear_end ** 0.5,\n",
    "                            n_timestep, dtype=np.float64) ** 2\n",
    "    elif schedule == 'linear':\n",
    "        betas = np.linspace(linear_start, linear_end,\n",
    "                            n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'warmup10':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.1)\n",
    "    elif schedule == 'warmup50':\n",
    "        betas = _warmup_beta(linear_start, linear_end,\n",
    "                             n_timestep, 0.5)\n",
    "    elif schedule == 'const':\n",
    "        betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n",
    "    elif schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n",
    "        betas = 1. / np.linspace(n_timestep,\n",
    "                                 1, n_timestep, dtype=np.float64)\n",
    "    elif schedule == \"cosine\":\n",
    "        timesteps = (\n",
    "            torch.arange(n_timestep + 1, dtype=torch.float64) /\n",
    "            n_timestep + cosine_s\n",
    "        )\n",
    "        alphas = timesteps / (1 + cosine_s) * math.pi / 2\n",
    "        alphas = torch.cos(alphas).pow(2)\n",
    "        alphas = alphas / alphas[0]\n",
    "        betas = 1 - alphas[1:] / alphas[:-1]\n",
    "        betas = betas.clamp(max=0.999)\n",
    "    else:\n",
    "        raise NotImplementedError(schedule)\n",
    "    return betas\n",
    "\n",
    "\n",
    "# gaussian diffusion trainer class\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        denoise_fn,\n",
    "        image_size,\n",
    "        channels=3,\n",
    "        loss_type='l1',\n",
    "        conditional=True,\n",
    "        schedule_opt=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.denoise_fn = denoise_fn\n",
    "        self.loss_type = loss_type\n",
    "        self.conditional = conditional\n",
    "        if schedule_opt is not None:\n",
    "            pass\n",
    "            # self.set_new_noise_schedule(schedule_opt)\n",
    "\n",
    "    def set_loss(self, device):\n",
    "        if self.loss_type == 'l1':\n",
    "            self.loss_func = nn.L1Loss(reduction='sum').to(device)\n",
    "        elif self.loss_type == 'l2':\n",
    "            self.loss_func = nn.MSELoss(reduction='sum').to(device)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, device):\n",
    "        to_torch = partial(torch.tensor, dtype=torch.float32, device=device)\n",
    "\n",
    "        betas = make_beta_schedule(\n",
    "            schedule=schedule_opt['schedule'],\n",
    "            n_timestep=schedule_opt['n_timestep'],\n",
    "            linear_start=schedule_opt['linear_start'],\n",
    "            linear_end=schedule_opt['linear_end'])\n",
    "        betas = betas.detach().cpu().numpy() if isinstance(\n",
    "            betas, torch.Tensor) else betas\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n",
    "        self.sqrt_alphas_cumprod_prev = np.sqrt(\n",
    "            np.append(1., alphas_cumprod))\n",
    "\n",
    "        timesteps, = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.register_buffer('betas', to_torch(betas))\n",
    "        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n",
    "        self.register_buffer('alphas_cumprod_prev',\n",
    "                             to_torch(alphas_cumprod_prev))\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        self.register_buffer('sqrt_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. - alphas_cumprod)))\n",
    "        self.register_buffer('log_one_minus_alphas_cumprod',\n",
    "                             to_torch(np.log(1. - alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recip_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod)))\n",
    "        self.register_buffer('sqrt_recipm1_alphas_cumprod',\n",
    "                             to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = betas * \\\n",
    "            (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "        self.register_buffer('posterior_variance',\n",
    "                             to_torch(posterior_variance))\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "        self.register_buffer('posterior_log_variance_clipped', to_torch(\n",
    "            np.log(np.maximum(posterior_variance, 1e-20))))\n",
    "        self.register_buffer('posterior_mean_coef1', to_torch(\n",
    "            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n",
    "        self.register_buffer('posterior_mean_coef2', to_torch(\n",
    "            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return self.sqrt_recip_alphas_cumprod[t] * x_t - \\\n",
    "            self.sqrt_recipm1_alphas_cumprod[t] * noise\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = self.posterior_mean_coef1[t] * \\\n",
    "            x_start + self.posterior_mean_coef2[t] * x_t\n",
    "        posterior_log_variance_clipped = self.posterior_log_variance_clipped[t]\n",
    "        return posterior_mean, posterior_log_variance_clipped\n",
    "\n",
    "    def p_mean_variance(self, x, t, clip_denoised: bool, condition_x=None):\n",
    "        batch_size = x.shape[0]\n",
    "        noise_level = torch.FloatTensor(\n",
    "            [self.sqrt_alphas_cumprod_prev[t+1]]).repeat(batch_size, 1).to(x.device)\n",
    "        if condition_x is not None:\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(torch.cat([condition_x, x], dim=1), noise_level))\n",
    "        else:\n",
    "            x_recon = self.predict_start_from_noise(\n",
    "                x, t=t, noise=self.denoise_fn(x, noise_level))\n",
    "\n",
    "        if clip_denoised:\n",
    "            x_recon.clamp_(-1., 1.)\n",
    "\n",
    "        model_mean, posterior_log_variance = self.q_posterior(\n",
    "            x_start=x_recon, x_t=x, t=t)\n",
    "        return model_mean, posterior_log_variance\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, clip_denoised=True, condition_x=None):\n",
    "        model_mean, model_log_variance = self.p_mean_variance(\n",
    "            x=x, t=t, clip_denoised=clip_denoised, condition_x=condition_x)\n",
    "        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "        return model_mean + noise * (0.5 * model_log_variance).exp()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, x_in, continous=False):\n",
    "        device = self.betas.device\n",
    "        sample_inter = (1 | (self.num_timesteps//10))\n",
    "        if not self.conditional:\n",
    "            shape = x_in\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = img\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        else:\n",
    "            x = x_in\n",
    "            shape = x.shape\n",
    "            img = torch.randn(shape, device=device)\n",
    "            ret_img = x\n",
    "            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n",
    "                img = self.p_sample(img, i, condition_x=x)\n",
    "                if i % sample_inter == 0:\n",
    "                    ret_img = torch.cat([ret_img, img], dim=0)\n",
    "        if continous:\n",
    "            return ret_img\n",
    "        else:\n",
    "            return ret_img[-1]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        image_size = self.image_size\n",
    "        channels = self.channels\n",
    "        return self.p_sample_loop((batch_size, channels, image_size, image_size), continous)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def super_resolution(self, x_in, continous=False):\n",
    "        return self.p_sample_loop(x_in, continous)\n",
    "\n",
    "    def q_sample(self, x_start, continuous_sqrt_alpha_cumprod, noise=None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        # random gama\n",
    "        return (\n",
    "            continuous_sqrt_alpha_cumprod * x_start +\n",
    "            (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_in, noise=None):\n",
    "        x_start = x_in['GT']\n",
    "        [b, c, h, w] = x_start.shape\n",
    "        t = np.random.randint(1, self.num_timesteps + 1)\n",
    "        continuous_sqrt_alpha_cumprod = torch.FloatTensor(\n",
    "            np.random.uniform(\n",
    "                self.sqrt_alphas_cumprod_prev[t-1],\n",
    "                self.sqrt_alphas_cumprod_prev[t],\n",
    "                size=b\n",
    "            )\n",
    "        ).to(x_start.device)\n",
    "        continuous_sqrt_alpha_cumprod = continuous_sqrt_alpha_cumprod.view(\n",
    "            b, -1)\n",
    "\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        x_noisy = self.q_sample(\n",
    "            x_start=x_start, continuous_sqrt_alpha_cumprod=continuous_sqrt_alpha_cumprod.view(-1, 1, 1, 1), noise=noise)\n",
    "\n",
    "        if not self.conditional:\n",
    "            x_recon = self.denoise_fn(x_noisy, continuous_sqrt_alpha_cumprod)\n",
    "        else:\n",
    "            x_recon = self.denoise_fn(\n",
    "                torch.cat([x_in['Noisy'], x_noisy], dim=1), continuous_sqrt_alpha_cumprod)\n",
    "                # Everything has to be 4D! Otherwise concatenation on this axis is not possible!!!\n",
    "                # The concatenated representation is automatically 4D anyways at the end!!!\n",
    "        loss = self.loss_func(noise, x_recon)\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.p_losses(x, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a687c",
   "metadata": {
    "papermill": {
     "duration": 0.005417,
     "end_time": "2025-05-13T23:11:20.113540",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.108123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2e85a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:11:20.125475Z",
     "iopub.status.busy": "2025-05-13T23:11:20.125258Z",
     "iopub.status.idle": "2025-05-13T23:11:20.136539Z",
     "shell.execute_reply": "2025-05-13T23:11:20.136052Z"
    },
    "papermill": {
     "duration": 0.018575,
     "end_time": "2025-05-13T23:11:20.137557",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.118982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m, std=0.02):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, std)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, std)  # BN also uses norm\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_kaiming(m, scale=1):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "        m.weight.data *= scale\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def weights_init_orthogonal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.orthogonal_(m.weight.data, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.constant_(m.weight.data, 1.0)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def init_weights(net, init_type='kaiming', scale=1, std=0.02):\n",
    "    # scale for 'kaiming', std for 'normal'.\n",
    "    logger.info('Initialization method [{:s}]'.format(init_type))\n",
    "    if init_type == 'normal':\n",
    "        weights_init_normal_ = functools.partial(weights_init_normal, std=std)\n",
    "        net.apply(weights_init_normal_)\n",
    "    elif init_type == 'kaiming':\n",
    "        weights_init_kaiming_ = functools.partial(\n",
    "            weights_init_kaiming, scale=scale)\n",
    "        net.apply(weights_init_kaiming_)\n",
    "    elif init_type == 'orthogonal':\n",
    "        net.apply(weights_init_orthogonal)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'initialization method [{:s}] not implemented'.format(init_type))\n",
    "\n",
    "\n",
    "####################\n",
    "# define network\n",
    "####################\n",
    "\n",
    "\n",
    "# Generator\n",
    "def define_G(opt):\n",
    "    model_opt = opt['model']\n",
    "    if ('norm_groups' not in model_opt['unet']) or model_opt['unet']['norm_groups'] is None:\n",
    "        model_opt['unet']['norm_groups']=32\n",
    "    model = UNet(\n",
    "        in_channel=model_opt['unet']['in_channel'],\n",
    "        out_channel=model_opt['unet']['out_channel'],\n",
    "        norm_groups=model_opt['unet']['norm_groups'],\n",
    "        inner_channel=model_opt['unet']['inner_channel'],\n",
    "        channel_mults=model_opt['unet']['channel_multiplier'],\n",
    "        attn_res=model_opt['unet']['attn_res'],\n",
    "        res_blocks=model_opt['unet']['res_blocks'],\n",
    "        dropout=model_opt['unet']['dropout'],\n",
    "        image_size=model_opt['diffusion']['image_size']\n",
    "    )\n",
    "    netG = GaussianDiffusion(\n",
    "        model,\n",
    "        image_size=model_opt['diffusion']['image_size'],\n",
    "        channels=model_opt['diffusion']['channels'],\n",
    "        loss_type='l1',    # L1 or L2\n",
    "        conditional=model_opt['diffusion']['conditional'],\n",
    "        schedule_opt=model_opt['beta_schedule']['train']\n",
    "    )\n",
    "    if opt['phase'] == 'train':\n",
    "        # init_weights(netG, init_type='kaiming', scale=0.1)\n",
    "        init_weights(netG, init_type='orthogonal')\n",
    "    if opt['gpu_ids']:\n",
    "        assert torch.cuda.is_available()\n",
    "    # if opt['gpu_ids'] and opt['distributed']:\n",
    "    #     assert torch.cuda.is_available()\n",
    "    #     netG = nn.DataParallel(netG)\n",
    "    return netG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa5b6db",
   "metadata": {
    "papermill": {
     "duration": 0.005374,
     "end_time": "2025-05-13T23:11:20.148630",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.143256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "479ea028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:11:20.160815Z",
     "iopub.status.busy": "2025-05-13T23:11:20.160593Z",
     "iopub.status.idle": "2025-05-13T23:11:20.179095Z",
     "shell.execute_reply": "2025-05-13T23:11:20.178403Z"
    },
    "papermill": {
     "duration": 0.026099,
     "end_time": "2025-05-13T23:11:20.180176",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.154077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SR3():\n",
    "    def __init__(self, opt):       \n",
    "        self.opt = opt\n",
    "        self.device = torch.device(\n",
    "            'cuda' if opt['gpu_ids'] is not None else 'cpu')\n",
    "        self.begin_step = 0\n",
    "        self.begin_epoch = 0\n",
    "        # define network and load pretrained models\n",
    "        self.netG = self.set_device(define_G(opt))\n",
    "        self.schedule_phase = None\n",
    "\n",
    "        # set loss and load resume state\n",
    "        self.set_loss()\n",
    "        self.set_new_noise_schedule(\n",
    "            opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "        if self.opt['phase'] == 'train':\n",
    "            self.netG.train()\n",
    "            # find the parameters to optimize\n",
    "            if opt['model']['finetune_norm']:\n",
    "                optim_params = []\n",
    "                for k, v in self.netG.named_parameters():\n",
    "                    v.requires_grad = False\n",
    "                    if k.find('transformer') >= 0:\n",
    "                        v.requires_grad = True\n",
    "                        v.data.zero_()\n",
    "                        optim_params.append(v)\n",
    "                        logger.info(\n",
    "                            'Params [{:s}] initialized to 0 and will optimize.'.format(k))\n",
    "            else:\n",
    "                optim_params = list(self.netG.parameters())\n",
    "\n",
    "            self.optG = torch.optim.Adam(\n",
    "                optim_params, lr=opt['train'][\"optimizer\"][\"lr\"])\n",
    "            self.log_dict = OrderedDict()\n",
    "        self.load_network()\n",
    "        self.print_network()\n",
    "\n",
    "    def set_device(self, x):\n",
    "        if isinstance(x, dict):\n",
    "            for key, item in x.items():\n",
    "                if item is not None and type(item)==torch.Tensor:\n",
    "                    x[key] = item.to(self.device)\n",
    "        elif isinstance(x, list):\n",
    "            for item in x:\n",
    "                if item is not None:\n",
    "                    item = item.to(self.device)\n",
    "        else:\n",
    "            x = x.to(self.device)\n",
    "        return x\n",
    "\n",
    "    def get_network_description(self, network):\n",
    "        '''Get the string and total parameters of the network'''\n",
    "        if isinstance(network, nn.DataParallel):\n",
    "            network = network.module\n",
    "        s = str(network)\n",
    "        n = sum(map(lambda x: x.numel(), network.parameters()))\n",
    "        return s, n\n",
    "\n",
    "    def feed_data(self, data):\n",
    "        self.data = self.set_device(data)\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        self.optG.zero_grad()\n",
    "        l_pix = self.netG(self.data)\n",
    "        b, c, h, w = self.data['GT'].shape\n",
    "        l_pix = l_pix.sum()/int(b*c*h*w)\n",
    "        l_pix.backward()\n",
    "        self.optG.step()\n",
    "\n",
    "        # set log\n",
    "        self.log_dict['l_pix'] = l_pix.item()\n",
    "\n",
    "        return l_pix.item()\n",
    "\n",
    "    def test(self, continous=False):\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.SR = self.netG.module.super_resolution(\n",
    "                    self.data['SR'], continous)\n",
    "            else:\n",
    "                self.SR = self.netG.super_resolution(\n",
    "                    self.data['SR'], continous)\n",
    "        self.netG.train()\n",
    "\n",
    "    def sample(self, batch_size=1, continous=False):\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.SR = self.netG.module.sample(batch_size, continous)\n",
    "            else:\n",
    "                self.SR = self.netG.sample(batch_size, continous)\n",
    "        self.netG.train()\n",
    "\n",
    "    def set_loss(self):\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            self.netG.module.set_loss(self.device)\n",
    "        else:\n",
    "            self.netG.set_loss(self.device)\n",
    "\n",
    "    def set_new_noise_schedule(self, schedule_opt, schedule_phase='train'):\n",
    "        if self.schedule_phase is None or self.schedule_phase != schedule_phase:\n",
    "            self.schedule_phase = schedule_phase\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                self.netG.module.set_new_noise_schedule(\n",
    "                    schedule_opt, self.device)\n",
    "            else:\n",
    "                self.netG.set_new_noise_schedule(schedule_opt, self.device)\n",
    "\n",
    "    def get_current_log(self):\n",
    "        return self.log_dict\n",
    "\n",
    "    def get_current_visuals(self, need_LR=True, sample=False):\n",
    "        out_dict = OrderedDict()\n",
    "        if sample:\n",
    "            out_dict['SAM'] = self.SR.detach().float().cpu()\n",
    "        else:\n",
    "            out_dict['SR'] = self.SR.detach().float().cpu()\n",
    "            out_dict['INF'] = self.data['SR'].detach().float().cpu()\n",
    "            out_dict['HR'] = self.data['HR'].detach().float().cpu()\n",
    "            if need_LR and 'LR' in self.data:\n",
    "                out_dict['LR'] = self.data['LR'].detach().float().cpu()\n",
    "            else:\n",
    "                out_dict['LR'] = out_dict['INF']\n",
    "        return out_dict\n",
    "\n",
    "    def print_network(self):\n",
    "        s, n = self.get_network_description(self.netG)\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            net_struc_str = '{} - {}'.format(self.netG.__class__.__name__,\n",
    "                                             self.netG.module.__class__.__name__)\n",
    "        else:\n",
    "            net_struc_str = '{}'.format(self.netG.__class__.__name__)\n",
    "\n",
    "        logger.info(\n",
    "            'Network G structure: {}, with parameters: {:,d}'.format(net_struc_str, n))\n",
    "        logger.info(s)\n",
    "\n",
    "    def save_network(self, epoch, iter_step, is_final=False):\n",
    "        if is_final:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'Final_I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        else:\n",
    "            gen_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_gen.pth'.format(iter_step, epoch))\n",
    "            opt_path = os.path.join(\n",
    "                self.opt['path']['checkpoint'], 'I{}_E{}_opt.pth'.format(iter_step, epoch))\n",
    "        # gen\n",
    "        network = self.netG\n",
    "        if isinstance(self.netG, nn.DataParallel):\n",
    "            network = network.module\n",
    "        state_dict = network.state_dict()\n",
    "        for key, param in state_dict.items():\n",
    "            state_dict[key] = param.cpu()\n",
    "        torch.save(state_dict, gen_path)\n",
    "        # opt\n",
    "        opt_state = {'epoch': epoch, 'iter': iter_step,\n",
    "                     'scheduler': None, 'optimizer': None}\n",
    "        opt_state['optimizer'] = self.optG.state_dict()\n",
    "        torch.save(opt_state, opt_path)\n",
    "\n",
    "        logger.info(\n",
    "            'Saved model in [{:s}] ...'.format(gen_path))\n",
    "\n",
    "    def load_network(self):\n",
    "        load_path = self.opt['path']['resume_state']\n",
    "        if load_path is not None:\n",
    "            logger.info(\n",
    "                'Loading pretrained model for G [{:s}] ...'.format(load_path))\n",
    "            gen_path = '{}_gen.pth'.format(load_path)\n",
    "            opt_path = '{}_opt.pth'.format(load_path)\n",
    "            # gen\n",
    "            network = self.netG\n",
    "            if isinstance(self.netG, nn.DataParallel):\n",
    "                network = network.module\n",
    "            network.load_state_dict(torch.load(\n",
    "                gen_path), strict=(not self.opt['model']['finetune_norm']))\n",
    "            # network.load_state_dict(torch.load(\n",
    "            #     gen_path), strict=False)\n",
    "            if self.opt['phase'] == 'train':\n",
    "                # optimizer\n",
    "                opt = torch.load(opt_path)\n",
    "                self.optG.load_state_dict(opt['optimizer'])\n",
    "                self.begin_step = opt['iter']\n",
    "                self.begin_epoch = opt['epoch']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505fa0e",
   "metadata": {
    "papermill": {
     "duration": 0.005376,
     "end_time": "2025-05-13T23:11:20.191050",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.185674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef6477c7",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T23:11:20.203137Z",
     "iopub.status.busy": "2025-05-13T23:11:20.202913Z",
     "iopub.status.idle": "2025-05-13T23:11:28.030830Z",
     "shell.execute_reply": "2025-05-13T23:11:28.029981Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 7.835898,
     "end_time": "2025-05-13T23:11:28.032490",
     "exception": false,
     "start_time": "2025-05-13T23:11:20.196592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-13 23:11:20.538 - INFO: Initialization method [orthogonal]\n",
      "25-05-13 23:11:28.026 - INFO: Network G structure: GaussianDiffusion, with parameters: 38,901,057\n",
      "25-05-13 23:11:28.027 - INFO: GaussianDiffusion(\n",
      "  (denoise_fn): UNet(\n",
      "    (noise_level_mlp): Sequential(\n",
      "      (0): PositionalEncoding()\n",
      "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
      "      (2): Swish()\n",
      "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "    )\n",
      "    (downs): ModuleList(\n",
      "      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): Downsample(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): Downsample(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (5): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (6): Downsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mid): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "        (attn): SelfAttention(\n",
      "          (norm): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "          (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ups): ModuleList(\n",
      "      (0): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (1): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (2): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (3): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (4): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (5): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (6): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (7): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (8): Upsample(\n",
      "        (up): Upsample(scale_factor=2.0, mode='nearest')\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (9): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (10): ResnetBlocWithAttn(\n",
      "        (res_block): ResnetBlock(\n",
      "          (noise_func): FeatureWiseAffine(\n",
      "            (noise_func): Sequential(\n",
      "              (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (block1): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (block2): Block(\n",
      "            (block): Sequential(\n",
      "              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "              (1): Swish()\n",
      "              (2): Identity()\n",
      "              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_conv): Block(\n",
      "      (block): Sequential(\n",
      "        (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n",
      "        (1): Swish()\n",
      "        (2): Identity()\n",
      "        (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loss_func): L1Loss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "diffusion = SR3(opt)\n",
    "# logger.info('Initial Model Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "016ff79f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T23:11:28.046151Z",
     "iopub.status.busy": "2025-05-13T23:11:28.045869Z",
     "iopub.status.idle": "2025-05-14T04:18:20.043860Z",
     "shell.execute_reply": "2025-05-14T04:18:20.043160Z"
    },
    "papermill": {
     "duration": 18412.005893,
     "end_time": "2025-05-14T04:18:20.045166",
     "exception": false,
     "start_time": "2025-05-13T23:11:28.039273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-13 23:13:38.948 - INFO: <epoch:  1, iter:     100> l_pix: 8.0211e-01 \n",
      "25-05-13 23:14:46.666 - INFO: <epoch:  1, iter:     200> l_pix: 7.9495e-01 \n",
      "25-05-13 23:15:54.450 - INFO: <epoch:  1, iter:     300> l_pix: 7.9612e-01 \n",
      "25-05-13 23:17:02.247 - INFO: <epoch:  1, iter:     400> l_pix: 8.5602e-01 \n",
      "25-05-13 23:18:10.050 - INFO: <epoch:  1, iter:     500> l_pix: 7.9817e-01 \n",
      "25-05-13 23:19:17.849 - INFO: <epoch:  1, iter:     600> l_pix: 7.9614e-01 \n",
      "25-05-13 23:20:25.663 - INFO: <epoch:  1, iter:     700> l_pix: 7.9489e-01 \n",
      "25-05-13 23:21:33.461 - INFO: <epoch:  1, iter:     800> l_pix: 7.9899e-01 \n",
      "25-05-13 23:22:41.260 - INFO: <epoch:  1, iter:     900> l_pix: 7.9467e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.7982833719915814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-13 23:23:49.464 - INFO: <epoch:  2, iter:   1,000> l_pix: 7.8719e-01 \n",
      "25-05-13 23:24:57.261 - INFO: <epoch:  2, iter:   1,100> l_pix: 7.9886e-01 \n",
      "25-05-13 23:26:05.070 - INFO: <epoch:  2, iter:   1,200> l_pix: 7.8781e-01 \n",
      "25-05-13 23:27:12.876 - INFO: <epoch:  2, iter:   1,300> l_pix: 7.6854e-01 \n",
      "25-05-13 23:28:20.681 - INFO: <epoch:  2, iter:   1,400> l_pix: 3.1365e-01 \n",
      "25-05-13 23:29:28.482 - INFO: <epoch:  2, iter:   1,500> l_pix: 2.5095e-01 \n",
      "25-05-13 23:30:36.292 - INFO: <epoch:  2, iter:   1,600> l_pix: 1.3736e-01 \n",
      "25-05-13 23:31:44.108 - INFO: <epoch:  2, iter:   1,700> l_pix: 4.6047e-01 \n",
      "25-05-13 23:32:51.921 - INFO: <epoch:  2, iter:   1,800> l_pix: 3.2651e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.5988393451521794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-13 23:34:00.140 - INFO: <epoch:  3, iter:   1,900> l_pix: 5.5560e-01 \n",
      "25-05-13 23:35:07.957 - INFO: <epoch:  3, iter:   2,000> l_pix: 8.0000e-02 \n",
      "25-05-13 23:36:15.779 - INFO: <epoch:  3, iter:   2,100> l_pix: 7.5129e-01 \n",
      "25-05-13 23:37:23.592 - INFO: <epoch:  3, iter:   2,200> l_pix: 6.6696e-02 \n",
      "25-05-13 23:38:31.410 - INFO: <epoch:  3, iter:   2,300> l_pix: 7.0071e-02 \n",
      "25-05-13 23:39:39.228 - INFO: <epoch:  3, iter:   2,400> l_pix: 3.9270e-02 \n",
      "25-05-13 23:40:47.052 - INFO: <epoch:  3, iter:   2,500> l_pix: 2.8262e-01 \n",
      "25-05-13 23:41:54.874 - INFO: <epoch:  3, iter:   2,600> l_pix: 5.6219e-01 \n",
      "25-05-13 23:43:02.689 - INFO: <epoch:  3, iter:   2,700> l_pix: 5.1668e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.2169023118664821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-13 23:44:10.918 - INFO: <epoch:  4, iter:   2,800> l_pix: 3.9973e-02 \n",
      "25-05-13 23:45:18.735 - INFO: <epoch:  4, iter:   2,900> l_pix: 7.2984e-02 \n",
      "25-05-13 23:46:26.556 - INFO: <epoch:  4, iter:   3,000> l_pix: 2.7385e-01 \n",
      "25-05-13 23:47:34.384 - INFO: <epoch:  4, iter:   3,100> l_pix: 6.1881e-01 \n",
      "25-05-13 23:48:42.203 - INFO: <epoch:  4, iter:   3,200> l_pix: 2.5577e-01 \n",
      "25-05-13 23:49:50.142 - INFO: <epoch:  4, iter:   3,300> l_pix: 2.6672e-01 \n",
      "25-05-13 23:50:58.047 - INFO: <epoch:  4, iter:   3,400> l_pix: 3.8313e-02 \n",
      "25-05-13 23:52:05.954 - INFO: <epoch:  4, iter:   3,500> l_pix: 3.1027e-02 \n",
      "25-05-13 23:53:13.857 - INFO: <epoch:  4, iter:   3,600> l_pix: 1.1969e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.19112497931139336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-13 23:54:22.169 - INFO: <epoch:  5, iter:   3,700> l_pix: 3.4947e-02 \n",
      "25-05-13 23:55:30.083 - INFO: <epoch:  5, iter:   3,800> l_pix: 4.5225e-02 \n",
      "25-05-13 23:56:38.024 - INFO: <epoch:  5, iter:   3,900> l_pix: 4.5575e-02 \n",
      "25-05-13 23:57:45.940 - INFO: <epoch:  5, iter:   4,000> l_pix: 2.9054e-02 \n",
      "25-05-13 23:58:53.854 - INFO: <epoch:  5, iter:   4,100> l_pix: 1.3001e-01 \n",
      "25-05-14 00:00:01.765 - INFO: <epoch:  5, iter:   4,200> l_pix: 5.0668e-02 \n",
      "25-05-14 00:01:09.688 - INFO: <epoch:  5, iter:   4,300> l_pix: 2.8512e-02 \n",
      "25-05-14 00:02:17.620 - INFO: <epoch:  5, iter:   4,400> l_pix: 3.1890e-02 \n",
      "25-05-14 00:03:25.531 - INFO: <epoch:  5, iter:   4,500> l_pix: 7.0621e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1844693789155119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 00:04:33.850 - INFO: <epoch:  6, iter:   4,600> l_pix: 2.6117e-02 \n",
      "25-05-14 00:05:41.758 - INFO: <epoch:  6, iter:   4,700> l_pix: 2.7079e-02 \n",
      "25-05-14 00:06:49.685 - INFO: <epoch:  6, iter:   4,800> l_pix: 3.5078e-02 \n",
      "25-05-14 00:07:57.628 - INFO: <epoch:  6, iter:   4,900> l_pix: 7.1512e-02 \n",
      "25-05-14 00:09:05.553 - INFO: <epoch:  6, iter:   5,000> l_pix: 2.7013e-02 \n",
      "25-05-14 00:10:13.468 - INFO: <epoch:  6, iter:   5,100> l_pix: 1.2826e-01 \n",
      "25-05-14 00:11:21.392 - INFO: <epoch:  6, iter:   5,200> l_pix: 4.5353e-01 \n",
      "25-05-14 00:12:29.320 - INFO: <epoch:  6, iter:   5,300> l_pix: 3.3684e-02 \n",
      "25-05-14 00:13:37.229 - INFO: <epoch:  6, iter:   5,400> l_pix: 2.6505e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1716436283538739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 00:14:45.531 - INFO: <epoch:  7, iter:   5,500> l_pix: 3.3000e-01 \n",
      "25-05-14 00:15:53.452 - INFO: <epoch:  7, iter:   5,600> l_pix: 6.2067e-01 \n",
      "25-05-14 00:17:01.377 - INFO: <epoch:  7, iter:   5,700> l_pix: 2.4718e-01 \n",
      "25-05-14 00:18:09.273 - INFO: <epoch:  7, iter:   5,800> l_pix: 3.9189e-02 \n",
      "25-05-14 00:19:17.175 - INFO: <epoch:  7, iter:   5,900> l_pix: 5.2759e-01 \n",
      "25-05-14 00:20:25.084 - INFO: <epoch:  7, iter:   6,000> l_pix: 2.5995e-01 \n",
      "25-05-14 00:21:32.987 - INFO: <epoch:  7, iter:   6,100> l_pix: 3.2939e-01 \n",
      "25-05-14 00:22:40.911 - INFO: <epoch:  7, iter:   6,200> l_pix: 3.5487e-02 \n",
      "25-05-14 00:23:48.821 - INFO: <epoch:  7, iter:   6,300> l_pix: 2.6652e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.17440420816962918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 00:24:57.122 - INFO: <epoch:  8, iter:   6,400> l_pix: 2.9215e-02 \n",
      "25-05-14 00:26:05.045 - INFO: <epoch:  8, iter:   6,500> l_pix: 7.0230e-02 \n",
      "25-05-14 00:27:12.944 - INFO: <epoch:  8, iter:   6,600> l_pix: 1.5684e-01 \n",
      "25-05-14 00:28:20.838 - INFO: <epoch:  8, iter:   6,700> l_pix: 7.2229e-02 \n",
      "25-05-14 00:29:28.735 - INFO: <epoch:  8, iter:   6,800> l_pix: 9.2558e-02 \n",
      "25-05-14 00:30:36.630 - INFO: <epoch:  8, iter:   6,900> l_pix: 4.0782e-02 \n",
      "25-05-14 00:31:44.558 - INFO: <epoch:  8, iter:   7,000> l_pix: 2.1918e-02 \n",
      "25-05-14 00:32:52.472 - INFO: <epoch:  8, iter:   7,100> l_pix: 5.6307e-01 \n",
      "25-05-14 00:34:00.382 - INFO: <epoch:  8, iter:   7,200> l_pix: 2.6291e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.17348042599029012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 00:35:08.687 - INFO: <epoch:  9, iter:   7,300> l_pix: 2.3870e-02 \n",
      "25-05-14 00:36:16.601 - INFO: <epoch:  9, iter:   7,400> l_pix: 1.1508e-01 \n",
      "25-05-14 00:37:24.515 - INFO: <epoch:  9, iter:   7,500> l_pix: 4.9046e-01 \n",
      "25-05-14 00:38:32.439 - INFO: <epoch:  9, iter:   7,600> l_pix: 2.9925e-02 \n",
      "25-05-14 00:39:40.350 - INFO: <epoch:  9, iter:   7,700> l_pix: 2.8763e-02 \n",
      "25-05-14 00:40:48.250 - INFO: <epoch:  9, iter:   7,800> l_pix: 2.0511e-01 \n",
      "25-05-14 00:41:56.163 - INFO: <epoch:  9, iter:   7,900> l_pix: 3.3888e-01 \n",
      "25-05-14 00:43:04.083 - INFO: <epoch:  9, iter:   8,000> l_pix: 5.3298e-02 \n",
      "25-05-14 00:44:12.009 - INFO: <epoch:  9, iter:   8,100> l_pix: 5.5901e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1811106906272471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 00:45:20.332 - INFO: <epoch: 10, iter:   8,200> l_pix: 2.3456e-02 \n",
      "25-05-14 00:46:28.267 - INFO: <epoch: 10, iter:   8,300> l_pix: 5.0159e-01 \n",
      "25-05-14 00:47:36.203 - INFO: <epoch: 10, iter:   8,400> l_pix: 1.5139e-01 \n",
      "25-05-14 00:48:44.140 - INFO: <epoch: 10, iter:   8,500> l_pix: 5.6620e-01 \n",
      "25-05-14 00:49:52.058 - INFO: <epoch: 10, iter:   8,600> l_pix: 1.5787e-01 \n",
      "25-05-14 00:50:59.975 - INFO: <epoch: 10, iter:   8,700> l_pix: 1.7797e-01 \n",
      "25-05-14 00:52:07.865 - INFO: <epoch: 10, iter:   8,800> l_pix: 6.3126e-01 \n",
      "25-05-14 00:53:15.779 - INFO: <epoch: 10, iter:   8,900> l_pix: 1.6588e-01 \n",
      "25-05-14 00:54:23.700 - INFO: <epoch: 10, iter:   9,000> l_pix: 2.3792e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.17203536657409535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 00:55:32.011 - INFO: <epoch: 11, iter:   9,100> l_pix: 2.2417e-02 \n",
      "25-05-14 00:56:39.945 - INFO: <epoch: 11, iter:   9,200> l_pix: 2.1102e-02 \n",
      "25-05-14 00:57:47.879 - INFO: <epoch: 11, iter:   9,300> l_pix: 2.3884e-01 \n",
      "25-05-14 00:58:55.791 - INFO: <epoch: 11, iter:   9,400> l_pix: 5.3880e-02 \n",
      "25-05-14 01:00:03.686 - INFO: <epoch: 11, iter:   9,500> l_pix: 5.4202e-02 \n",
      "25-05-14 01:01:11.600 - INFO: <epoch: 11, iter:   9,600> l_pix: 3.0255e-01 \n",
      "25-05-14 01:02:19.520 - INFO: <epoch: 11, iter:   9,700> l_pix: 3.2598e-02 \n",
      "25-05-14 01:03:27.414 - INFO: <epoch: 11, iter:   9,800> l_pix: 1.1140e-01 \n",
      "25-05-14 01:04:35.322 - INFO: <epoch: 11, iter:   9,900> l_pix: 2.4428e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1721128255004684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 01:05:43.639 - INFO: <epoch: 12, iter:  10,000> l_pix: 2.4906e-01 \n",
      "25-05-14 01:06:51.544 - INFO: <epoch: 12, iter:  10,100> l_pix: 2.3641e-02 \n",
      "25-05-14 01:07:59.442 - INFO: <epoch: 12, iter:  10,200> l_pix: 9.0328e-02 \n",
      "25-05-14 01:09:07.339 - INFO: <epoch: 12, iter:  10,300> l_pix: 4.0098e-02 \n",
      "25-05-14 01:10:15.229 - INFO: <epoch: 12, iter:  10,400> l_pix: 2.1365e-02 \n",
      "25-05-14 01:11:23.115 - INFO: <epoch: 12, iter:  10,500> l_pix: 4.0765e-02 \n",
      "25-05-14 01:12:31.026 - INFO: <epoch: 12, iter:  10,600> l_pix: 3.6500e-01 \n",
      "25-05-14 01:13:38.950 - INFO: <epoch: 12, iter:  10,700> l_pix: 2.1160e-02 \n",
      "25-05-14 01:14:46.854 - INFO: <epoch: 12, iter:  10,800> l_pix: 6.3792e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.16677365361609392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 01:15:55.150 - INFO: <epoch: 13, iter:  10,900> l_pix: 2.2476e-02 \n",
      "25-05-14 01:17:03.037 - INFO: <epoch: 13, iter:  11,000> l_pix: 8.9762e-02 \n",
      "25-05-14 01:18:10.926 - INFO: <epoch: 13, iter:  11,100> l_pix: 2.5406e-02 \n",
      "25-05-14 01:19:18.814 - INFO: <epoch: 13, iter:  11,200> l_pix: 2.2848e-02 \n",
      "25-05-14 01:20:26.715 - INFO: <epoch: 13, iter:  11,300> l_pix: 4.6956e-02 \n",
      "25-05-14 01:21:34.628 - INFO: <epoch: 13, iter:  11,400> l_pix: 1.6737e-01 \n",
      "25-05-14 01:22:42.524 - INFO: <epoch: 13, iter:  11,500> l_pix: 3.3920e-02 \n",
      "25-05-14 01:23:50.408 - INFO: <epoch: 13, iter:  11,600> l_pix: 2.2134e-02 \n",
      "25-05-14 01:24:58.301 - INFO: <epoch: 13, iter:  11,700> l_pix: 1.4885e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.15619416032607356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 01:26:06.575 - INFO: <epoch: 14, iter:  11,800> l_pix: 1.1708e-01 \n",
      "25-05-14 01:27:14.463 - INFO: <epoch: 14, iter:  11,900> l_pix: 7.9946e-01 \n",
      "25-05-14 01:28:22.294 - INFO: <epoch: 14, iter:  12,000> l_pix: 7.9790e-01 \n",
      "25-05-14 01:29:30.130 - INFO: <epoch: 14, iter:  12,100> l_pix: 7.9596e-01 \n",
      "25-05-14 01:30:37.987 - INFO: <epoch: 14, iter:  12,200> l_pix: 7.9609e-01 \n",
      "25-05-14 01:31:45.854 - INFO: <epoch: 14, iter:  12,300> l_pix: 7.9245e-01 \n",
      "25-05-14 01:32:53.721 - INFO: <epoch: 14, iter:  12,400> l_pix: 7.9356e-01 \n",
      "25-05-14 01:34:01.594 - INFO: <epoch: 14, iter:  12,500> l_pix: 7.8855e-01 \n",
      "25-05-14 01:35:09.486 - INFO: <epoch: 14, iter:  12,600> l_pix: 7.8527e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.69170666537765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 01:36:17.744 - INFO: <epoch: 15, iter:  12,700> l_pix: 7.9744e-01 \n",
      "25-05-14 01:37:25.599 - INFO: <epoch: 15, iter:  12,800> l_pix: 7.9602e-01 \n",
      "25-05-14 01:38:33.460 - INFO: <epoch: 15, iter:  12,900> l_pix: 7.9222e-01 \n",
      "25-05-14 01:39:41.285 - INFO: <epoch: 15, iter:  13,000> l_pix: 7.9863e-01 \n",
      "25-05-14 01:40:49.125 - INFO: <epoch: 15, iter:  13,100> l_pix: 7.9565e-01 \n",
      "25-05-14 01:41:56.957 - INFO: <epoch: 15, iter:  13,200> l_pix: 7.9242e-01 \n",
      "25-05-14 01:43:04.825 - INFO: <epoch: 15, iter:  13,300> l_pix: 6.7927e-01 \n",
      "25-05-14 01:44:12.698 - INFO: <epoch: 15, iter:  13,400> l_pix: 4.2282e-01 \n",
      "25-05-14 01:45:20.597 - INFO: <epoch: 15, iter:  13,500> l_pix: 1.1215e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.6969865947465101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 01:46:28.912 - INFO: <epoch: 16, iter:  13,600> l_pix: 5.9484e-01 \n",
      "25-05-14 01:47:36.839 - INFO: <epoch: 16, iter:  13,700> l_pix: 8.7514e-02 \n",
      "25-05-14 01:48:44.755 - INFO: <epoch: 16, iter:  13,800> l_pix: 3.7166e-02 \n",
      "25-05-14 01:49:52.669 - INFO: <epoch: 16, iter:  13,900> l_pix: 2.1623e-01 \n",
      "25-05-14 01:51:00.573 - INFO: <epoch: 16, iter:  14,000> l_pix: 6.1819e-02 \n",
      "25-05-14 01:52:08.475 - INFO: <epoch: 16, iter:  14,100> l_pix: 7.3200e-02 \n",
      "25-05-14 01:53:16.391 - INFO: <epoch: 16, iter:  14,200> l_pix: 1.0530e-01 \n",
      "25-05-14 01:54:24.296 - INFO: <epoch: 16, iter:  14,300> l_pix: 3.3691e-01 \n",
      "25-05-14 01:55:32.196 - INFO: <epoch: 16, iter:  14,400> l_pix: 2.9869e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1781598259218865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 01:56:40.547 - INFO: <epoch: 17, iter:  14,500> l_pix: 3.4311e-02 \n",
      "25-05-14 01:57:48.455 - INFO: <epoch: 17, iter:  14,600> l_pix: 3.5846e-02 \n",
      "25-05-14 01:58:56.355 - INFO: <epoch: 17, iter:  14,700> l_pix: 2.7190e-02 \n",
      "25-05-14 02:00:04.260 - INFO: <epoch: 17, iter:  14,800> l_pix: 3.2981e-02 \n",
      "25-05-14 02:01:12.182 - INFO: <epoch: 17, iter:  14,900> l_pix: 4.5178e-02 \n",
      "25-05-14 02:02:20.095 - INFO: <epoch: 17, iter:  15,000> l_pix: 2.6025e-02 \n",
      "25-05-14 02:03:28.001 - INFO: <epoch: 17, iter:  15,100> l_pix: 2.1555e-01 \n",
      "25-05-14 02:04:35.916 - INFO: <epoch: 17, iter:  15,200> l_pix: 5.0046e-01 \n",
      "25-05-14 02:05:43.804 - INFO: <epoch: 17, iter:  15,300> l_pix: 1.9193e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1695661555085745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 02:06:52.094 - INFO: <epoch: 18, iter:  15,400> l_pix: 2.8547e-02 \n",
      "25-05-14 02:08:00.010 - INFO: <epoch: 18, iter:  15,500> l_pix: 1.5331e-01 \n",
      "25-05-14 02:09:07.905 - INFO: <epoch: 18, iter:  15,600> l_pix: 6.4595e-02 \n",
      "25-05-14 02:10:15.831 - INFO: <epoch: 18, iter:  15,700> l_pix: 2.1412e-01 \n",
      "25-05-14 02:11:23.732 - INFO: <epoch: 18, iter:  15,800> l_pix: 5.7278e-02 \n",
      "25-05-14 02:12:31.656 - INFO: <epoch: 18, iter:  15,900> l_pix: 7.7330e-02 \n",
      "25-05-14 02:13:39.594 - INFO: <epoch: 18, iter:  16,000> l_pix: 2.8182e-01 \n",
      "25-05-14 02:14:47.526 - INFO: <epoch: 18, iter:  16,100> l_pix: 2.2164e-02 \n",
      "25-05-14 02:15:55.455 - INFO: <epoch: 18, iter:  16,200> l_pix: 2.8456e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.17994080485569106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 02:17:03.776 - INFO: <epoch: 19, iter:  16,300> l_pix: 1.3886e-01 \n",
      "25-05-14 02:18:11.685 - INFO: <epoch: 19, iter:  16,400> l_pix: 3.3215e-02 \n",
      "25-05-14 02:19:19.596 - INFO: <epoch: 19, iter:  16,500> l_pix: 2.2852e-01 \n",
      "25-05-14 02:20:27.501 - INFO: <epoch: 19, iter:  16,600> l_pix: 3.4002e-01 \n",
      "25-05-14 02:21:35.408 - INFO: <epoch: 19, iter:  16,700> l_pix: 4.1237e-01 \n",
      "25-05-14 02:22:43.314 - INFO: <epoch: 19, iter:  16,800> l_pix: 2.4414e-02 \n",
      "25-05-14 02:23:51.208 - INFO: <epoch: 19, iter:  16,900> l_pix: 8.4134e-02 \n",
      "25-05-14 02:24:59.135 - INFO: <epoch: 19, iter:  17,000> l_pix: 1.7759e-01 \n",
      "25-05-14 02:26:07.048 - INFO: <epoch: 19, iter:  17,100> l_pix: 8.0149e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.16109086014330387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 02:27:15.361 - INFO: <epoch: 20, iter:  17,200> l_pix: 1.5221e-01 \n",
      "25-05-14 02:28:23.298 - INFO: <epoch: 20, iter:  17,300> l_pix: 3.1855e-01 \n",
      "25-05-14 02:29:31.193 - INFO: <epoch: 20, iter:  17,400> l_pix: 2.8191e-02 \n",
      "25-05-14 02:30:39.101 - INFO: <epoch: 20, iter:  17,500> l_pix: 2.0581e-01 \n",
      "25-05-14 02:31:47.012 - INFO: <epoch: 20, iter:  17,600> l_pix: 1.4356e-01 \n",
      "25-05-14 02:32:54.927 - INFO: <epoch: 20, iter:  17,700> l_pix: 7.0668e-01 \n",
      "25-05-14 02:34:02.835 - INFO: <epoch: 20, iter:  17,800> l_pix: 8.4707e-02 \n",
      "25-05-14 02:35:10.735 - INFO: <epoch: 20, iter:  17,900> l_pix: 1.3688e-01 \n",
      "25-05-14 02:36:18.648 - INFO: <epoch: 20, iter:  18,000> l_pix: 1.7092e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.17580315062983168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 02:37:26.930 - INFO: <epoch: 21, iter:  18,100> l_pix: 2.0200e-02 \n",
      "25-05-14 02:38:34.857 - INFO: <epoch: 21, iter:  18,200> l_pix: 1.2623e-01 \n",
      "25-05-14 02:39:42.766 - INFO: <epoch: 21, iter:  18,300> l_pix: 2.1465e-02 \n",
      "25-05-14 02:40:50.661 - INFO: <epoch: 21, iter:  18,400> l_pix: 6.0645e-02 \n",
      "25-05-14 02:41:58.571 - INFO: <epoch: 21, iter:  18,500> l_pix: 4.6818e-01 \n",
      "25-05-14 02:43:06.466 - INFO: <epoch: 21, iter:  18,600> l_pix: 3.3531e-02 \n",
      "25-05-14 02:44:14.363 - INFO: <epoch: 21, iter:  18,700> l_pix: 8.1144e-01 \n",
      "25-05-14 02:45:22.271 - INFO: <epoch: 21, iter:  18,800> l_pix: 7.9324e-01 \n",
      "25-05-14 02:46:30.183 - INFO: <epoch: 21, iter:  18,900> l_pix: 2.6629e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1676325093768537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 02:47:38.492 - INFO: <epoch: 22, iter:  19,000> l_pix: 1.2769e-01 \n",
      "25-05-14 02:48:46.392 - INFO: <epoch: 22, iter:  19,100> l_pix: 2.1855e-02 \n",
      "25-05-14 02:49:54.281 - INFO: <epoch: 22, iter:  19,200> l_pix: 1.5093e-01 \n",
      "25-05-14 02:51:02.192 - INFO: <epoch: 22, iter:  19,300> l_pix: 8.1004e-02 \n",
      "25-05-14 02:52:10.101 - INFO: <epoch: 22, iter:  19,400> l_pix: 2.2745e-02 \n",
      "25-05-14 02:53:18.011 - INFO: <epoch: 22, iter:  19,500> l_pix: 4.6965e-01 \n",
      "25-05-14 02:54:25.918 - INFO: <epoch: 22, iter:  19,600> l_pix: 3.9257e-02 \n",
      "25-05-14 02:55:33.798 - INFO: <epoch: 22, iter:  19,700> l_pix: 7.9789e-01 \n",
      "25-05-14 02:56:41.646 - INFO: <epoch: 22, iter:  19,800> l_pix: 7.7191e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.26798104462317296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 02:57:49.891 - INFO: <epoch: 23, iter:  19,900> l_pix: 7.9823e-01 \n",
      "25-05-14 02:58:57.719 - INFO: <epoch: 23, iter:  20,000> l_pix: 7.9911e-01 \n",
      "25-05-14 03:00:05.558 - INFO: <epoch: 23, iter:  20,100> l_pix: 7.9722e-01 \n",
      "25-05-14 03:01:13.400 - INFO: <epoch: 23, iter:  20,200> l_pix: 7.9601e-01 \n",
      "25-05-14 03:02:21.253 - INFO: <epoch: 23, iter:  20,300> l_pix: 7.9595e-01 \n",
      "25-05-14 03:03:29.090 - INFO: <epoch: 23, iter:  20,400> l_pix: 7.8873e-01 \n",
      "25-05-14 03:04:36.959 - INFO: <epoch: 23, iter:  20,500> l_pix: 3.7638e-01 \n",
      "25-05-14 03:05:44.842 - INFO: <epoch: 23, iter:  20,600> l_pix: 7.1215e-02 \n",
      "25-05-14 03:06:52.732 - INFO: <epoch: 23, iter:  20,700> l_pix: 2.5527e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.634244826996906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 03:08:01.025 - INFO: <epoch: 24, iter:  20,800> l_pix: 1.3162e-01 \n",
      "25-05-14 03:09:08.929 - INFO: <epoch: 24, iter:  20,900> l_pix: 2.5951e-01 \n",
      "25-05-14 03:10:16.815 - INFO: <epoch: 24, iter:  21,000> l_pix: 2.3955e-01 \n",
      "25-05-14 03:11:24.681 - INFO: <epoch: 24, iter:  21,100> l_pix: 2.4386e-02 \n",
      "25-05-14 03:12:32.579 - INFO: <epoch: 24, iter:  21,200> l_pix: 4.0835e-01 \n",
      "25-05-14 03:13:40.474 - INFO: <epoch: 24, iter:  21,300> l_pix: 7.2294e-02 \n",
      "25-05-14 03:14:48.360 - INFO: <epoch: 24, iter:  21,400> l_pix: 6.9518e-02 \n",
      "25-05-14 03:15:56.264 - INFO: <epoch: 24, iter:  21,500> l_pix: 7.9671e-01 \n",
      "25-05-14 03:17:04.167 - INFO: <epoch: 24, iter:  21,600> l_pix: 2.1659e-02 \n",
      "25-05-14 03:17:04.168 - INFO: Saving models and training states.\n",
      "25-05-14 03:17:04.896 - INFO: Saved model in [/kaggle/working/checkpoint/I21600_E24_gen.pth] ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1631361530824668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 03:18:13.196 - INFO: <epoch: 25, iter:  21,700> l_pix: 1.5029e-01 \n",
      "25-05-14 03:19:21.117 - INFO: <epoch: 25, iter:  21,800> l_pix: 3.2515e-02 \n",
      "25-05-14 03:20:29.031 - INFO: <epoch: 25, iter:  21,900> l_pix: 1.9495e-01 \n",
      "25-05-14 03:21:36.941 - INFO: <epoch: 25, iter:  22,000> l_pix: 4.9445e-01 \n",
      "25-05-14 03:22:44.831 - INFO: <epoch: 25, iter:  22,100> l_pix: 5.2253e-02 \n",
      "25-05-14 03:23:52.726 - INFO: <epoch: 25, iter:  22,200> l_pix: 1.1606e-01 \n",
      "25-05-14 03:25:00.617 - INFO: <epoch: 25, iter:  22,300> l_pix: 2.9721e-02 \n",
      "25-05-14 03:26:08.510 - INFO: <epoch: 25, iter:  22,400> l_pix: 6.2441e-02 \n",
      "25-05-14 03:27:16.414 - INFO: <epoch: 25, iter:  22,500> l_pix: 2.3741e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.16095561570384437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 03:28:24.749 - INFO: <epoch: 26, iter:  22,600> l_pix: 7.4162e-01 \n",
      "25-05-14 03:29:32.657 - INFO: <epoch: 26, iter:  22,700> l_pix: 9.2311e-02 \n",
      "25-05-14 03:30:40.557 - INFO: <epoch: 26, iter:  22,800> l_pix: 2.2896e-02 \n",
      "25-05-14 03:31:48.467 - INFO: <epoch: 26, iter:  22,900> l_pix: 7.7928e-02 \n",
      "25-05-14 03:32:56.364 - INFO: <epoch: 26, iter:  23,000> l_pix: 7.3182e-02 \n",
      "25-05-14 03:34:04.268 - INFO: <epoch: 26, iter:  23,100> l_pix: 3.0789e-02 \n",
      "25-05-14 03:35:12.173 - INFO: <epoch: 26, iter:  23,200> l_pix: 2.3090e-02 \n",
      "25-05-14 03:36:20.079 - INFO: <epoch: 26, iter:  23,300> l_pix: 4.1785e-02 \n",
      "25-05-14 03:37:27.979 - INFO: <epoch: 26, iter:  23,400> l_pix: 1.8049e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.1705773453331656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 03:38:36.293 - INFO: <epoch: 27, iter:  23,500> l_pix: 1.0080e-01 \n",
      "25-05-14 03:39:44.207 - INFO: <epoch: 27, iter:  23,600> l_pix: 1.9373e-02 \n",
      "25-05-14 03:40:52.099 - INFO: <epoch: 27, iter:  23,700> l_pix: 2.1817e-02 \n",
      "25-05-14 03:41:59.999 - INFO: <epoch: 27, iter:  23,800> l_pix: 2.6819e-01 \n",
      "25-05-14 03:43:07.896 - INFO: <epoch: 27, iter:  23,900> l_pix: 5.7046e-02 \n",
      "25-05-14 03:44:15.815 - INFO: <epoch: 27, iter:  24,000> l_pix: 3.4843e-02 \n",
      "25-05-14 03:45:23.712 - INFO: <epoch: 27, iter:  24,100> l_pix: 1.5754e-02 \n",
      "25-05-14 03:46:31.614 - INFO: <epoch: 27, iter:  24,200> l_pix: 2.3597e-02 \n",
      "25-05-14 03:47:39.515 - INFO: <epoch: 27, iter:  24,300> l_pix: 2.6487e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.16537473743988407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 03:48:47.836 - INFO: <epoch: 28, iter:  24,400> l_pix: 5.7116e-01 \n",
      "25-05-14 03:49:55.724 - INFO: <epoch: 28, iter:  24,500> l_pix: 6.3816e-02 \n",
      "25-05-14 03:51:03.639 - INFO: <epoch: 28, iter:  24,600> l_pix: 2.6538e-01 \n",
      "25-05-14 03:52:11.566 - INFO: <epoch: 28, iter:  24,700> l_pix: 1.0411e-01 \n",
      "25-05-14 03:53:19.481 - INFO: <epoch: 28, iter:  24,800> l_pix: 2.6352e-02 \n",
      "25-05-14 03:54:27.392 - INFO: <epoch: 28, iter:  24,900> l_pix: 7.1511e-01 \n",
      "25-05-14 03:55:37.480 - INFO: <epoch: 28, iter:  25,000> l_pix: 4.5296e-01 \n",
      "25-05-14 03:56:45.389 - INFO: <epoch: 28, iter:  25,100> l_pix: 9.0887e-02 \n",
      "25-05-14 03:57:53.311 - INFO: <epoch: 28, iter:  25,200> l_pix: 2.5649e-01 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.15319611865509716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 03:59:01.652 - INFO: <epoch: 29, iter:  25,300> l_pix: 3.3231e-01 \n",
      "25-05-14 04:00:09.573 - INFO: <epoch: 29, iter:  25,400> l_pix: 1.3295e-01 \n",
      "25-05-14 04:01:17.497 - INFO: <epoch: 29, iter:  25,500> l_pix: 1.1060e-01 \n",
      "25-05-14 04:02:25.412 - INFO: <epoch: 29, iter:  25,600> l_pix: 2.0981e-02 \n",
      "25-05-14 04:03:33.343 - INFO: <epoch: 29, iter:  25,700> l_pix: 3.6833e-01 \n",
      "25-05-14 04:04:41.281 - INFO: <epoch: 29, iter:  25,800> l_pix: 1.2647e-01 \n",
      "25-05-14 04:05:49.205 - INFO: <epoch: 29, iter:  25,900> l_pix: 5.2759e-02 \n",
      "25-05-14 04:06:57.128 - INFO: <epoch: 29, iter:  26,000> l_pix: 1.7482e-02 \n",
      "25-05-14 04:08:07.403 - INFO: <epoch: 29, iter:  26,100> l_pix: 9.6945e-02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.16699275204808348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-05-14 04:09:15.771 - INFO: <epoch: 30, iter:  26,200> l_pix: 2.2223e-02 \n",
      "25-05-14 04:10:23.710 - INFO: <epoch: 30, iter:  26,300> l_pix: 3.2302e-02 \n",
      "25-05-14 04:11:31.667 - INFO: <epoch: 30, iter:  26,400> l_pix: 1.9916e-02 \n",
      "25-05-14 04:12:39.593 - INFO: <epoch: 30, iter:  26,500> l_pix: 5.8433e-01 \n",
      "25-05-14 04:13:47.522 - INFO: <epoch: 30, iter:  26,600> l_pix: 1.0320e-01 \n",
      "25-05-14 04:14:55.450 - INFO: <epoch: 30, iter:  26,700> l_pix: 3.3403e-01 \n",
      "25-05-14 04:16:03.374 - INFO: <epoch: 30, iter:  26,800> l_pix: 8.9138e-02 \n",
      "25-05-14 04:17:11.290 - INFO: <epoch: 30, iter:  26,900> l_pix: 3.6910e-02 \n",
      "25-05-14 04:18:19.203 - INFO: <epoch: 30, iter:  27,000> l_pix: 2.5246e-02 \n",
      "25-05-14 04:18:19.204 - INFO: Saving final model\n",
      "25-05-14 04:18:20.001 - INFO: Saved model in [/kaggle/working/checkpoint/Final_I27000_E30_gen.pth] ...\n",
      "25-05-14 04:18:20.039 - INFO: End of training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Loss:  0.16206810346287157\n",
      "Epoch Loss List:  [0.7982833719915814, 0.5988393451521794, 0.2169023118664821, 0.19112497931139336, 0.1844693789155119, 0.1716436283538739, 0.17440420816962918, 0.17348042599029012, 0.1811106906272471, 0.17203536657409535, 0.1721128255004684, 0.16677365361609392, 0.15619416032607356, 0.69170666537765, 0.6969865947465101, 0.1781598259218865, 0.1695661555085745, 0.17994080485569106, 0.16109086014330387, 0.17580315062983168, 0.1676325093768537, 0.26798104462317296, 0.634244826996906, 0.1631361530824668, 0.16095561570384437, 0.1705773453331656, 0.16537473743988407, 0.15319611865509716, 0.16699275204808348, 0.16206810346287157]\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epoch_loss_list = []\n",
    "\n",
    "current_step = diffusion.begin_step\n",
    "current_epoch = diffusion.begin_epoch\n",
    "n_iter = opt['train']['n_iter']\n",
    "\n",
    "if opt['path']['resume_state']:\n",
    "    logger.info('Resuming training from epoch: {}, iter: {}.'.format(\n",
    "        current_epoch, current_step))\n",
    "\n",
    "diffusion.set_new_noise_schedule(\n",
    "    opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])\n",
    "if opt['phase'] == 'train':\n",
    "    while current_step < n_iter:\n",
    "        current_epoch += 1\n",
    "        epoch_loss_values = []\n",
    "        for _, train_data in enumerate(train_loader):\n",
    "            current_step += 1\n",
    "            if current_step > n_iter:\n",
    "                break\n",
    "            diffusion.feed_data(train_data)\n",
    "            current_l_pix = diffusion.optimize_parameters()\n",
    "            epoch_loss_values.append(current_l_pix)\n",
    "            # log\n",
    "            if current_step % opt['train']['print_freq'] == 0:\n",
    "                logs = diffusion.get_current_log()\n",
    "                message = '<epoch:{:3d}, iter:{:8,d}> '.format(\n",
    "                    current_epoch, current_step)\n",
    "                for k, v in logs.items():\n",
    "                    message += '{:s}: {:.4e} '.format(k, v)\n",
    "                    #tb_logger.add_scalar(k, v, current_step)\n",
    "                logger.info(message)\n",
    "                \n",
    "        \n",
    "\n",
    "                # if wandb_logger:\n",
    "                #     wandb_logger.log_metrics(logs)\n",
    "\n",
    "    #         # validation\n",
    "    #         if current_step % opt['train']['val_freq'] == 0:\n",
    "    #             avg_psnr = 0.0\n",
    "    #             idx = 0\n",
    "    #             result_path = '{}/{}'.format(opt['path']\n",
    "    #                                             ['results'], current_epoch)\n",
    "    #             os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "    #             diffusion.set_new_noise_schedule(\n",
    "    #                 opt['model']['beta_schedule']['val'], schedule_phase='val')\n",
    "    #             for _,  val_data in enumerate(val_loader):\n",
    "    #                 idx += 1\n",
    "    #                 diffusion.feed_data(val_data)\n",
    "    #                 diffusion.test(continous=False)\n",
    "    #                 visuals = diffusion.get_current_visuals()\n",
    "    #                 sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "    #                 hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "    #                 lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "    #                 fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "\n",
    "    #                 # generation\n",
    "    #                 Metrics.save_img(\n",
    "    #                     hr_img, '{}/{}_{}_hr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     sr_img, '{}/{}_{}_sr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     lr_img, '{}/{}_{}_lr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     fake_img, '{}/{}_{}_inf.png'.format(result_path, current_step, idx))\n",
    "    #                 tb_logger.add_image(\n",
    "    #                     'Iter_{}'.format(current_step),\n",
    "    #                     np.transpose(np.concatenate(\n",
    "    #                         (fake_img, sr_img, hr_img), axis=1), [2, 0, 1]),\n",
    "    #                     idx)\n",
    "    #                 avg_psnr += Metrics.calculate_psnr(\n",
    "    #                     sr_img, hr_img)\n",
    "\n",
    "    #                 if wandb_logger:\n",
    "    #                     wandb_logger.log_image(\n",
    "    #                         f'validation_{idx}', \n",
    "    #                         np.concatenate((fake_img, sr_img, hr_img), axis=1)\n",
    "    #                     )\n",
    "\n",
    "    #             avg_psnr = avg_psnr / idx\n",
    "    #             diffusion.set_new_noise_schedule(\n",
    "    #                 opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "    #             # log\n",
    "    #             logger.info('# Validation # PSNR: {:.4e}'.format(avg_psnr))\n",
    "    #             logger_val = logging.getLogger('val')  # validation logger\n",
    "    #             logger_val.info('<epoch:{:3d}, iter:{:8,d}> psnr: {:.4e}'.format(\n",
    "    #                 current_epoch, current_step, avg_psnr))\n",
    "    #             # tensorboard logger\n",
    "    #             tb_logger.add_scalar('psnr', avg_psnr, current_step)\n",
    "\n",
    "    #             if wandb_logger:\n",
    "    #                 wandb_logger.log_metrics({\n",
    "    #                     'validation/val_psnr': avg_psnr,\n",
    "    #                     'validation/val_step': val_step\n",
    "    #                 })\n",
    "    #                 val_step += 1\n",
    "                \n",
    "            if current_step % opt['train']['save_checkpoint_freq'] == 0:\n",
    "                logger.info('Saving models and training states.')\n",
    "                diffusion.save_network(current_epoch, current_step)\n",
    "            \n",
    "            if current_step == n_iter:\n",
    "                logger.info(\"Saving final model\")\n",
    "                diffusion.save_network(current_epoch, current_step, is_final=True)\n",
    "\n",
    "                # if wandb_logger and opt['log_wandb_ckpt']:\n",
    "                #     wandb_logger.log_checkpoint(current_epoch, current_step)\n",
    "\n",
    "        epoch_loss = sum(epoch_loss_values)/len(epoch_loss_values)\n",
    "        print('Epoch Loss: ', epoch_loss)\n",
    "        epoch_loss_list.append(epoch_loss)\n",
    "\n",
    "        # if wandb_logger:\n",
    "        #     wandb_logger.log_metrics({'epoch': current_epoch-1})\n",
    "\n",
    "    # save model\n",
    "    print('Epoch Loss List: ', epoch_loss_list)\n",
    "    logger.info('End of training.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446fa478",
   "metadata": {
    "papermill": {
     "duration": 0.016988,
     "end_time": "2025-05-14T04:18:20.080384",
     "exception": false,
     "start_time": "2025-05-14T04:18:20.063396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Training visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "417f9a26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T04:18:20.115797Z",
     "iopub.status.busy": "2025-05-14T04:18:20.115516Z",
     "iopub.status.idle": "2025-05-14T04:18:20.121036Z",
     "shell.execute_reply": "2025-05-14T04:18:20.120227Z"
    },
    "papermill": {
     "duration": 0.024761,
     "end_time": "2025-05-14T04:18:20.122193",
     "exception": false,
     "start_time": "2025-05-14T04:18:20.097432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_loss_curve(epoch_loss_list, filename='loss_curve.png'):\n",
    "    epochs = range(1, len(epoch_loss_list) + 1)  # X-axis starts at 1\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epochs, epoch_loss_list, marker='o', label='Training Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(epochs)  # Set integer ticks\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55850acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T04:18:20.157165Z",
     "iopub.status.busy": "2025-05-14T04:18:20.156961Z",
     "iopub.status.idle": "2025-05-14T04:18:20.410354Z",
     "shell.execute_reply": "2025-05-14T04:18:20.409570Z"
    },
    "papermill": {
     "duration": 0.272555,
     "end_time": "2025-05-14T04:18:20.411746",
     "exception": false,
     "start_time": "2025-05-14T04:18:20.139191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_loss_curve(epoch_loss_list, \"/kaggle/working/train_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d37b1b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-14T04:18:20.447823Z",
     "iopub.status.busy": "2025-05-14T04:18:20.447573Z",
     "iopub.status.idle": "2025-05-14T04:18:20.451378Z",
     "shell.execute_reply": "2025-05-14T04:18:20.450893Z"
    },
    "papermill": {
     "duration": 0.022757,
     "end_time": "2025-05-14T04:18:20.452325",
     "exception": false,
     "start_time": "2025-05-14T04:18:20.429568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# handling validation (not considered for now and maybe even moving to seperate notebook could make sense, has to be thought about)\n",
    "\n",
    "# else:\n",
    "#     logger.info('Begin Model Evaluation.')\n",
    "#     avg_psnr = 0.0\n",
    "#     avg_ssim = 0.0\n",
    "#     idx = 0\n",
    "#     result_path = '{}'.format(opt['path']['results'])\n",
    "#     os.makedirs(result_path, exist_ok=True)\n",
    "#     for _,  val_data in enumerate(val_loader):\n",
    "#         idx += 1\n",
    "#         diffusion.feed_data(val_data)\n",
    "#         diffusion.test(continous=True)\n",
    "#         visuals = diffusion.get_current_visuals()\n",
    "\n",
    "#         hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "#         lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "#         fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "\n",
    "#         sr_img_mode = 'grid'\n",
    "#         if sr_img_mode == 'single':\n",
    "#             # single img series\n",
    "#             sr_img = visuals['SR']  # uint8\n",
    "#             sample_num = sr_img.shape[0]\n",
    "#             for iter in range(0, sample_num):\n",
    "#                 Metrics.save_img(\n",
    "#                     Metrics.tensor2img(sr_img[iter]), '{}/{}_{}_sr_{}.png'.format(result_path, current_step, idx, iter))\n",
    "#         else:\n",
    "#             # grid img\n",
    "#             sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "#             Metrics.save_img(\n",
    "#                 sr_img, '{}/{}_{}_sr_process.png'.format(result_path, current_step, idx))\n",
    "#             Metrics.save_img(\n",
    "#                 Metrics.tensor2img(visuals['SR'][-1]), '{}/{}_{}_sr.png'.format(result_path, current_step, idx))\n",
    "\n",
    "#         Metrics.save_img(\n",
    "#             hr_img, '{}/{}_{}_hr.png'.format(result_path, current_step, idx))\n",
    "#         Metrics.save_img(\n",
    "#             lr_img, '{}/{}_{}_lr.png'.format(result_path, current_step, idx))\n",
    "#         Metrics.save_img(\n",
    "#             fake_img, '{}/{}_{}_inf.png'.format(result_path, current_step, idx))\n",
    "\n",
    "#         # generation\n",
    "#         eval_psnr = Metrics.calculate_psnr(Metrics.tensor2img(visuals['SR'][-1]), hr_img)\n",
    "#         eval_ssim = Metrics.calculate_ssim(Metrics.tensor2img(visuals['SR'][-1]), hr_img)\n",
    "\n",
    "#         avg_psnr += eval_psnr\n",
    "#         avg_ssim += eval_ssim\n",
    "\n",
    "#         if wandb_logger and opt['log_eval']:\n",
    "#             wandb_logger.log_eval_data(fake_img, Metrics.tensor2img(visuals['SR'][-1]), hr_img, eval_psnr, eval_ssim)\n",
    "\n",
    "#     avg_psnr = avg_psnr / idx\n",
    "#     avg_ssim = avg_ssim / idx\n",
    "\n",
    "#     # log\n",
    "#     logger.info('# Validation # PSNR: {:.4e}'.format(avg_psnr))\n",
    "#     logger.info('# Validation # SSIM: {:.4e}'.format(avg_ssim))\n",
    "#     logger_val = logging.getLogger('val')  # validation logger\n",
    "#     logger_val.info('<epoch:{:3d}, iter:{:8,d}> psnr: {:.4e}, ssim{:.4e}'.format(\n",
    "#         current_epoch, current_step, avg_psnr, avg_ssim))\n",
    "\n",
    "#     if wandb_logger:\n",
    "#         if opt['log_eval']:\n",
    "#             wandb_logger.log_eval_table()\n",
    "#         wandb_logger.log_metrics({\n",
    "#             'PSNR': float(avg_psnr),\n",
    "#             'SSIM': float(avg_ssim)\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ece83b",
   "metadata": {
    "papermill": {
     "duration": 0.017746,
     "end_time": "2025-05-14T04:18:20.487200",
     "exception": false,
     "start_time": "2025-05-14T04:18:20.469454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a33c3",
   "metadata": {
    "papermill": {
     "duration": 0.017197,
     "end_time": "2025-05-14T04:18:20.521790",
     "exception": false,
     "start_time": "2025-05-14T04:18:20.504593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa99a4",
   "metadata": {
    "papermill": {
     "duration": 0.027511,
     "end_time": "2025-05-14T04:18:20.572975",
     "exception": false,
     "start_time": "2025-05-14T04:18:20.545464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed0b18",
   "metadata": {
    "papermill": {
     "duration": 0.021934,
     "end_time": "2025-05-14T04:18:20.614766",
     "exception": false,
     "start_time": "2025-05-14T04:18:20.592832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7135363,
     "sourceId": 11393337,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7410143,
     "sourceId": 11799854,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7410151,
     "sourceId": 11799865,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7410155,
     "sourceId": 11799871,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18465.863087,
   "end_time": "2025-05-14T04:18:22.872335",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-13T23:10:37.009248",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
