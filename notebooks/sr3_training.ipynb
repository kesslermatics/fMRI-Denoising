{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdddae8",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import logging\n",
    "# from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from re import split\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752d72c",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"denoising_v1\",\n",
    "    \"phase\": \"train\",\n",
    "    \"gpu_ids\": [0, 1], \n",
    "    \"debug\": False,  \n",
    "    \"enable_wandb\": False,  \n",
    "    \"log_wandb_ckpt\": False,  \n",
    "    \"log_eval\": False,  \n",
    "    \"path\": {\n",
    "        \"log\": \"logs\",\n",
    "        \"tb_logger\": \"tb_logger\",\n",
    "        \"results\": \"results\",\n",
    "        \"checkpoint\": \"checkpoint\",\n",
    "        \"resume_state\": None\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\",\n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 6,\n",
    "            \"out_channel\": 3,\n",
    "            \"inner_channel\": 64,\n",
    "            \"norm_groups\": 16,\n",
    "            \"channel_multiplier\": [1, 2, 4, 8, 16],\n",
    "            \"attn_res\": [],\n",
    "            \"res_blocks\": 1,\n",
    "            \"dropout\": 0\n",
    "        },\n",
    "        \"beta_schedule\": {\n",
    "            \"train\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 512,\n",
    "            \"channels\": 3,\n",
    "            \"conditional\": True\n",
    "        }\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"n_iter\": 1000000,\n",
    "        \"val_freq\": 1e4,\n",
    "        \"save_checkpoint_freq\": 1e4,\n",
    "        \"print_freq\": 50,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"lr\": 3e-6\n",
    "        },\n",
    "        \"ema_scheduler\": {\n",
    "            \"step_start_ema\": 5000,\n",
    "            \"update_ema_every\": 1,\n",
    "            \"ema_decay\": 0.9999\n",
    "        }\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        \"project\": \"denoising_v1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afedc2",
   "metadata": {},
   "source": [
    "Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # logging\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Logger.setup_logger(None, opt['path']['log'],\n",
    "#                     'train', level=logging.INFO, screen=True)\n",
    "# Logger.setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "# logger = logging.getLogger('base')\n",
    "# logger.info(Logger.dict2str(opt))\n",
    "# tb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])\n",
    "\n",
    "# # Initialize WandbLogger\n",
    "# if opt['enable_wandb']:\n",
    "#     import wandb\n",
    "#     wandb_logger = WandbLogger(opt)\n",
    "#     wandb.define_metric('validation/val_step')\n",
    "#     wandb.define_metric('epoch')\n",
    "#     wandb.define_metric(\"validation/*\", step_metric=\"val_step\")\n",
    "#     val_step = 0\n",
    "# else:\n",
    "#     wandb_logger = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80637995",
   "metadata": {},
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, noisy_images_paths: list, gt_images_paths: list):\n",
    "        \"\"\"Initialize fMRI dataset for denoising.\n",
    "        \n",
    "        Args:\n",
    "            noisy_images_paths (list): List of paths to noisy fMRI volumes (.npy files)\n",
    "            gt_images_paths (list): List of paths to ground truth fMRI volumes (.npy files)\n",
    "        \"\"\"\n",
    "        self.noisy_data = []\n",
    "        self.gt_data = []\n",
    "        \n",
    "        # Load and process noisy data\n",
    "        if noisy_images_paths:\n",
    "            for path in noisy_images_paths:\n",
    "                data = np.load(path)  # Load 4D array (x, y, z, t)\n",
    "                # Reshape to collapse last 2 dimensions into one\n",
    "                reshaped_data = np.reshape(data, (data.shape[0], data.shape[1], -1))\n",
    "                self.noisy_data.append(reshaped_data)\n",
    "            # Concatenate all arrays along the third dimension\n",
    "            self.noisy_data = np.concatenate(self.noisy_data, axis=2)\n",
    "            \n",
    "        # Load and process ground truth data\n",
    "        if gt_images_paths:\n",
    "            for path in gt_images_paths:\n",
    "                data = np.load(path)  # Load 4D array (x, y, z, t)\n",
    "                # Reshape to collapse last 2 dimensions into one\n",
    "                reshaped_data = np.reshape(data, (data.shape[0], data.shape[1], -1))\n",
    "                self.gt_data.append(reshaped_data)\n",
    "            # Concatenate all arrays along the third dimension\n",
    "            self.gt_data = np.concatenate(self.gt_data, axis=2)\n",
    "            \n",
    "        self.data_len = self.noisy_data.shape[2] if len(self.noisy_data) > 0 else 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Select the i-th noisy and ground truth images\n",
    "        noisy_image = self.noisy_data[:, :, index]\n",
    "        gt_image = self.gt_data[:, :, index]\n",
    "        return {'GT': gt_image, 'Noisy': noisy_image, 'Index': index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd281146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, dataset_opt, phase):\n",
    "    '''create dataloader '''\n",
    "    if phase == 'train':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=dataset_opt['batch_size'],\n",
    "            shuffle=dataset_opt['use_shuffle'],\n",
    "            num_workers=dataset_opt['num_workers'],\n",
    "            pin_memory=True)\n",
    "    elif phase == 'val':\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            'Dataloader [{:s}] is not found.'.format(phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data paths\n",
    "noisy_images_paths_train = ['/kaggle/input/fmri-train-1/data/noisy_func_train_1.npy',\n",
    "                      '/kaggle/input/fmri-train-2/data/noisy_func_train_2.npy',\n",
    "                      '/kaggle/input/fmri-train-3/data/noisy_func_train_3.npy']\n",
    "\n",
    "gt_images_paths_train = ['/kaggle/input/fmri-train-1/data/gt_func_train_1.npy',\n",
    "                   '/kaggle/input/fmri-train-2/data/gt_func_train_2.npy',\n",
    "                   '/kaggle/input/fmri-train-3/data/gt_func_train_3.npy']\n",
    "\n",
    "# Test data paths\n",
    "noisy_images_paths_test = ['/kaggle/input/fmri-test/data/noisy_func_test.npy']\n",
    "\n",
    "gt_images_paths_test = ['/kaggle/input/fmri-test/data/gt_func_test.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "for phase, dataset_opt in opt['datasets'].items():\n",
    "    if phase == 'train' and opt['phase'] != 'test':\n",
    "        train_set = PairwiseDataset(noisy_images_paths_train, gt_images_paths_train)\n",
    "        train_loader = create_dataloader(\n",
    "            train_set, dataset_opt, phase)\n",
    "    elif phase == 'test':\n",
    "        test_set = PairwiseDataset(noisy_images_paths_test, gt_images_paths_test)\n",
    "        test_loader = create_dataloader(\n",
    "            test_set, dataset_opt, phase)\n",
    "# logger.info('Initial Dataset Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85513b02",
   "metadata": {},
   "source": [
    "Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "diffusion = Model.create_model(opt)\n",
    "# logger.info('Initial Model Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64707f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "current_step = diffusion.begin_step\n",
    "current_epoch = diffusion.begin_epoch\n",
    "n_iter = opt['train']['n_iter']\n",
    "\n",
    "if opt['path']['resume_state']:\n",
    "    logger.info('Resuming training from epoch: {}, iter: {}.'.format(\n",
    "        current_epoch, current_step))\n",
    "\n",
    "diffusion.set_new_noise_schedule(\n",
    "    opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])\n",
    "if opt['phase'] == 'train':\n",
    "    while current_step < n_iter:\n",
    "        current_epoch += 1\n",
    "        for _, train_data in enumerate(train_loader):\n",
    "            current_step += 1\n",
    "            if current_step > n_iter:\n",
    "                break\n",
    "            diffusion.feed_data(train_data)\n",
    "            diffusion.optimize_parameters()\n",
    "            # log\n",
    "            if current_step % opt['train']['print_freq'] == 0:\n",
    "                logs = diffusion.get_current_log()\n",
    "                message = '<epoch:{:3d}, iter:{:8,d}> '.format(\n",
    "                    current_epoch, current_step)\n",
    "                for k, v in logs.items():\n",
    "                    message += '{:s}: {:.4e} '.format(k, v)\n",
    "                    tb_logger.add_scalar(k, v, current_step)\n",
    "                logger.info(message)\n",
    "\n",
    "                if wandb_logger:\n",
    "                    wandb_logger.log_metrics(logs)\n",
    "\n",
    "    #         # validation\n",
    "    #         if current_step % opt['train']['val_freq'] == 0:\n",
    "    #             avg_psnr = 0.0\n",
    "    #             idx = 0\n",
    "    #             result_path = '{}/{}'.format(opt['path']\n",
    "    #                                             ['results'], current_epoch)\n",
    "    #             os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "    #             diffusion.set_new_noise_schedule(\n",
    "    #                 opt['model']['beta_schedule']['val'], schedule_phase='val')\n",
    "    #             for _,  val_data in enumerate(val_loader):\n",
    "    #                 idx += 1\n",
    "    #                 diffusion.feed_data(val_data)\n",
    "    #                 diffusion.test(continous=False)\n",
    "    #                 visuals = diffusion.get_current_visuals()\n",
    "    #                 sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "    #                 hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "    #                 lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "    #                 fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "\n",
    "    #                 # generation\n",
    "    #                 Metrics.save_img(\n",
    "    #                     hr_img, '{}/{}_{}_hr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     sr_img, '{}/{}_{}_sr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     lr_img, '{}/{}_{}_lr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     fake_img, '{}/{}_{}_inf.png'.format(result_path, current_step, idx))\n",
    "    #                 tb_logger.add_image(\n",
    "    #                     'Iter_{}'.format(current_step),\n",
    "    #                     np.transpose(np.concatenate(\n",
    "    #                         (fake_img, sr_img, hr_img), axis=1), [2, 0, 1]),\n",
    "    #                     idx)\n",
    "    #                 avg_psnr += Metrics.calculate_psnr(\n",
    "    #                     sr_img, hr_img)\n",
    "\n",
    "    #                 if wandb_logger:\n",
    "    #                     wandb_logger.log_image(\n",
    "    #                         f'validation_{idx}', \n",
    "    #                         np.concatenate((fake_img, sr_img, hr_img), axis=1)\n",
    "    #                     )\n",
    "\n",
    "    #             avg_psnr = avg_psnr / idx\n",
    "    #             diffusion.set_new_noise_schedule(\n",
    "    #                 opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "    #             # log\n",
    "    #             logger.info('# Validation # PSNR: {:.4e}'.format(avg_psnr))\n",
    "    #             logger_val = logging.getLogger('val')  # validation logger\n",
    "    #             logger_val.info('<epoch:{:3d}, iter:{:8,d}> psnr: {:.4e}'.format(\n",
    "    #                 current_epoch, current_step, avg_psnr))\n",
    "    #             # tensorboard logger\n",
    "    #             tb_logger.add_scalar('psnr', avg_psnr, current_step)\n",
    "\n",
    "    #             if wandb_logger:\n",
    "    #                 wandb_logger.log_metrics({\n",
    "    #                     'validation/val_psnr': avg_psnr,\n",
    "    #                     'validation/val_step': val_step\n",
    "    #                 })\n",
    "    #                 val_step += 1\n",
    "\n",
    "    #         if current_step % opt['train']['save_checkpoint_freq'] == 0:\n",
    "    #             logger.info('Saving models and training states.')\n",
    "    #             diffusion.save_network(current_epoch, current_step)\n",
    "\n",
    "    #             if wandb_logger and opt['log_wandb_ckpt']:\n",
    "    #                 wandb_logger.log_checkpoint(current_epoch, current_step)\n",
    "\n",
    "    #     if wandb_logger:\n",
    "    #         wandb_logger.log_metrics({'epoch': current_epoch-1})\n",
    "\n",
    "    # # save model\n",
    "    # logger.info('End of training.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf70127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling validation (not considered for now and maybe even moving to seperate notebook could make sense, has to be thought about)\n",
    "\n",
    "# else:\n",
    "#     logger.info('Begin Model Evaluation.')\n",
    "#     avg_psnr = 0.0\n",
    "#     avg_ssim = 0.0\n",
    "#     idx = 0\n",
    "#     result_path = '{}'.format(opt['path']['results'])\n",
    "#     os.makedirs(result_path, exist_ok=True)\n",
    "#     for _,  val_data in enumerate(val_loader):\n",
    "#         idx += 1\n",
    "#         diffusion.feed_data(val_data)\n",
    "#         diffusion.test(continous=True)\n",
    "#         visuals = diffusion.get_current_visuals()\n",
    "\n",
    "#         hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "#         lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "#         fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "\n",
    "#         sr_img_mode = 'grid'\n",
    "#         if sr_img_mode == 'single':\n",
    "#             # single img series\n",
    "#             sr_img = visuals['SR']  # uint8\n",
    "#             sample_num = sr_img.shape[0]\n",
    "#             for iter in range(0, sample_num):\n",
    "#                 Metrics.save_img(\n",
    "#                     Metrics.tensor2img(sr_img[iter]), '{}/{}_{}_sr_{}.png'.format(result_path, current_step, idx, iter))\n",
    "#         else:\n",
    "#             # grid img\n",
    "#             sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "#             Metrics.save_img(\n",
    "#                 sr_img, '{}/{}_{}_sr_process.png'.format(result_path, current_step, idx))\n",
    "#             Metrics.save_img(\n",
    "#                 Metrics.tensor2img(visuals['SR'][-1]), '{}/{}_{}_sr.png'.format(result_path, current_step, idx))\n",
    "\n",
    "#         Metrics.save_img(\n",
    "#             hr_img, '{}/{}_{}_hr.png'.format(result_path, current_step, idx))\n",
    "#         Metrics.save_img(\n",
    "#             lr_img, '{}/{}_{}_lr.png'.format(result_path, current_step, idx))\n",
    "#         Metrics.save_img(\n",
    "#             fake_img, '{}/{}_{}_inf.png'.format(result_path, current_step, idx))\n",
    "\n",
    "#         # generation\n",
    "#         eval_psnr = Metrics.calculate_psnr(Metrics.tensor2img(visuals['SR'][-1]), hr_img)\n",
    "#         eval_ssim = Metrics.calculate_ssim(Metrics.tensor2img(visuals['SR'][-1]), hr_img)\n",
    "\n",
    "#         avg_psnr += eval_psnr\n",
    "#         avg_ssim += eval_ssim\n",
    "\n",
    "#         if wandb_logger and opt['log_eval']:\n",
    "#             wandb_logger.log_eval_data(fake_img, Metrics.tensor2img(visuals['SR'][-1]), hr_img, eval_psnr, eval_ssim)\n",
    "\n",
    "#     avg_psnr = avg_psnr / idx\n",
    "#     avg_ssim = avg_ssim / idx\n",
    "\n",
    "#     # log\n",
    "#     logger.info('# Validation # PSNR: {:.4e}'.format(avg_psnr))\n",
    "#     logger.info('# Validation # SSIM: {:.4e}'.format(avg_ssim))\n",
    "#     logger_val = logging.getLogger('val')  # validation logger\n",
    "#     logger_val.info('<epoch:{:3d}, iter:{:8,d}> psnr: {:.4e}, ssim：{:.4e}'.format(\n",
    "#         current_epoch, current_step, avg_psnr, avg_ssim))\n",
    "\n",
    "#     if wandb_logger:\n",
    "#         if opt['log_eval']:\n",
    "#             wandb_logger.log_eval_table()\n",
    "#         wandb_logger.log_metrics({\n",
    "#             'PSNR': float(avg_psnr),\n",
    "#             'SSIM': float(avg_ssim)\n",
    "#         })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
