{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11393337,"sourceType":"datasetVersion","datasetId":7135363},{"sourceId":11733946,"sourceType":"datasetVersion","datasetId":7366231},{"sourceId":11733959,"sourceType":"datasetVersion","datasetId":7366110},{"sourceId":11734408,"sourceType":"datasetVersion","datasetId":7366162},{"sourceId":382623,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":315941,"modelId":336404}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"!pip install tensorboardX","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:26:06.561468Z","iopub.execute_input":"2025-05-08T16:26:06.562008Z","iopub.status.idle":"2025-05-08T16:26:10.519391Z","shell.execute_reply.started":"2025-05-08T16:26:06.561984Z","shell.execute_reply":"2025-05-08T16:26:10.518471Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorboardX\n  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\nRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (3.20.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->tensorboardX) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->tensorboardX) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->tensorboardX) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->tensorboardX) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->tensorboardX) (2024.2.0)\nDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboardX\nSuccessfully installed tensorboardX-2.6.2.2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport argparse\nimport logging\nfrom tensorboardX import SummaryWriter\nimport os\nimport numpy as np\n\nfrom io import BytesIO\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport random\nfrom re import split\nimport torch.utils.data\n\n# import torch.nn as nn\nfrom collections import OrderedDict\n\nimport functools\nfrom torch.nn import init\nfrom torch.nn import modules\n\n# u-net\nimport math\nimport torch.nn.functional as F\nfrom inspect import isfunction\n\n# diffusion\nfrom torch import nn\nfrom functools import partial\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:26:10.521012Z","iopub.execute_input":"2025-05-08T16:26:10.521327Z","iopub.status.idle":"2025-05-08T16:26:25.777789Z","shell.execute_reply.started":"2025-05-08T16:26:10.521297Z","shell.execute_reply":"2025-05-08T16:26:25.777264Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Config","metadata":{}},{"cell_type":"code","source":"opt = {\n    \"name\": \"denoising\",\n    \"phase\": \"test\",\n    \"gpu_ids\": [0, 1], \n    \"debug\": False,  \n    \"enable_wandb\": False,  \n    \"log_wandb_ckpt\": False,  \n    \"log_eval\": False,  \n    \"path\": {\n        \"log\": \"/kaggle/working/logs\",\n        \"tb_logger\": \"/kaggle/working/tb_logger\",\n        \"results\": \"/kaggle/working/results\",\n        \"checkpoint\": \"/kaggle/working/checkpoint\",\n        \"resume_state\": \"/kaggle/input/sr3_v01/pytorch/default/1/checkpoint/I100_E1\"\n    },\n    \"datasets\": {\n        \"train\": {\n            \"noisy_data_paths\": ['/kaggle/input/fmri-train-1-sampled/data/noisy_func_train_1.npy',\n                '/kaggle/input/fmri-train-2-sampled/data/noisy_func_train_2.npy',\n                '/kaggle/input/fmri-train-3-sampled/data/noisy_func_train_3.npy'],\n            \"gt_data_paths\": ['/kaggle/input/fmri-train-1-sampled/data/gt_func_train_1.npy',\n                '/kaggle/input/fmri-train-2-sampled/data/gt_func_train_2.npy',\n                '/kaggle/input/fmri-train-3-sampled/data/gt_func_train_3.npy'],\n            \"batch_size\": 1,\n            \"num_workers\": 1,\n            \"use_shuffle\": True\n        },\n        \"test\": {\n            \"noisy_data_paths\": ['/kaggle/input/fmri-test/data/noisy_func_test.npy'],\n            \"gt_data_paths\": ['/kaggle/input/fmri-test/data/gt_func_test.npy']\n        }\n    },\n    \"model\": {\n        \"which_model_G\": \"sr3\",\n        \"finetune_norm\": False,\n        \"unet\": {\n            \"in_channel\": 2,\n            \"out_channel\": 1,\n            \"inner_channel\": 64,\n            \"norm_groups\": 16,\n            \"channel_multiplier\": [1, 2, 4, 8, 16],\n            \"attn_res\": [],\n            \"res_blocks\": 1,\n            \"dropout\": 0\n        },\n        \"beta_schedule\": {\n            \"train\": {\n                \"schedule\": \"linear\",\n                \"n_timestep\": 2000,\n                \"linear_start\": 1e-6,\n                \"linear_end\": 1e-2\n            },\n            \"test\": {\n                \"schedule\": \"linear\",\n                \"n_timestep\": 2000,\n                \"linear_start\": 1e-6,\n                \"linear_end\": 1e-2\n            }\n        },\n        \"diffusion\": {\n            \"image_size\": 64,\n            \"channels\": 1,\n            \"conditional\": True\n        }\n    },\n    \"train\": {\n        \"n_iter\": 150,\n        \"val_freq\": 1e4,\n        \"save_checkpoint_freq\": 100,\n        \"print_freq\": 50,\n        \"optimizer\": {\n            \"type\": \"adam\",\n            \"lr\": 3e-6\n        },\n        \"ema_scheduler\": {\n            \"step_start_ema\": 5000,\n            \"update_ema_every\": 1,\n            \"ema_decay\": 0.9999\n        }\n    },\n    \"wandb\": {\n        \"project\": \"distributed_high_sr_ffhq\"\n    },\n    \"config_file\": \"config/sr_sr3_16_128.json\"  # from CLI\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:13.748923Z","iopub.execute_input":"2025-05-08T16:39:13.749490Z","iopub.status.idle":"2025-05-08T16:39:13.756524Z","shell.execute_reply.started":"2025-05-08T16:39:13.749465Z","shell.execute_reply":"2025-05-08T16:39:13.755730Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"os.makedirs(opt['path']['log'], exist_ok=True)\nos.makedirs(opt['path']['tb_logger'], exist_ok=True)\nos.makedirs(opt['path']['results'], exist_ok=True)\nos.makedirs(opt['path']['checkpoint'], exist_ok=True)\n#os.makedirs(opt['path']['resume_state'], exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:17.732901Z","iopub.execute_input":"2025-05-08T16:39:17.733252Z","iopub.status.idle":"2025-05-08T16:39:17.737989Z","shell.execute_reply.started":"2025-05-08T16:39:17.733230Z","shell.execute_reply":"2025-05-08T16:39:17.737253Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"Logger","metadata":{}},{"cell_type":"code","source":"# logging\ntorch.backends.cudnn.enabled = True\ntorch.backends.cudnn.benchmark = True\n\ndef dict2str(opt, indent_l=1):\n    '''dict to string for logger'''\n    msg = ''\n    for k, v in opt.items():\n        if isinstance(v, dict):\n            msg += ' ' * (indent_l * 2) + k + ':[\\n'\n            msg += dict2str(v, indent_l + 1)\n            msg += ' ' * (indent_l * 2) + ']\\n'\n        else:\n            msg += ' ' * (indent_l * 2) + k + ': ' + str(v) + '\\n'\n    return msg\n\ndef setup_logger(logger_name, root, phase, level=logging.INFO, screen=False):\n    '''set up logger'''\n    l = logging.getLogger(logger_name)\n    formatter = logging.Formatter(\n        '%(asctime)s.%(msecs)03d - %(levelname)s: %(message)s', datefmt='%y-%m-%d %H:%M:%S')\n    log_file = os.path.join(root, '{}.log'.format(phase))\n    fh = logging.FileHandler(log_file, mode='w')\n    fh.setFormatter(formatter)\n    l.setLevel(level)\n    l.addHandler(fh)\n    if screen:\n        sh = logging.StreamHandler()\n        sh.setFormatter(formatter)\n        l.addHandler(sh)\n\n\nsetup_logger(None, opt['path']['log'],\n                    'train', level=logging.INFO, screen=True)\nsetup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\nlogger = logging.getLogger('base')\n#logger.info(dict2str(opt))\ntb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])\n\n# # Initialize WandbLogger\n# if opt['enable_wandb']:\n#     import wandb\n#     wandb_logger = WandbLogger(opt)\n#     wandb.define_metric('validation/val_step')\n#     wandb.define_metric('epoch')\n#     wandb.define_metric(\"validation/*\", step_metric=\"val_step\")\n#     val_step = 0\n# else:\n#     wandb_logger = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:18.012340Z","iopub.execute_input":"2025-05-08T16:39:18.012933Z","iopub.status.idle":"2025-05-08T16:39:18.023036Z","shell.execute_reply.started":"2025-05-08T16:39:18.012910Z","shell.execute_reply":"2025-05-08T16:39:18.022321Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"Dataset creation","metadata":{}},{"cell_type":"code","source":"class PairwiseDataset(Dataset):\n    def __init__(self, noisy_images_paths: list, gt_images_paths: list):\n        \"\"\"Initialize fMRI dataset for denoising with memory-efficient loading.\n        \n        Args:\n            noisy_images_paths (list): List of paths to noisy fMRI volumes (.npy files)\n            gt_images_paths (list): List of paths to ground truth fMRI volumes (.npy files)\n        \"\"\"\n        self.noisy_paths = noisy_images_paths\n        self.gt_paths = gt_images_paths\n        \n        # Get the data shape and total slices without loading all data\n        # Just load file info and calculate indices\n        self.file_slice_mapping = []\n        self.z_t_dimension_sizes = []\n        total_slices = 0\n        dataset_length = 0 # in terms of indeces that can be iteratet over at the end (less than slice number due to batch loading within get_item)\n        \n        for i, path in enumerate(noisy_images_paths):\n            # Load metadata about the file shape without loading full content\n            data_shape = np.load(path, mmap_mode='r').shape\n            num_slices = data_shape[2] * data_shape[3]  # z * t\n            self.z_t_dimension_sizes.append((data_shape[2], data_shape[3]))\n            \n            # Store mapping information: which file and which t index (has been done due to more efficient data loading, no information aggregation based thinking behind that)\n            for batch_idx in range(0, data_shape[3]):\n                self.file_slice_mapping.append((i, batch_idx))\n                dataset_length += 1\n            \n            total_slices += num_slices \n            \n        self.data_len = dataset_length\n\n    def __len__(self):\n        return self.data_len\n\n    def __getitem__(self, index):\n        # Use the mapping to determine which file and slice to load\n        file_idx, t_idx = self.file_slice_mapping[index]\n        \n        # Load data from the specific file\n        noisy_file_path = self.noisy_paths[file_idx]\n        gt_file_path = self.gt_paths[file_idx]\n        \n        # Load the full 4D array with mmap_mode to avoid loading everything\n        noisy_volume = np.load(noisy_file_path, mmap_mode='r')\n        gt_volume = np.load(gt_file_path, mmap_mode='r')\n        \n        # Extract only the slice we need\n        noisy_slice = noisy_volume[:, :, :, t_idx].copy()  # Force copy from mmap\n        gt_slice = gt_volume[:, :, :, t_idx].copy()\n        \n        return {\n            'GT': torch.tensor(gt_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n            'Noisy': torch.tensor(noisy_slice).float().unsqueeze(0).permute(-1, 0, 1, 2),\n            'Index': index\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:18.416582Z","iopub.execute_input":"2025-05-08T16:39:18.417066Z","iopub.status.idle":"2025-05-08T16:39:18.424349Z","shell.execute_reply.started":"2025-05-08T16:39:18.417043Z","shell.execute_reply":"2025-05-08T16:39:18.423606Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"class PairwiseTestDataset(Dataset):\n    def __init__(self, noisy_images_paths: list, gt_images_paths: list):\n        \"\"\"Initialize fMRI dataset for denoising with memory-efficient loading.\n        \n        Args:\n            noisy_images_paths (list): List of paths to noisy fMRI volumes (.npy files)\n            gt_images_paths (list): List of paths to ground truth fMRI volumes (.npy files)\n        \"\"\"\n        self.noisy_paths = noisy_images_paths\n        self.gt_paths = gt_images_paths\n        \n        # Get the data shape and total slices without loading all data\n        # Just load file info and calculate indices\n        self.file_slice_mapping = []\n        total_slices = 0\n        \n        for i, path in enumerate(noisy_images_paths):\n            # Load metadata about the file shape without loading full content\n            data_shape = np.load(path, mmap_mode='r').shape\n            num_slices = data_shape[2] * data_shape[3]  # z * t\n            \n            # Store mapping information: which file and which slice\n            for slice_idx in range(num_slices):\n                self.file_slice_mapping.append((i, slice_idx))\n            \n            total_slices += num_slices\n            \n        self.data_len = total_slices\n\n    def __len__(self):\n        return self.data_len\n\n    def __getitem__(self, index):\n        # Use the mapping to determine which file and slice to load\n        file_idx, slice_idx = self.file_slice_mapping[index]\n        \n        # Load data from the specific file\n        noisy_file_path = self.noisy_paths[file_idx]\n        gt_file_path = self.gt_paths[file_idx]\n        \n        # Load the full 4D array with mmap_mode to avoid loading everything\n        noisy_volume = np.load(noisy_file_path, mmap_mode='r')\n        gt_volume = np.load(gt_file_path, mmap_mode='r')\n        \n        # Calculate the z and t indices from linear slice_idx\n        z = slice_idx % noisy_volume.shape[2]\n        t = slice_idx // noisy_volume.shape[2]\n        \n        # Extract only the slice we need\n        noisy_slice = noisy_volume[:, :, z, t].copy()  # Force copy from mmap\n        gt_slice = gt_volume[:, :, z, t].copy()\n        \n        return {\n            'GT': torch.tensor(gt_slice).float().unsqueeze(0),\n            'Noisy': torch.tensor(noisy_slice).float().unsqueeze(0),\n            'Index': index\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:18.438493Z","iopub.execute_input":"2025-05-08T16:39:18.438721Z","iopub.status.idle":"2025-05-08T16:39:18.446239Z","shell.execute_reply.started":"2025-05-08T16:39:18.438703Z","shell.execute_reply":"2025-05-08T16:39:18.445639Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def collate_merge_batches(batch):\n    merged = {\n        'Noisy': torch.cat([item['Noisy'] for item in batch], dim=0),\n        'GT': torch.cat([item['GT'] for item in batch], dim=0),\n        'Index': [item['Index'] for item in batch]\n    }\n    return merged\n\ndef create_dataloader(dataset, dataset_opt, phase):\n    '''create dataloader '''\n    if phase == 'train':\n        return torch.utils.data.DataLoader(\n            dataset,\n            batch_size=dataset_opt['batch_size'],\n            shuffle=dataset_opt['use_shuffle'],\n            num_workers=dataset_opt['num_workers'],\n            pin_memory=True,\n            collate_fn = collate_merge_batches)\n    elif phase == 'test':\n        return torch.utils.data.DataLoader(\n            dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n    else:\n        raise NotImplementedError(\n            'Dataloader [{:s}] is not found.'.format(phase))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:18.532009Z","iopub.execute_input":"2025-05-08T16:39:18.532353Z","iopub.status.idle":"2025-05-08T16:39:18.537864Z","shell.execute_reply.started":"2025-05-08T16:39:18.532330Z","shell.execute_reply":"2025-05-08T16:39:18.537331Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# dataset\nfor phase, dataset_opt in opt['datasets'].items():\n    if phase == 'train' and opt['phase'] != 'test':\n        train_set = PairwiseDataset(dataset_opt['noisy_data_paths'], dataset_opt['gt_data_paths'])\n        train_loader = create_dataloader(\n            train_set, dataset_opt, phase)\n    elif phase == 'test':\n        test_set = PairwiseTestDataset(dataset_opt['noisy_data_paths'], dataset_opt['gt_data_paths'])\n        test_loader = create_dataloader(\n            test_set, dataset_opt, phase)\n# logger.info('Initial Dataset Finished')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:18.676608Z","iopub.execute_input":"2025-05-08T16:39:18.676839Z","iopub.status.idle":"2025-05-08T16:39:18.729775Z","shell.execute_reply.started":"2025-05-08T16:39:18.676822Z","shell.execute_reply":"2025-05-08T16:39:18.729242Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"noisy_slice = test_set[400][\"Noisy\"]\ngt_slice = test_set[400][\"GT\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:18.813243Z","iopub.execute_input":"2025-05-08T16:39:18.813497Z","iopub.status.idle":"2025-05-08T16:39:18.962588Z","shell.execute_reply.started":"2025-05-08T16:39:18.813479Z","shell.execute_reply":"2025-05-08T16:39:18.962025Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# for _, data in train_loader:\n#     print(data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:18.963545Z","iopub.execute_input":"2025-05-08T16:39:18.963828Z","iopub.status.idle":"2025-05-08T16:39:18.967574Z","shell.execute_reply.started":"2025-05-08T16:39:18.963803Z","shell.execute_reply":"2025-05-08T16:39:18.966603Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, axes = plt.subplots(1, 2, figsize=(10, 5))\n\n# Plot ground truth image\naxes[0].imshow(noisy_slice.squeeze(0), cmap='gray')\naxes[1].imshow(gt_slice.squeeze(0), cmap='gray')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:19.088274Z","iopub.execute_input":"2025-05-08T16:39:19.088774Z","iopub.status.idle":"2025-05-08T16:39:19.397952Z","shell.execute_reply.started":"2025-05-08T16:39:19.088749Z","shell.execute_reply":"2025-05-08T16:39:19.397162Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f96ee7df550>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"## Model loading","metadata":{}},{"cell_type":"markdown","source":"Modules","metadata":{}},{"cell_type":"code","source":"# generic functions\ndef exists(x):\n    return x is not None\n\n\ndef default(val, d):\n    if exists(val):\n        return val\n    return d() if isfunction(d) else d","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:19.508317Z","iopub.execute_input":"2025-05-08T16:39:19.508860Z","iopub.status.idle":"2025-05-08T16:39:19.512621Z","shell.execute_reply.started":"2025-05-08T16:39:19.508837Z","shell.execute_reply":"2025-05-08T16:39:19.512062Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"### U-Net ###\n\n# PositionalEncoding Source： https://github.com/lmnt-com/wavegrad/blob/master/src/wavegrad/model.py\nclass PositionalEncoding(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, noise_level):\n        count = self.dim // 2\n        step = torch.arange(count, dtype=noise_level.dtype,\n                            device=noise_level.device) / count\n        encoding = noise_level.unsqueeze(\n            1) * torch.exp(-math.log(1e4) * step.unsqueeze(0))\n        encoding = torch.cat(\n            [torch.sin(encoding), torch.cos(encoding)], dim=-1)\n        return encoding\n\n\nclass FeatureWiseAffine(nn.Module):\n    def __init__(self, in_channels, out_channels, use_affine_level=False):\n        super(FeatureWiseAffine, self).__init__()\n        self.use_affine_level = use_affine_level\n        self.noise_func = nn.Sequential(\n            nn.Linear(in_channels, out_channels*(1+self.use_affine_level))\n        )\n\n    def forward(self, x, noise_embed):\n        batch = x.shape[0]\n        if self.use_affine_level:\n            gamma, beta = self.noise_func(noise_embed).view(\n                batch, -1, 1, 1).chunk(2, dim=1)\n            x = (1 + gamma) * x + beta\n        else:\n            x = x + self.noise_func(noise_embed).view(batch, -1, 1, 1)\n        return x\n\n\nclass Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\n\nclass Upsample(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.up = nn.Upsample(scale_factor=2, mode=\"nearest\")\n        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n\n    def forward(self, x):\n        return self.conv(self.up(x))\n\n\nclass Downsample(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.conv = nn.Conv2d(dim, dim, 3, 2, 1)\n\n    def forward(self, x):\n        return self.conv(x)\n\n\n# building block modules\n\n\nclass Block(nn.Module):\n    def __init__(self, dim, dim_out, groups=32, dropout=0):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.GroupNorm(groups, dim),\n            Swish(),\n            nn.Dropout(dropout) if dropout != 0 else nn.Identity(),\n            nn.Conv2d(dim, dim_out, 3, padding=1)\n        )\n\n    def forward(self, x):\n        return self.block(x)\n\n\nclass ResnetBlock(nn.Module):\n    def __init__(self, dim, dim_out, noise_level_emb_dim=None, dropout=0, use_affine_level=False, norm_groups=32):\n        super().__init__()\n        self.noise_func = FeatureWiseAffine(\n            noise_level_emb_dim, dim_out, use_affine_level)\n\n        self.block1 = Block(dim, dim_out, groups=norm_groups)\n        self.block2 = Block(dim_out, dim_out, groups=norm_groups, dropout=dropout)\n        self.res_conv = nn.Conv2d(\n            dim, dim_out, 1) if dim != dim_out else nn.Identity()\n\n    def forward(self, x, time_emb):\n        b, c, h, w = x.shape\n        h = self.block1(x)\n        h = self.noise_func(h, time_emb)\n        h = self.block2(h)\n        return h + self.res_conv(x)\n\n\nclass SelfAttention(nn.Module):\n    def __init__(self, in_channel, n_head=1, norm_groups=32):\n        super().__init__()\n\n        self.n_head = n_head\n\n        self.norm = nn.GroupNorm(norm_groups, in_channel)\n        self.qkv = nn.Conv2d(in_channel, in_channel * 3, 1, bias=False)\n        self.out = nn.Conv2d(in_channel, in_channel, 1)\n\n    def forward(self, input):\n        batch, channel, height, width = input.shape\n        n_head = self.n_head\n        head_dim = channel // n_head\n\n        norm = self.norm(input)\n        qkv = self.qkv(norm).view(batch, n_head, head_dim * 3, height, width)\n        query, key, value = qkv.chunk(3, dim=2)  # bhdyx\n\n        attn = torch.einsum(\n            \"bnchw, bncyx -> bnhwyx\", query, key\n        ).contiguous() / math.sqrt(channel)\n        attn = attn.view(batch, n_head, height, width, -1)\n        attn = torch.softmax(attn, -1)\n        attn = attn.view(batch, n_head, height, width, height, width)\n\n        out = torch.einsum(\"bnhwyx, bncyx -> bnchw\", attn, value).contiguous()\n        out = self.out(out.view(batch, channel, height, width))\n\n        return out + input\n\n\nclass ResnetBlocWithAttn(nn.Module):\n    def __init__(self, dim, dim_out, *, noise_level_emb_dim=None, norm_groups=32, dropout=0, with_attn=False):\n        super().__init__()\n        self.with_attn = with_attn\n        self.res_block = ResnetBlock(\n            dim, dim_out, noise_level_emb_dim, norm_groups=norm_groups, dropout=dropout)\n        if with_attn:\n            self.attn = SelfAttention(dim_out, norm_groups=norm_groups)\n\n    def forward(self, x, time_emb):\n        x = self.res_block(x, time_emb)\n        if(self.with_attn):\n            x = self.attn(x)\n        return x\n\n\nclass UNet(nn.Module):\n    def __init__(\n        self,\n        in_channel=6,\n        out_channel=3,\n        inner_channel=32,\n        norm_groups=32,\n        channel_mults=(1, 2, 4, 8, 8),\n        attn_res=(8),\n        res_blocks=3,\n        dropout=0,\n        with_noise_level_emb=True,\n        image_size=128\n    ):\n        super().__init__()\n\n        if with_noise_level_emb:\n            noise_level_channel = inner_channel\n            self.noise_level_mlp = nn.Sequential(\n                PositionalEncoding(inner_channel),\n                nn.Linear(inner_channel, inner_channel * 4),\n                Swish(),\n                nn.Linear(inner_channel * 4, inner_channel)\n            )\n        else:\n            noise_level_channel = None\n            self.noise_level_mlp = None\n\n        num_mults = len(channel_mults)\n        pre_channel = inner_channel\n        feat_channels = [pre_channel]\n        now_res = image_size\n        downs = [nn.Conv2d(in_channel, inner_channel,\n                           kernel_size=3, padding=1)]\n        for ind in range(num_mults):\n            is_last = (ind == num_mults - 1)\n            use_attn = (now_res in attn_res)\n            channel_mult = inner_channel * channel_mults[ind]\n            for _ in range(0, res_blocks):\n                downs.append(ResnetBlocWithAttn(\n                    pre_channel, channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups, dropout=dropout, with_attn=use_attn))\n                feat_channels.append(channel_mult)\n                pre_channel = channel_mult\n            if not is_last:\n                downs.append(Downsample(pre_channel))\n                feat_channels.append(pre_channel)\n                now_res = now_res//2\n        self.downs = nn.ModuleList(downs)\n\n        self.mid = nn.ModuleList([\n            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n                               dropout=dropout, with_attn=True),\n            ResnetBlocWithAttn(pre_channel, pre_channel, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n                               dropout=dropout, with_attn=False)\n        ])\n\n        ups = []\n        for ind in reversed(range(num_mults)):\n            is_last = (ind < 1)\n            use_attn = (now_res in attn_res)\n            channel_mult = inner_channel * channel_mults[ind]\n            for _ in range(0, res_blocks+1):\n                ups.append(ResnetBlocWithAttn(\n                    pre_channel+feat_channels.pop(), channel_mult, noise_level_emb_dim=noise_level_channel, norm_groups=norm_groups,\n                        dropout=dropout, with_attn=use_attn))\n                pre_channel = channel_mult\n            if not is_last:\n                ups.append(Upsample(pre_channel))\n                now_res = now_res*2\n\n        self.ups = nn.ModuleList(ups)\n\n        self.final_conv = Block(pre_channel, default(out_channel, in_channel), groups=norm_groups)\n\n    def forward(self, x, time):\n        t = self.noise_level_mlp(time) if exists(\n            self.noise_level_mlp) else None\n\n        feats = []\n        for layer in self.downs:\n            if isinstance(layer, ResnetBlocWithAttn):\n                x = layer(x, t)\n            else:\n                x = layer(x)\n            feats.append(x)\n\n        for layer in self.mid:\n            if isinstance(layer, ResnetBlocWithAttn):\n                x = layer(x, t)\n            else:\n                x = layer(x)\n\n        for layer in self.ups:\n            if isinstance(layer, ResnetBlocWithAttn):\n                x = layer(torch.cat((x, feats.pop()), dim=1), t)\n            else:\n                x = layer(x)\n\n        return self.final_conv(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T16:39:23.022495Z","iopub.execute_input":"2025-05-08T16:39:23.023153Z","iopub.status.idle":"2025-05-08T16:39:23.047535Z","shell.execute_reply.started":"2025-05-08T16:39:23.023131Z","shell.execute_reply":"2025-05-08T16:39:23.046822Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"### Diffusion ###\ndef _warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n    betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n    warmup_time = int(n_timestep * warmup_frac)\n    betas[:warmup_time] = np.linspace(\n        linear_start, linear_end, warmup_time, dtype=np.float64)\n    return betas\n\n\ndef make_beta_schedule(schedule, n_timestep, linear_start=1e-4, linear_end=2e-2, cosine_s=8e-3):\n    if schedule == 'quad':\n        betas = np.linspace(linear_start ** 0.5, linear_end ** 0.5,\n                            n_timestep, dtype=np.float64) ** 2\n    elif schedule == 'linear':\n        betas = np.linspace(linear_start, linear_end,\n                            n_timestep, dtype=np.float64)\n    elif schedule == 'warmup10':\n        betas = _warmup_beta(linear_start, linear_end,\n                             n_timestep, 0.1)\n    elif schedule == 'warmup50':\n        betas = _warmup_beta(linear_start, linear_end,\n                             n_timestep, 0.5)\n    elif schedule == 'const':\n        betas = linear_end * np.ones(n_timestep, dtype=np.float64)\n    elif schedule == 'jsd':  # 1/T, 1/(T-1), 1/(T-2), ..., 1\n        betas = 1. / np.linspace(n_timestep,\n                                 1, n_timestep, dtype=np.float64)\n    elif schedule == \"cosine\":\n        timesteps = (\n            torch.arange(n_timestep + 1, dtype=torch.float64) /\n            n_timestep + cosine_s\n        )\n        alphas = timesteps / (1 + cosine_s) * math.pi / 2\n        alphas = torch.cos(alphas).pow(2)\n        alphas = alphas / alphas[0]\n        betas = 1 - alphas[1:] / alphas[:-1]\n        betas = betas.clamp(max=0.999)\n    else:\n        raise NotImplementedError(schedule)\n    return betas\n\n\n# gaussian diffusion trainer class\nclass GaussianDiffusion(nn.Module):\n    def __init__(\n        self,\n        denoise_fn,\n        image_size,\n        channels=3,\n        loss_type='l1',\n        conditional=True,\n        schedule_opt=None\n    ):\n        super().__init__()\n        self.channels = channels\n        self.image_size = image_size\n        self.denoise_fn = denoise_fn\n        self.loss_type = loss_type\n        self.conditional = conditional\n        if schedule_opt is not None:\n            pass\n            # self.set_new_noise_schedule(schedule_opt)\n\n    def set_loss(self, device):\n        if self.loss_type == 'l1':\n            self.loss_func = nn.L1Loss(reduction='sum').to(device)\n        elif self.loss_type == 'l2':\n            self.loss_func = nn.MSELoss(reduction='sum').to(device)\n        else:\n            raise NotImplementedError()\n\n    def set_new_noise_schedule(self, schedule_opt, device):\n        to_torch = partial(torch.tensor, dtype=torch.float32, device=device)\n\n        betas = make_beta_schedule(\n            schedule=schedule_opt['schedule'],\n            n_timestep=schedule_opt['n_timestep'],\n            linear_start=schedule_opt['linear_start'],\n            linear_end=schedule_opt['linear_end'])\n        betas = betas.detach().cpu().numpy() if isinstance(\n            betas, torch.Tensor) else betas\n        alphas = 1. - betas\n        alphas_cumprod = np.cumprod(alphas, axis=0)\n        alphas_cumprod_prev = np.append(1., alphas_cumprod[:-1])\n        self.sqrt_alphas_cumprod_prev = np.sqrt(\n            np.append(1., alphas_cumprod))\n\n        timesteps, = betas.shape\n        self.num_timesteps = int(timesteps)\n        self.register_buffer('betas', to_torch(betas))\n        self.register_buffer('alphas_cumprod', to_torch(alphas_cumprod))\n        self.register_buffer('alphas_cumprod_prev',\n                             to_torch(alphas_cumprod_prev))\n\n        # calculations for diffusion q(x_t | x_{t-1}) and others\n        self.register_buffer('sqrt_alphas_cumprod',\n                             to_torch(np.sqrt(alphas_cumprod)))\n        self.register_buffer('sqrt_one_minus_alphas_cumprod',\n                             to_torch(np.sqrt(1. - alphas_cumprod)))\n        self.register_buffer('log_one_minus_alphas_cumprod',\n                             to_torch(np.log(1. - alphas_cumprod)))\n        self.register_buffer('sqrt_recip_alphas_cumprod',\n                             to_torch(np.sqrt(1. / alphas_cumprod)))\n        self.register_buffer('sqrt_recipm1_alphas_cumprod',\n                             to_torch(np.sqrt(1. / alphas_cumprod - 1)))\n\n        # calculations for posterior q(x_{t-1} | x_t, x_0)\n        posterior_variance = betas * \\\n            (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n        self.register_buffer('posterior_variance',\n                             to_torch(posterior_variance))\n        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n        self.register_buffer('posterior_log_variance_clipped', to_torch(\n            np.log(np.maximum(posterior_variance, 1e-20))))\n        self.register_buffer('posterior_mean_coef1', to_torch(\n            betas * np.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod)))\n        self.register_buffer('posterior_mean_coef2', to_torch(\n            (1. - alphas_cumprod_prev) * np.sqrt(alphas) / (1. - alphas_cumprod)))\n\n    def predict_start_from_noise(self, x_t, t, noise):\n        return self.sqrt_recip_alphas_cumprod[t] * x_t - \\\n            self.sqrt_recipm1_alphas_cumprod[t] * noise\n\n    def q_posterior(self, x_start, x_t, t):\n        posterior_mean = self.posterior_mean_coef1[t] * \\\n            x_start + self.posterior_mean_coef2[t] * x_t\n        posterior_log_variance_clipped = self.posterior_log_variance_clipped[t]\n        return posterior_mean, posterior_log_variance_clipped\n\n    def p_mean_variance(self, x, t, clip_denoised: bool, condition_x=None):\n        batch_size = x.shape[0]\n        noise_level = torch.FloatTensor(\n            [self.sqrt_alphas_cumprod_prev[t+1]]).repeat(batch_size, 1).to(x.device)\n        if condition_x is not None:\n            #print(f\"condition:{condition_x.shape}\")\n            #print(f\"x:{x.shape}\")\n            x_recon = self.predict_start_from_noise(\n                x, t=t, noise=self.denoise_fn(torch.cat([condition_x, x], dim=1), noise_level)) # previously dim=1\n            #print(f\"x_recon:{x_recon.shape}\")\n        else:\n            x_recon = self.predict_start_from_noise(\n                x, t=t, noise=self.denoise_fn(x, noise_level))\n\n        if clip_denoised:\n            x_recon.clamp_(-1., 1.)\n\n        model_mean, posterior_log_variance = self.q_posterior(\n            x_start=x_recon, x_t=x, t=t)\n        return model_mean, posterior_log_variance\n\n    @torch.no_grad()\n    def p_sample(self, x, t, clip_denoised=True, condition_x=None):\n        model_mean, model_log_variance = self.p_mean_variance(\n            x=x, t=t, clip_denoised=clip_denoised, condition_x=condition_x)\n        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n        return model_mean + noise * (0.5 * model_log_variance).exp()\n\n    @torch.no_grad()\n    def p_sample_loop(self, x_in, continous=False):\n        device = self.betas.device\n        sample_inter = (1 | (self.num_timesteps//10))\n        if not self.conditional:\n            shape = x_in\n            img = torch.randn(shape, device=device)\n            ret_img = img\n            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n                img = self.p_sample(img, i)\n                if i % sample_inter == 0:\n                    ret_img = torch.cat([ret_img, img], dim=0)\n        else:\n            x = x_in\n            shape = x.shape\n            #print(shape)\n            img = torch.randn(shape, device=device)\n            ret_img = x\n            for i in tqdm(reversed(range(0, self.num_timesteps)), desc='sampling loop time step', total=self.num_timesteps):\n                img = self.p_sample(img, i, condition_x=x)\n                if i % sample_inter == 0:\n                    ret_img = torch.cat([ret_img, img], dim=0)\n                    #print(ret_img.shape)\n        if continous:\n            return ret_img\n        else:\n            return ret_img[-1]\n\n    @torch.no_grad()\n    def sample(self, batch_size=1, continous=False):\n        image_size = self.image_size\n        channels = self.channels\n        return self.p_sample_loop((batch_size, channels, image_size, image_size), continous)\n\n    @torch.no_grad()\n    def super_resolution(self, x_in, continous=False):\n        return self.p_sample_loop(x_in, continous)\n\n    def q_sample(self, x_start, continuous_sqrt_alpha_cumprod, noise=None):\n        noise = default(noise, lambda: torch.randn_like(x_start))\n\n        # random gama\n        return (\n            continuous_sqrt_alpha_cumprod * x_start +\n            (1 - continuous_sqrt_alpha_cumprod**2).sqrt() * noise\n        )\n\n    def p_losses(self, x_in, noise=None):\n        x_start = x_in['GT']\n        [b, c, h, w] = x_start.shape\n        t = np.random.randint(1, self.num_timesteps + 1)\n        continuous_sqrt_alpha_cumprod = torch.FloatTensor(\n            np.random.uniform(\n                self.sqrt_alphas_cumprod_prev[t-1],\n                self.sqrt_alphas_cumprod_prev[t],\n                size=b\n            )\n        ).to(x_start.device)\n        continuous_sqrt_alpha_cumprod = continuous_sqrt_alpha_cumprod.view(\n            b, -1)\n\n        noise = default(noise, lambda: torch.randn_like(x_start))\n        x_noisy = self.q_sample(\n            x_start=x_start, continuous_sqrt_alpha_cumprod=continuous_sqrt_alpha_cumprod.view(-1, 1, 1, 1), noise=noise)\n\n        if not self.conditional:\n            x_recon = self.denoise_fn(x_noisy, continuous_sqrt_alpha_cumprod)\n        else:\n            x_recon = self.denoise_fn(\n                torch.cat([x_in['Noisy'], x_noisy], dim=1), continuous_sqrt_alpha_cumprod)\n                # Everything has to be 4D! Otherwise concatenation on this axis is not possible!!!\n                # The concatenated representation is automatically 4D anyways at the end!!!\n        loss = self.loss_func(noise, x_recon)\n        return loss\n\n    def forward(self, x, *args, **kwargs):\n        return self.p_losses(x, *args, **kwargs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:03:31.383660Z","iopub.execute_input":"2025-05-08T17:03:31.384227Z","iopub.status.idle":"2025-05-08T17:03:31.408607Z","shell.execute_reply.started":"2025-05-08T17:03:31.384204Z","shell.execute_reply":"2025-05-08T17:03:31.407922Z"}},"outputs":[],"execution_count":95},{"cell_type":"markdown","source":"Helper functions","metadata":{}},{"cell_type":"code","source":"def weights_init_normal(m, std=0.02):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.normal_(m.weight.data, 0.0, std)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('Linear') != -1:\n        init.normal_(m.weight.data, 0.0, std)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('BatchNorm2d') != -1:\n        init.normal_(m.weight.data, 1.0, std)  # BN also uses norm\n        init.constant_(m.bias.data, 0.0)\n\n\ndef weights_init_kaiming(m, scale=1):\n    classname = m.__class__.__name__\n    if classname.find('Conv2d') != -1:\n        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n        m.weight.data *= scale\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('Linear') != -1:\n        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n        m.weight.data *= scale\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('BatchNorm2d') != -1:\n        init.constant_(m.weight.data, 1.0)\n        init.constant_(m.bias.data, 0.0)\n\n\ndef weights_init_orthogonal(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        init.orthogonal_(m.weight.data, gain=1)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('Linear') != -1:\n        init.orthogonal_(m.weight.data, gain=1)\n        if m.bias is not None:\n            m.bias.data.zero_()\n    elif classname.find('BatchNorm2d') != -1:\n        init.constant_(m.weight.data, 1.0)\n        init.constant_(m.bias.data, 0.0)\n\n\ndef init_weights(net, init_type='kaiming', scale=1, std=0.02):\n    # scale for 'kaiming', std for 'normal'.\n    logger.info('Initialization method [{:s}]'.format(init_type))\n    if init_type == 'normal':\n        weights_init_normal_ = functools.partial(weights_init_normal, std=std)\n        net.apply(weights_init_normal_)\n    elif init_type == 'kaiming':\n        weights_init_kaiming_ = functools.partial(\n            weights_init_kaiming, scale=scale)\n        net.apply(weights_init_kaiming_)\n    elif init_type == 'orthogonal':\n        net.apply(weights_init_orthogonal)\n    else:\n        raise NotImplementedError(\n            'initialization method [{:s}] not implemented'.format(init_type))\n\n\n####################\n# define network\n####################\n\n\n# Generator\ndef define_G(opt):\n    model_opt = opt['model']\n    if ('norm_groups' not in model_opt['unet']) or model_opt['unet']['norm_groups'] is None:\n        model_opt['unet']['norm_groups']=32\n    model = UNet(\n        in_channel=model_opt['unet']['in_channel'],\n        out_channel=model_opt['unet']['out_channel'],\n        norm_groups=model_opt['unet']['norm_groups'],\n        inner_channel=model_opt['unet']['inner_channel'],\n        channel_mults=model_opt['unet']['channel_multiplier'],\n        attn_res=model_opt['unet']['attn_res'],\n        res_blocks=model_opt['unet']['res_blocks'],\n        dropout=model_opt['unet']['dropout'],\n        image_size=model_opt['diffusion']['image_size']\n    )\n    netG = GaussianDiffusion(\n        model,\n        image_size=model_opt['diffusion']['image_size'],\n        channels=model_opt['diffusion']['channels'],\n        loss_type='l1',    # L1 or L2\n        conditional=model_opt['diffusion']['conditional'],\n        schedule_opt=model_opt['beta_schedule']['train']\n    )\n    if opt['phase'] == 'train':\n        # init_weights(netG, init_type='kaiming', scale=0.1)\n        init_weights(netG, init_type='orthogonal')\n    if opt['gpu_ids']:\n        assert torch.cuda.is_available()\n    # if opt['gpu_ids'] and opt['distributed']:\n    #     assert torch.cuda.is_available()\n    #     netG = nn.DataParallel(netG)\n    return netG","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:03:31.653451Z","iopub.execute_input":"2025-05-08T17:03:31.653937Z","iopub.status.idle":"2025-05-08T17:03:31.665755Z","shell.execute_reply.started":"2025-05-08T17:03:31.653917Z","shell.execute_reply":"2025-05-08T17:03:31.664973Z"}},"outputs":[],"execution_count":96},{"cell_type":"markdown","source":"Model classes","metadata":{}},{"cell_type":"code","source":"class SR3():\n    def __init__(self, opt):\n        self.opt = opt\n        self.device = torch.device(\n            'cuda' if opt['gpu_ids'] is not None else 'cpu')\n        self.begin_step = 0\n        self.begin_epoch = 0\n        # define network and load pretrained models\n        self.netG = self.set_device(define_G(opt))\n        self.schedule_phase = None\n\n        # set loss and load resume state\n        self.set_loss()\n        self.set_new_noise_schedule(\n            opt['model']['beta_schedule']['train'], schedule_phase='train')\n        if self.opt['phase'] == 'train':\n            self.netG.train()\n            # find the parameters to optimize\n            if opt['model']['finetune_norm']:\n                optim_params = []\n                for k, v in self.netG.named_parameters():\n                    v.requires_grad = False\n                    if k.find('transformer') >= 0:\n                        v.requires_grad = True\n                        v.data.zero_()\n                        optim_params.append(v)\n                        logger.info(\n                            'Params [{:s}] initialized to 0 and will optimize.'.format(k))\n            else:\n                optim_params = list(self.netG.parameters())\n\n            self.optG = torch.optim.Adam(\n                optim_params, lr=opt['train'][\"optimizer\"][\"lr\"])\n            self.log_dict = OrderedDict()\n        self.load_network()\n        self.print_network()\n\n    def set_device(self, x):\n        if isinstance(x, dict):\n            for key, item in x.items():\n                if item is not None and type(item)==torch.Tensor:\n                    x[key] = item.to(self.device)\n        elif isinstance(x, list):\n            for item in x:\n                if item is not None:\n                    item = item.to(self.device)\n        else:\n            x = x.to(self.device)\n        return x\n\n    def get_network_description(self, network):\n        '''Get the string and total parameters of the network'''\n        if isinstance(network, nn.DataParallel):\n            network = network.module\n        s = str(network)\n        n = sum(map(lambda x: x.numel(), network.parameters()))\n        return s, n\n\n    def feed_data(self, data):\n        self.data = self.set_device(data)\n\n    def optimize_parameters(self):\n        self.optG.zero_grad()\n        l_pix = self.netG(self.data)\n        # need to average in multi-gpu\n        b, c, h, w = self.data['GT'].shape\n        l_pix = l_pix.sum()/int(b*c*h*w)\n        l_pix.backward()\n        self.optG.step()\n\n        # set log\n        self.log_dict['l_pix'] = l_pix.item()\n\n    def test(self, continous=False):\n        self.netG.eval()\n        with torch.no_grad():\n            if isinstance(self.netG, nn.DataParallel):\n                self.SR = self.netG.module.super_resolution(\n                    self.data['Noisy'], continous)\n            else:\n                self.SR = self.netG.super_resolution(\n                    self.data['Noisy'], continous)\n        self.netG.train()\n\n    def inference(self, img, continous=False):\n        self.netG.eval()\n        return self.netG.super_resolution(\n                    img, continous)\n\n    def sample(self, batch_size=1, continous=False):\n        self.netG.eval()\n        with torch.no_grad():\n            if isinstance(self.netG, nn.DataParallel):\n                self.SR = self.netG.module.sample(batch_size, continous)\n            else:\n                self.SR = self.netG.sample(batch_size, continous)\n        self.netG.train()\n\n    def set_loss(self):\n        if isinstance(self.netG, nn.DataParallel):\n            self.netG.module.set_loss(self.device)\n        else:\n            self.netG.set_loss(self.device)\n\n    def set_new_noise_schedule(self, schedule_opt, schedule_phase='train'):\n        if self.schedule_phase is None or self.schedule_phase != schedule_phase:\n            self.schedule_phase = schedule_phase\n            if isinstance(self.netG, nn.DataParallel):\n                self.netG.module.set_new_noise_schedule(\n                    schedule_opt, self.device)\n            else:\n                self.netG.set_new_noise_schedule(schedule_opt, self.device)\n\n    def get_current_log(self):\n        return self.log_dict\n\n    def get_current_visuals(self, need_LR=True, sample=False):\n        out_dict = OrderedDict()\n        if sample:\n            out_dict['SAM'] = self.SR.detach().float().cpu()\n        else:\n            out_dict['SR'] = self.SR.detach().float().cpu()\n            out_dict['INF'] = self.data['SR'].detach().float().cpu()\n            out_dict['HR'] = self.data['HR'].detach().float().cpu()\n            if need_LR and 'LR' in self.data:\n                out_dict['LR'] = self.data['LR'].detach().float().cpu()\n            else:\n                out_dict['LR'] = out_dict['INF']\n        return out_dict\n\n    def print_network(self):\n        s, n = self.get_network_description(self.netG)\n        if isinstance(self.netG, nn.DataParallel):\n            net_struc_str = '{} - {}'.format(self.netG.__class__.__name__,\n                                             self.netG.module.__class__.__name__)\n        else:\n            net_struc_str = '{}'.format(self.netG.__class__.__name__)\n\n        logger.info(\n            'Network G structure: {}, with parameters: {:,d}'.format(net_struc_str, n))\n        logger.info(s)\n\n    def save_network(self, epoch, iter_step):\n        gen_path = os.path.join(\n            self.opt['path']['checkpoint'], 'I{}_E{}_gen.pth'.format(iter_step, epoch))\n        opt_path = os.path.join(\n            self.opt['path']['checkpoint'], 'I{}_E{}_opt.pth'.format(iter_step, epoch))\n        # gen\n        network = self.netG\n        if isinstance(self.netG, nn.DataParallel):\n            network = network.module\n        state_dict = network.state_dict()\n        for key, param in state_dict.items():\n            state_dict[key] = param.cpu()\n        torch.save(state_dict, gen_path)\n        # opt\n        opt_state = {'epoch': epoch, 'iter': iter_step,\n                     'scheduler': None, 'optimizer': None}\n        opt_state['optimizer'] = self.optG.state_dict()\n        torch.save(opt_state, opt_path)\n\n        logger.info(\n            'Saved model in [{:s}] ...'.format(gen_path))\n\n    def load_network(self):\n        load_path = self.opt['path']['resume_state']\n        if load_path is not None:\n            logger.info(\n                'Loading pretrained model for G [{:s}] ...'.format(load_path))\n            gen_path = '{}_gen.pth'.format(load_path)\n            opt_path = '{}_opt.pth'.format(load_path)\n            # gen\n            network = self.netG\n            if isinstance(self.netG, nn.DataParallel):\n                network = network.module\n            network.load_state_dict(torch.load(\n                gen_path), strict=(not self.opt['model']['finetune_norm']))\n            # network.load_state_dict(torch.load(\n            #     gen_path), strict=False)\n            if self.opt['phase'] == 'train':\n                # optimizer\n                opt = torch.load(opt_path)\n                self.optG.load_state_dict(opt['optimizer'])\n                self.begin_step = opt['iter']\n                self.begin_epoch = opt['epoch']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:03:31.928984Z","iopub.execute_input":"2025-05-08T17:03:31.929692Z","iopub.status.idle":"2025-05-08T17:03:31.948533Z","shell.execute_reply.started":"2025-05-08T17:03:31.929667Z","shell.execute_reply":"2025-05-08T17:03:31.947731Z"}},"outputs":[],"execution_count":97},{"cell_type":"markdown","source":"Training process","metadata":{}},{"cell_type":"code","source":"# model\ndiffusion = SR3(opt)\n# logger.info('Initial Model Finished')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:03:36.258369Z","iopub.execute_input":"2025-05-08T17:03:36.258802Z","iopub.status.idle":"2025-05-08T17:03:38.035220Z","shell.execute_reply.started":"2025-05-08T17:03:36.258780Z","shell.execute_reply":"2025-05-08T17:03:38.034670Z"}},"outputs":[{"name":"stderr","text":"25-05-08 17:03:37.537 - INFO: Loading pretrained model for G [/kaggle/input/sr3_v01/pytorch/default/1/checkpoint/I100_E1] ...\n25-05-08 17:03:37.537 - INFO: Loading pretrained model for G [/kaggle/input/sr3_v01/pytorch/default/1/checkpoint/I100_E1] ...\n/tmp/ipykernel_31/1563499019.py:176: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  network.load_state_dict(torch.load(\n25-05-08 17:03:38.028 - INFO: Network G structure: GaussianDiffusion, with parameters: 155,330,881\n25-05-08 17:03:38.028 - INFO: Network G structure: GaussianDiffusion, with parameters: 155,330,881\n25-05-08 17:03:38.030 - INFO: GaussianDiffusion(\n  (denoise_fn): UNet(\n    (noise_level_mlp): Sequential(\n      (0): PositionalEncoding()\n      (1): Linear(in_features=64, out_features=256, bias=True)\n      (2): Swish()\n      (3): Linear(in_features=256, out_features=64, bias=True)\n    )\n    (downs): ModuleList(\n      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=64, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Identity()\n        )\n      )\n      (2): Downsample(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (3): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=128, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (4): Downsample(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (5): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=256, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (6): Downsample(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (7): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=512, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (8): Downsample(\n        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (9): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (mid): ModuleList(\n      (0): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Identity()\n        )\n        (attn): SelfAttention(\n          (norm): GroupNorm(16, 1024, eps=1e-05, affine=True)\n          (qkv): Conv2d(1024, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (out): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (1): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Identity()\n        )\n      )\n    )\n    (ups): ModuleList(\n      (0): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 2048, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (1): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1536, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (2): Upsample(\n        (up): Upsample(scale_factor=2.0, mode='nearest')\n        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (3): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=512, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (4): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=512, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (5): Upsample(\n        (up): Upsample(scale_factor=2.0, mode='nearest')\n        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (6): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=256, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (7): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=256, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (8): Upsample(\n        (up): Upsample(scale_factor=2.0, mode='nearest')\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (9): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=128, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (10): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=128, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (11): Upsample(\n        (up): Upsample(scale_factor=2.0, mode='nearest')\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (12): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=64, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (13): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=64, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (final_conv): Block(\n      (block): Sequential(\n        (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n        (1): Swish()\n        (2): Identity()\n        (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n  )\n  (loss_func): L1Loss()\n)\n25-05-08 17:03:38.030 - INFO: GaussianDiffusion(\n  (denoise_fn): UNet(\n    (noise_level_mlp): Sequential(\n      (0): PositionalEncoding()\n      (1): Linear(in_features=64, out_features=256, bias=True)\n      (2): Swish()\n      (3): Linear(in_features=256, out_features=64, bias=True)\n    )\n    (downs): ModuleList(\n      (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=64, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Identity()\n        )\n      )\n      (2): Downsample(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (3): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=128, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (4): Downsample(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (5): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=256, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (6): Downsample(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (7): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=512, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (8): Downsample(\n        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      )\n      (9): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (mid): ModuleList(\n      (0): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Identity()\n        )\n        (attn): SelfAttention(\n          (norm): GroupNorm(16, 1024, eps=1e-05, affine=True)\n          (qkv): Conv2d(1024, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (out): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (1): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Identity()\n        )\n      )\n    )\n    (ups): ModuleList(\n      (0): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 2048, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (1): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=1024, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1536, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1024, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(1536, 1024, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (2): Upsample(\n        (up): Upsample(scale_factor=2.0, mode='nearest')\n        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (3): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=512, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 1536, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(1536, 512, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (4): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=512, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 512, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (5): Upsample(\n        (up): Upsample(scale_factor=2.0, mode='nearest')\n        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (6): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=256, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 768, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (7): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=256, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 256, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (8): Upsample(\n        (up): Upsample(scale_factor=2.0, mode='nearest')\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (9): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=128, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 384, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (10): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=128, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (11): Upsample(\n        (up): Upsample(scale_factor=2.0, mode='nearest')\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n      (12): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=64, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 192, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (13): ResnetBlocWithAttn(\n        (res_block): ResnetBlock(\n          (noise_func): FeatureWiseAffine(\n            (noise_func): Sequential(\n              (0): Linear(in_features=64, out_features=64, bias=True)\n            )\n          )\n          (block1): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 128, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (block2): Block(\n            (block): Sequential(\n              (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n              (1): Swish()\n              (2): Identity()\n              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n            )\n          )\n          (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n    (final_conv): Block(\n      (block): Sequential(\n        (0): GroupNorm(16, 64, eps=1e-05, affine=True)\n        (1): Swish()\n        (2): Identity()\n        (3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n  )\n  (loss_func): L1Loss()\n)\n","output_type":"stream"}],"execution_count":98},{"cell_type":"markdown","source":"Load weights of trained model","metadata":{}},{"cell_type":"code","source":"diffusion.load_network()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:03:40.121861Z","iopub.execute_input":"2025-05-08T17:03:40.122567Z","iopub.status.idle":"2025-05-08T17:03:40.552242Z","shell.execute_reply.started":"2025-05-08T17:03:40.122545Z","shell.execute_reply":"2025-05-08T17:03:40.551420Z"}},"outputs":[{"name":"stderr","text":"25-05-08 17:03:40.123 - INFO: Loading pretrained model for G [/kaggle/input/sr3_v01/pytorch/default/1/checkpoint/I100_E1] ...\n25-05-08 17:03:40.123 - INFO: Loading pretrained model for G [/kaggle/input/sr3_v01/pytorch/default/1/checkpoint/I100_E1] ...\n/tmp/ipykernel_31/1563499019.py:176: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  network.load_state_dict(torch.load(\n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"test_img = test_set[100]['Noisy'].unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:00:07.862424Z","iopub.execute_input":"2025-05-08T17:00:07.862630Z","iopub.status.idle":"2025-05-08T17:00:07.938785Z","shell.execute_reply.started":"2025-05-08T17:00:07.862613Z","shell.execute_reply":"2025-05-08T17:00:07.938257Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"test_img.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:00:07.940196Z","iopub.execute_input":"2025-05-08T17:00:07.940431Z","iopub.status.idle":"2025-05-08T17:00:07.944937Z","shell.execute_reply.started":"2025-05-08T17:00:07.940409Z","shell.execute_reply":"2025-05-08T17:00:07.944411Z"}},"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 1, 64, 64])"},"metadata":{}}],"execution_count":90},{"cell_type":"code","source":"result = diffusion.inference(test_img.to(\"cuda\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:03:45.749585Z","iopub.execute_input":"2025-05-08T17:03:45.749858Z","iopub.status.idle":"2025-05-08T17:04:14.695383Z","shell.execute_reply.started":"2025-05-08T17:03:45.749837Z","shell.execute_reply":"2025-05-08T17:04:14.694780Z"}},"outputs":[{"name":"stderr","text":"sampling loop time step: 100%|██████████| 2000/2000 [00:28<00:00, 69.11it/s]\n","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:04:17.498042Z","iopub.execute_input":"2025-05-08T17:04:17.498365Z","iopub.status.idle":"2025-05-08T17:04:17.506735Z","shell.execute_reply.started":"2025-05-08T17:04:17.498344Z","shell.execute_reply":"2025-05-08T17:04:17.506127Z"}},"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"tensor([[[-1.0000, -0.9955, -0.9797,  ..., -0.9847, -0.5032, -1.0000],\n         [ 0.9878,  1.0000,  0.9997,  ...,  0.5149, -0.2514,  0.5546],\n         [ 1.0000,  0.0135, -0.9969,  ...,  0.4458, -0.0819, -0.8066],\n         ...,\n         [ 0.7357, -0.9757, -0.7680,  ..., -0.5426, -0.9862,  0.2832],\n         [ 0.7538,  0.9269, -0.0483,  ..., -0.9999, -0.2616,  0.2488],\n         [-0.0875,  0.0151, -0.3422,  ..., -0.5522,  0.9964,  0.2924]]],\n       device='cuda:0')"},"metadata":{}}],"execution_count":101},{"cell_type":"code","source":"from torchvision import transforms\n\nto_pil = transforms.ToPILImage()\n\n# Assume `tensor` is in shape [C, H, W] and in [0, 1] or [0, 255] range\npil_image = to_pil(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:04:41.369645Z","iopub.execute_input":"2025-05-08T17:04:41.369913Z","iopub.status.idle":"2025-05-08T17:04:44.470976Z","shell.execute_reply.started":"2025-05-08T17:04:41.369888Z","shell.execute_reply":"2025-05-08T17:04:44.470435Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"pil_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T17:04:45.926782Z","iopub.execute_input":"2025-05-08T17:04:45.927799Z","iopub.status.idle":"2025-05-08T17:04:45.935953Z","shell.execute_reply.started":"2025-05-08T17:04:45.927771Z","shell.execute_reply":"2025-05-08T17:04:45.935041Z"}},"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"<PIL.Image.Image image mode=L size=64x64>","image/png":"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","image/jpeg":"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"},"metadata":{}}],"execution_count":103},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}