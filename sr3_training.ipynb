{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdddae8",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import data as Data\n",
    "import model as Model\n",
    "import argparse\n",
    "import logging\n",
    "import core.logger as Logger\n",
    "import core.metrics as Metrics\n",
    "from core.wandb_logger import WandbLogger\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "import lmdb\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import data.util as Util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752d72c",
   "metadata": {},
   "source": [
    "Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ac5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    \"name\": \"distributed_high_sr_ffhq\",\n",
    "    \"phase\": \"train\",  # overridden or defaulted from CLI\n",
    "    \"gpu_ids\": [0, 1],  # from config (unless overridden by CLI)\n",
    "    \"debug\": False,  # default from CLI\n",
    "    \"enable_wandb\": False,  # default from CLI\n",
    "    \"log_wandb_ckpt\": False,  # default from CLI\n",
    "    \"log_eval\": False,  # default from CLI\n",
    "    \"path\": {\n",
    "        \"log\": \"logs\",\n",
    "        \"tb_logger\": \"tb_logger\",\n",
    "        \"results\": \"results\",\n",
    "        \"checkpoint\": \"checkpoint\",\n",
    "        \"resume_state\": None\n",
    "    },\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"name\": \"FFHQ\",\n",
    "            \"mode\": \"HR\",\n",
    "            \"dataroot\": \"dataset/ffhq_64_512\",\n",
    "            \"datatype\": \"img\",\n",
    "            \"l_resolution\": 64,\n",
    "            \"r_resolution\": 512,\n",
    "            \"batch_size\": 2,\n",
    "            \"num_workers\": 8,\n",
    "            \"use_shuffle\": True,\n",
    "            \"data_len\": -1\n",
    "        },\n",
    "        \"val\": {\n",
    "            \"name\": \"CelebaHQ\",\n",
    "            \"mode\": \"LRHR\",\n",
    "            \"dataroot\": \"dataset/celebahq_64_512\",\n",
    "            \"datatype\": \"img\",\n",
    "            \"l_resolution\": 64,\n",
    "            \"r_resolution\": 512,\n",
    "            \"data_len\": 50\n",
    "        }\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"which_model_G\": \"sr3\",\n",
    "        \"finetune_norm\": False,\n",
    "        \"unet\": {\n",
    "            \"in_channel\": 6,\n",
    "            \"out_channel\": 3,\n",
    "            \"inner_channel\": 64,\n",
    "            \"norm_groups\": 16,\n",
    "            \"channel_multiplier\": [1, 2, 4, 8, 16],\n",
    "            \"attn_res\": [],\n",
    "            \"res_blocks\": 1,\n",
    "            \"dropout\": 0\n",
    "        },\n",
    "        \"beta_schedule\": {\n",
    "            \"train\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            },\n",
    "            \"val\": {\n",
    "                \"schedule\": \"linear\",\n",
    "                \"n_timestep\": 2000,\n",
    "                \"linear_start\": 1e-6,\n",
    "                \"linear_end\": 1e-2\n",
    "            }\n",
    "        },\n",
    "        \"diffusion\": {\n",
    "            \"image_size\": 512,\n",
    "            \"channels\": 3,\n",
    "            \"conditional\": True\n",
    "        }\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"n_iter\": 1000000,\n",
    "        \"val_freq\": 1e4,\n",
    "        \"save_checkpoint_freq\": 1e4,\n",
    "        \"print_freq\": 50,\n",
    "        \"optimizer\": {\n",
    "            \"type\": \"adam\",\n",
    "            \"lr\": 3e-6\n",
    "        },\n",
    "        \"ema_scheduler\": {\n",
    "            \"step_start_ema\": 5000,\n",
    "            \"update_ema_every\": 1,\n",
    "            \"ema_decay\": 0.9999\n",
    "        }\n",
    "    },\n",
    "    \"wandb\": {\n",
    "        \"project\": \"distributed_high_sr_ffhq\"\n",
    "    },\n",
    "    \"config_file\": \"config/sr_sr3_16_128.json\"  # from CLI\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3afedc2",
   "metadata": {},
   "source": [
    "Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # logging\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Logger.setup_logger(None, opt['path']['log'],\n",
    "#                     'train', level=logging.INFO, screen=True)\n",
    "# Logger.setup_logger('val', opt['path']['log'], 'val', level=logging.INFO)\n",
    "# logger = logging.getLogger('base')\n",
    "# logger.info(Logger.dict2str(opt))\n",
    "# tb_logger = SummaryWriter(log_dir=opt['path']['tb_logger'])\n",
    "\n",
    "# # Initialize WandbLogger\n",
    "# if opt['enable_wandb']:\n",
    "#     import wandb\n",
    "#     wandb_logger = WandbLogger(opt)\n",
    "#     wandb.define_metric('validation/val_step')\n",
    "#     wandb.define_metric('epoch')\n",
    "#     wandb.define_metric(\"validation/*\", step_metric=\"val_step\")\n",
    "#     val_step = 0\n",
    "# else:\n",
    "#     wandb_logger = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80637995",
   "metadata": {},
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f3906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRHRDataset(Dataset):\n",
    "    def __init__(self, dataroot, datatype, l_resolution=16, r_resolution=128, split='train', data_len=-1, need_LR=False):\n",
    "        self.datatype = datatype\n",
    "        self.l_res = l_resolution\n",
    "        self.r_res = r_resolution\n",
    "        self.data_len = data_len\n",
    "        self.need_LR = need_LR\n",
    "        self.split = split\n",
    "\n",
    "        if datatype == 'lmdb':\n",
    "            self.env = lmdb.open(dataroot, readonly=True, lock=False,\n",
    "                                 readahead=False, meminit=False)\n",
    "            # init the datalen\n",
    "            with self.env.begin(write=False) as txn:\n",
    "                self.dataset_len = int(txn.get(\"length\".encode(\"utf-8\")))\n",
    "            if self.data_len <= 0:\n",
    "                self.data_len = self.dataset_len\n",
    "            else:\n",
    "                self.data_len = min(self.data_len, self.dataset_len)\n",
    "        elif datatype == 'img':\n",
    "            self.sr_path = Util.get_paths_from_images(\n",
    "                '{}/sr_{}_{}'.format(dataroot, l_resolution, r_resolution))\n",
    "            self.hr_path = Util.get_paths_from_images(\n",
    "                '{}/hr_{}'.format(dataroot, r_resolution))\n",
    "            if self.need_LR:\n",
    "                self.lr_path = Util.get_paths_from_images(\n",
    "                    '{}/lr_{}'.format(dataroot, l_resolution))\n",
    "            self.dataset_len = len(self.hr_path)\n",
    "            if self.data_len <= 0:\n",
    "                self.data_len = self.dataset_len\n",
    "            else:\n",
    "                self.data_len = min(self.data_len, self.dataset_len)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                'data_type [{:s}] is not recognized.'.format(datatype))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_HR = None\n",
    "        img_LR = None\n",
    "\n",
    "        if self.datatype == 'lmdb':\n",
    "            with self.env.begin(write=False) as txn:\n",
    "                hr_img_bytes = txn.get(\n",
    "                    'hr_{}_{}'.format(\n",
    "                        self.r_res, str(index).zfill(5)).encode('utf-8')\n",
    "                )\n",
    "                sr_img_bytes = txn.get(\n",
    "                    'sr_{}_{}_{}'.format(\n",
    "                        self.l_res, self.r_res, str(index).zfill(5)).encode('utf-8')\n",
    "                )\n",
    "                if self.need_LR:\n",
    "                    lr_img_bytes = txn.get(\n",
    "                        'lr_{}_{}'.format(\n",
    "                            self.l_res, str(index).zfill(5)).encode('utf-8')\n",
    "                    )\n",
    "                # skip the invalid index\n",
    "                while (hr_img_bytes is None) or (sr_img_bytes is None):\n",
    "                    new_index = random.randint(0, self.data_len-1)\n",
    "                    hr_img_bytes = txn.get(\n",
    "                        'hr_{}_{}'.format(\n",
    "                            self.r_res, str(new_index).zfill(5)).encode('utf-8')\n",
    "                    )\n",
    "                    sr_img_bytes = txn.get(\n",
    "                        'sr_{}_{}_{}'.format(\n",
    "                            self.l_res, self.r_res, str(new_index).zfill(5)).encode('utf-8')\n",
    "                    )\n",
    "                    if self.need_LR:\n",
    "                        lr_img_bytes = txn.get(\n",
    "                            'lr_{}_{}'.format(\n",
    "                                self.l_res, str(new_index).zfill(5)).encode('utf-8')\n",
    "                        )\n",
    "                img_HR = Image.open(BytesIO(hr_img_bytes)).convert(\"RGB\")\n",
    "                img_SR = Image.open(BytesIO(sr_img_bytes)).convert(\"RGB\")\n",
    "                if self.need_LR:\n",
    "                    img_LR = Image.open(BytesIO(lr_img_bytes)).convert(\"RGB\")\n",
    "        else:\n",
    "            img_HR = Image.open(self.hr_path[index]).convert(\"RGB\")\n",
    "            img_SR = Image.open(self.sr_path[index]).convert(\"RGB\")\n",
    "            if self.need_LR:\n",
    "                img_LR = Image.open(self.lr_path[index]).convert(\"RGB\")\n",
    "        if self.need_LR:\n",
    "            [img_LR, img_SR, img_HR] = Util.transform_augment(\n",
    "                [img_LR, img_SR, img_HR], split=self.split, min_max=(-1, 1))\n",
    "            return {'LR': img_LR, 'HR': img_HR, 'SR': img_SR, 'Index': index}\n",
    "        else:\n",
    "            [img_SR, img_HR] = Util.transform_augment(\n",
    "                [img_SR, img_HR], split=self.split, min_max=(-1, 1))\n",
    "            return {'HR': img_HR, 'SR': img_SR, 'Index': index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "for phase, dataset_opt in opt['datasets'].items():\n",
    "    if phase == 'train' and opt['phase'] != 'val':\n",
    "        train_set = Data.create_dataset(dataset_opt, phase)\n",
    "        train_loader = Data.create_dataloader(\n",
    "            train_set, dataset_opt, phase)\n",
    "    elif phase == 'val':\n",
    "        val_set = Data.create_dataset(dataset_opt, phase)\n",
    "        val_loader = Data.create_dataloader(\n",
    "            val_set, dataset_opt, phase)\n",
    "# logger.info('Initial Dataset Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85513b02",
   "metadata": {},
   "source": [
    "Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "diffusion = Model.create_model(opt)\n",
    "# logger.info('Initial Model Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64707f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "current_step = diffusion.begin_step\n",
    "current_epoch = diffusion.begin_epoch\n",
    "n_iter = opt['train']['n_iter']\n",
    "\n",
    "if opt['path']['resume_state']:\n",
    "    logger.info('Resuming training from epoch: {}, iter: {}.'.format(\n",
    "        current_epoch, current_step))\n",
    "\n",
    "diffusion.set_new_noise_schedule(\n",
    "    opt['model']['beta_schedule'][opt['phase']], schedule_phase=opt['phase'])\n",
    "if opt['phase'] == 'train':\n",
    "    while current_step < n_iter:\n",
    "        current_epoch += 1\n",
    "        for _, train_data in enumerate(train_loader):\n",
    "            current_step += 1\n",
    "            if current_step > n_iter:\n",
    "                break\n",
    "            diffusion.feed_data(train_data)\n",
    "            diffusion.optimize_parameters()\n",
    "            # log\n",
    "            if current_step % opt['train']['print_freq'] == 0:\n",
    "                logs = diffusion.get_current_log()\n",
    "                message = '<epoch:{:3d}, iter:{:8,d}> '.format(\n",
    "                    current_epoch, current_step)\n",
    "                for k, v in logs.items():\n",
    "                    message += '{:s}: {:.4e} '.format(k, v)\n",
    "                    tb_logger.add_scalar(k, v, current_step)\n",
    "                logger.info(message)\n",
    "\n",
    "                if wandb_logger:\n",
    "                    wandb_logger.log_metrics(logs)\n",
    "\n",
    "    #         # validation\n",
    "    #         if current_step % opt['train']['val_freq'] == 0:\n",
    "    #             avg_psnr = 0.0\n",
    "    #             idx = 0\n",
    "    #             result_path = '{}/{}'.format(opt['path']\n",
    "    #                                             ['results'], current_epoch)\n",
    "    #             os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "    #             diffusion.set_new_noise_schedule(\n",
    "    #                 opt['model']['beta_schedule']['val'], schedule_phase='val')\n",
    "    #             for _,  val_data in enumerate(val_loader):\n",
    "    #                 idx += 1\n",
    "    #                 diffusion.feed_data(val_data)\n",
    "    #                 diffusion.test(continous=False)\n",
    "    #                 visuals = diffusion.get_current_visuals()\n",
    "    #                 sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "    #                 hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "    #                 lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "    #                 fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "\n",
    "    #                 # generation\n",
    "    #                 Metrics.save_img(\n",
    "    #                     hr_img, '{}/{}_{}_hr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     sr_img, '{}/{}_{}_sr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     lr_img, '{}/{}_{}_lr.png'.format(result_path, current_step, idx))\n",
    "    #                 Metrics.save_img(\n",
    "    #                     fake_img, '{}/{}_{}_inf.png'.format(result_path, current_step, idx))\n",
    "    #                 tb_logger.add_image(\n",
    "    #                     'Iter_{}'.format(current_step),\n",
    "    #                     np.transpose(np.concatenate(\n",
    "    #                         (fake_img, sr_img, hr_img), axis=1), [2, 0, 1]),\n",
    "    #                     idx)\n",
    "    #                 avg_psnr += Metrics.calculate_psnr(\n",
    "    #                     sr_img, hr_img)\n",
    "\n",
    "    #                 if wandb_logger:\n",
    "    #                     wandb_logger.log_image(\n",
    "    #                         f'validation_{idx}', \n",
    "    #                         np.concatenate((fake_img, sr_img, hr_img), axis=1)\n",
    "    #                     )\n",
    "\n",
    "    #             avg_psnr = avg_psnr / idx\n",
    "    #             diffusion.set_new_noise_schedule(\n",
    "    #                 opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "    #             # log\n",
    "    #             logger.info('# Validation # PSNR: {:.4e}'.format(avg_psnr))\n",
    "    #             logger_val = logging.getLogger('val')  # validation logger\n",
    "    #             logger_val.info('<epoch:{:3d}, iter:{:8,d}> psnr: {:.4e}'.format(\n",
    "    #                 current_epoch, current_step, avg_psnr))\n",
    "    #             # tensorboard logger\n",
    "    #             tb_logger.add_scalar('psnr', avg_psnr, current_step)\n",
    "\n",
    "    #             if wandb_logger:\n",
    "    #                 wandb_logger.log_metrics({\n",
    "    #                     'validation/val_psnr': avg_psnr,\n",
    "    #                     'validation/val_step': val_step\n",
    "    #                 })\n",
    "    #                 val_step += 1\n",
    "\n",
    "    #         if current_step % opt['train']['save_checkpoint_freq'] == 0:\n",
    "    #             logger.info('Saving models and training states.')\n",
    "    #             diffusion.save_network(current_epoch, current_step)\n",
    "\n",
    "    #             if wandb_logger and opt['log_wandb_ckpt']:\n",
    "    #                 wandb_logger.log_checkpoint(current_epoch, current_step)\n",
    "\n",
    "    #     if wandb_logger:\n",
    "    #         wandb_logger.log_metrics({'epoch': current_epoch-1})\n",
    "\n",
    "    # # save model\n",
    "    # logger.info('End of training.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf70127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling validation (not considered for now and maybe even moving to seperate notebook could make sense, has to be thought about)\n",
    "\n",
    "# else:\n",
    "#     logger.info('Begin Model Evaluation.')\n",
    "#     avg_psnr = 0.0\n",
    "#     avg_ssim = 0.0\n",
    "#     idx = 0\n",
    "#     result_path = '{}'.format(opt['path']['results'])\n",
    "#     os.makedirs(result_path, exist_ok=True)\n",
    "#     for _,  val_data in enumerate(val_loader):\n",
    "#         idx += 1\n",
    "#         diffusion.feed_data(val_data)\n",
    "#         diffusion.test(continous=True)\n",
    "#         visuals = diffusion.get_current_visuals()\n",
    "\n",
    "#         hr_img = Metrics.tensor2img(visuals['HR'])  # uint8\n",
    "#         lr_img = Metrics.tensor2img(visuals['LR'])  # uint8\n",
    "#         fake_img = Metrics.tensor2img(visuals['INF'])  # uint8\n",
    "\n",
    "#         sr_img_mode = 'grid'\n",
    "#         if sr_img_mode == 'single':\n",
    "#             # single img series\n",
    "#             sr_img = visuals['SR']  # uint8\n",
    "#             sample_num = sr_img.shape[0]\n",
    "#             for iter in range(0, sample_num):\n",
    "#                 Metrics.save_img(\n",
    "#                     Metrics.tensor2img(sr_img[iter]), '{}/{}_{}_sr_{}.png'.format(result_path, current_step, idx, iter))\n",
    "#         else:\n",
    "#             # grid img\n",
    "#             sr_img = Metrics.tensor2img(visuals['SR'])  # uint8\n",
    "#             Metrics.save_img(\n",
    "#                 sr_img, '{}/{}_{}_sr_process.png'.format(result_path, current_step, idx))\n",
    "#             Metrics.save_img(\n",
    "#                 Metrics.tensor2img(visuals['SR'][-1]), '{}/{}_{}_sr.png'.format(result_path, current_step, idx))\n",
    "\n",
    "#         Metrics.save_img(\n",
    "#             hr_img, '{}/{}_{}_hr.png'.format(result_path, current_step, idx))\n",
    "#         Metrics.save_img(\n",
    "#             lr_img, '{}/{}_{}_lr.png'.format(result_path, current_step, idx))\n",
    "#         Metrics.save_img(\n",
    "#             fake_img, '{}/{}_{}_inf.png'.format(result_path, current_step, idx))\n",
    "\n",
    "#         # generation\n",
    "#         eval_psnr = Metrics.calculate_psnr(Metrics.tensor2img(visuals['SR'][-1]), hr_img)\n",
    "#         eval_ssim = Metrics.calculate_ssim(Metrics.tensor2img(visuals['SR'][-1]), hr_img)\n",
    "\n",
    "#         avg_psnr += eval_psnr\n",
    "#         avg_ssim += eval_ssim\n",
    "\n",
    "#         if wandb_logger and opt['log_eval']:\n",
    "#             wandb_logger.log_eval_data(fake_img, Metrics.tensor2img(visuals['SR'][-1]), hr_img, eval_psnr, eval_ssim)\n",
    "\n",
    "#     avg_psnr = avg_psnr / idx\n",
    "#     avg_ssim = avg_ssim / idx\n",
    "\n",
    "#     # log\n",
    "#     logger.info('# Validation # PSNR: {:.4e}'.format(avg_psnr))\n",
    "#     logger.info('# Validation # SSIM: {:.4e}'.format(avg_ssim))\n",
    "#     logger_val = logging.getLogger('val')  # validation logger\n",
    "#     logger_val.info('<epoch:{:3d}, iter:{:8,d}> psnr: {:.4e}, ssim：{:.4e}'.format(\n",
    "#         current_epoch, current_step, avg_psnr, avg_ssim))\n",
    "\n",
    "#     if wandb_logger:\n",
    "#         if opt['log_eval']:\n",
    "#             wandb_logger.log_eval_table()\n",
    "#         wandb_logger.log_metrics({\n",
    "#             'PSNR': float(avg_psnr),\n",
    "#             'SSIM': float(avg_ssim)\n",
    "#         })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
